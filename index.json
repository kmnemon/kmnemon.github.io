[{"content":"在软件行业摸爬滚很多年，从开发软件采用分布式编译技术也需要一天一夜才能编译完成一套系统，大家都在使用16寸CRT编写代码的时代，到现在一台Mac的性能远超当时的集群性能。当年一本《硝烟中的Scrum和XP》读的津津乐道，学到的新东西立马在团队试用，到后来作为敏捷教练帮助企业组织转型。近几年企业开始“降本增效”风潮，普遍看到的只是“降本”，采用精益敏捷的方式减少浪费提升效率的实在太少。有时候看到明明只需1/2甚至1/3的人，改变做事方式，就能比现在更好，但企业还是倾向于低效堆人，十分感叹。\n言归正传，很早作为软件工程师的时候，喜欢在工作外写一些小工具帮助团队自动化一些事情，这个习惯在做教练的时候也继续保持着，估计还是内心喜欢写代码这件很纯粹有趣的事情。以前也想过开发一些面向用户的软件，投向市场，看看能不能掀起一点浪花。也跟曾经的团队聊过，无奈大家都要吃饭，养家，靠爱发电似乎难以实现。大家都知道现在这类软件基本很难有市场，所以这件事情一直搁置着，但内心仍有不甘。\n在从事敏捷教练期间听到最多的争论是“敏捷教练不要只当裁判，也要下场踢球”，“既要管杀，也要管埋”。于是教练不仅要传递知识，方法论，也要下场带着团队一起干。虽然这样，但进行软件交付的核心工作还是团队。除了通过帮助团队，自己也想深度体验敏捷，迭代，持续交付能做到什么程度，所以内心有个想法，自己分别扮演PO，Team，Scrum Master，从一个想法开始，到实现一个软件并推向市场。在这个过程中会对产品经理，开发，测试，运维，运营等角色在敏捷活动中怎样高效的协作有更深入的理解。记录这个过程中发生的事情，分享给大家，希望能有一些帮助。\n可以预见执行过程中的难点，一个是能不能完全实现这些想法，中间肯定会遇到各种困难需要去解决，第二个是主要是时间投入的保证，最近公司开始重视提效，希望能有所帮助，估计会有些忙，家里还有小朋友需要陪伴，考验怎样合理安排时间。好了暂时想到这些。\n初步想法如下：\n迭代周期为一周，在迭代内既要完成当前迭代的开发，也要完成下迭代用户故事的准备 采用用户故事地图进行版本规划 采用看板进行每日任务跟踪 每周进行回顾 借用TDD思维进行开发，但不完全遵循TDD的步骤 那么下周开始\u0026lt;迭代0-迭代准备阶段\u0026gt;：\n准备完成商业模式画布，用户建模，用户故事地图，迭代1用户故事准备,准备决策看板，任务看板\nWeek 1: Sprint 0 - 迭代准备\n","permalink":"https://kmnemon.github.io/posts/2025-02-09-start-agile/","summary":"\u003cp\u003e在软件行业摸爬滚很多年，从开发软件采用分布式编译技术也需要一天一夜才能编译完成一套系统，大家都在使用16寸CRT编写代码的时代，到现在一台Mac的性能远超当时的集群性能。当年一本《硝烟中的Scrum和XP》读的津津乐道，学到的新东西立马在团队试用，到后来作为敏捷教练帮助企业组织转型。近几年企业开始“降本增效”风潮，普遍看到的只是“降本”，采用精益敏捷的方式减少浪费提升效率的实在太少。有时候看到明明只需1/2甚至1/3的人，改变做事方式，就能比现在更好，但企业还是倾向于低效堆人，十分感叹。\u003c/p\u003e\n\u003cp\u003e言归正传，很早作为软件工程师的时候，喜欢在工作外写一些小工具帮助团队自动化一些事情，这个习惯在做教练的时候也继续保持着，估计还是内心喜欢写代码这件很纯粹有趣的事情。以前也想过开发一些面向用户的软件，投向市场，看看能不能掀起一点浪花。也跟曾经的团队聊过，无奈大家都要吃饭，养家，靠爱发电似乎难以实现。大家都知道现在这类软件基本很难有市场，所以这件事情一直搁置着，但内心仍有不甘。\u003c/p\u003e\n\u003cp\u003e在从事敏捷教练期间听到最多的争论是“敏捷教练不要只当裁判，也要下场踢球”，“既要管杀，也要管埋”。于是教练不仅要传递知识，方法论，也要下场带着团队一起干。虽然这样，但进行软件交付的核心工作还是团队。除了通过帮助团队，自己也想深度体验敏捷，迭代，持续交付能做到什么程度，所以内心有个想法，自己分别扮演PO，Team，Scrum Master，从一个想法开始，到实现一个软件并推向市场。在这个过程中会对产品经理，开发，测试，运维，运营等角色在敏捷活动中怎样高效的协作有更深入的理解。记录这个过程中发生的事情，分享给大家，希望能有一些帮助。\u003c/p\u003e\n\u003cp\u003e可以预见执行过程中的难点，一个是能不能完全实现这些想法，中间肯定会遇到各种困难需要去解决，第二个是主要是时间投入的保证，最近公司开始重视提效，希望能有所帮助，估计会有些忙，家里还有小朋友需要陪伴，考验怎样合理安排时间。好了暂时想到这些。\u003c/p\u003e\n\u003cp\u003e初步想法如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e迭代周期为一周，在迭代内既要完成当前迭代的开发，也要完成下迭代用户故事的准备\u003c/li\u003e\n\u003cli\u003e采用用户故事地图进行版本规划\u003c/li\u003e\n\u003cli\u003e采用看板进行每日任务跟踪\u003c/li\u003e\n\u003cli\u003e每周进行回顾\u003c/li\u003e\n\u003cli\u003e借用TDD思维进行开发，但不完全遵循TDD的步骤\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e那么下周开始\u0026lt;迭代0-迭代准备阶段\u0026gt;：\u003cbr\u003e\n准备完成商业模式画布，用户建模，用户故事地图，迭代1用户故事准备,准备决策看板，任务看板\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eWeek 1: Sprint 0 - 迭代准备\u003c/em\u003e\u003c/p\u003e","title":"敏捷日记 - 1.回到起点"},{"content":"Parallel和Concurrent 我们先来回顾一下概念: Parallel是指同时执行多个任务或计算.通常在多核或多处理器的硬件上并行执行多个操作,每个操作独立运行,并且是同步的(并行的任务在同一时刻发生).并行计算的目标是通过同时使用多个计算资源来加速程序的执行.\nConcurrent是指系统在同一时间段内处理多个任务的能力.并发并不意味着任务是同时执行的,而是任务在某一时刻轮流执行.\n举个例子就更容易理解： 你有一个奶茶店,制作奶茶需要三个步骤,分别是收银,调制奶茶配料和用设备制作奶茶.假设现在有两个角色,A负责收银,B负责调制奶茶配料和用设备制作奶茶.整个步骤是A-\u0026gt;B.作为店主你很快发现A收银很快,B调制配料和制作奶茶很慢造成了瓶颈,这是你选择解决方案是再雇佣了另外一个人和B一起负责调制奶茶配料和用设备制作奶茶,现在整个步骤是A-\u0026gt;B1 or B2.在这个场景中增加B2就是我们说的Parallel.当然你还可以用另一个方案解决,把原步骤调制奶茶配料和用设备制作奶茶拆分为两个步骤,分别让B负责调制奶茶配料,再雇佣一个人去负责用设备制作奶茶,步骤变为A-\u0026gt;B-\u0026gt;C,在这个场景中增加C就是增加了Concurrent.\n现代语言的并发模型 现代语言支持并发模型一般会在操作系统线程和应用程序之间增加一层,在这层中使用预先分配的线程池和调度器来实现应用程序的并发能力.如在Go语言中称为协程(Coroutine). Go语言的并发模型如下: G—Goroutine M—OS thread (stands for machine) P—CPU core (stands for processor) 默认情况每一个CPU核心(P)里面会有一个线程(M),每个线程会不断切换去运行协程(G).\nSwift语言的并发模型,同样也是在操作系统线程和应用程序之间增加了一层.稍有不同的是他通过把代码划分为逻辑单元称为局部任务(Partial Tasks),通过调度器把局部任务分配到线程池不同的线程运行来实现并发能力. 现代语言中支持并发的语言特性 那么在这些语言中怎么支持并发的呢？这里我们举例三个场景:\n场景1: 增加Parallel,就是我们前面说的第一个方案增加另一个人和B一起负责调制奶茶配料和用设备制作奶茶 Go实现\nfunc taskA() int {\rtime.Sleep(2 * time.Second)\rreturn 5\r}\rfunc parallelExample() int {\rc := make(chan int)\rgo func() {\rc \u0026lt;- taskA()\r}()\rgo func() {\rc \u0026lt;- taskA()\r}()\rr1 := \u0026lt;-c\rr2 := \u0026lt;-c\rreturn r1 + r2\r} Swift实现\nfunc taskA() async -\u0026gt; Int {\rtry! await Task.sleep(for: .seconds(2))\rreturn 5\r}\rfunc parallelExample() async -\u0026gt; Int {\rasync let resultA = taskA()\rasync let resultB = taskA()\rlet r1 = await resultA\rlet r2 = await resultB\rreturn r1 + r2\r} 场景2: 增加Concurrent,另一个方案把原步骤拆分为两个步骤由两个人去操作 Go实现\nfunc taskA1() int {\rtime.Sleep(2 * time.Second)\rreturn 5\r}\rfunc taskB1(a1 int) int {\rtime.Sleep(1 * time.Second)\rreturn a1 + 2\r}\rfunc concurrentExample() int {\rc := make(chan int, 3)\rrc := make(chan int)\rgo func() {\rfor range 5 {\rc \u0026lt;- taskA1()\r}\r}()\rgo func() {\rfor range 5 {\rr1 := \u0026lt;-c\rrc \u0026lt;- taskB1(r1)\r}\r}()\rresult := 0\rfor range 5 {\rresult += \u0026lt;-rc\r}\rreturn result\r} Swift实现\nfunc taskA1() async -\u0026gt; Int {\rtry! await Task.sleep(for: .seconds(2))\rreturn 5\r}\rfunc taskB1(a1: Int) async -\u0026gt; Int {\rtry! await Task.sleep(for: .seconds(2))\rreturn a1 + 2\r}\rfunc concurrentExample() async -\u0026gt; Int {\rvar result = 0\rlet taskCount = 5\rlet taskAStream = AsyncStream\u0026lt;Int\u0026gt; { continuation in\rTask {\rfor _ in 0..\u0026lt;taskCount {\rlet taskAResult = await taskA1()\rcontinuation.yield(taskAResult) // Yield the result as soon as it\u0026#39;s ready\r}\rcontinuation.finish() // Finish the stream when all taskA1 are done\r}\r}\rfor await a1 in taskAStream {\rlet b1Result = await taskB1(a1: a1)\rresult += b1Result\r}\rreturn result\r} 场景3:先Parallel再Concurrent,即增加人去调制奶茶,同时也增加步骤让不同的人分别负责调制奶茶和用设备制作奶茶 Go实现\nfunc taskA2() int {\rtime.Sleep(2 * time.Second)\rreturn 5\r}\rfunc taskB2(a1 int) int {\rtime.Sleep(1 * time.Second)\rreturn a1 + 2\r}\rfunc parallelWithConcurrentExample() int {\rc := make(chan int, 3)\rrc := make(chan int)\rgo func() {\rfor range 5 {\rc \u0026lt;- taskA1()\r}\r}()\rgo func() {\rfor range 5 {\rc \u0026lt;- taskA1()\r}\r}()\rgo func() {\rfor range 10 {\rr1 := \u0026lt;-c\rrc \u0026lt;- taskB1(r1)\r}\r}()\rresult := 0\rfor range 10 {\rresult += \u0026lt;-rc\r}\rreturn result\r} Swift实现\nfunc taskA2() async -\u0026gt; Int {\rtry! await Task.sleep(for: .seconds(2))\rreturn 5\r}\rfunc taskB2(a1: Int) async -\u0026gt; Int {\rtry! await Task.sleep(for: .seconds(2))\rreturn a1 + 2\r}\rfunc parallelWithConcurrentExample() async -\u0026gt; Int {\rvar result = 0\rlet taskCount = 5\rlet streamCount = 2\rlet taskAStream = AsyncStream\u0026lt;Int\u0026gt; { continuation in\rvar c = 0\rTask {\rfor _ in 0..\u0026lt;taskCount {\rlet taskA2Result = await taskA2()\rcontinuation.yield(taskA2Result) // Yield the result as soon as it\u0026#39;s ready\r}\rc += 1\rif c == 2 {\rcontinuation.finish()\r}// Finish the stream when all taskA1 are done\r}\rTask {\rfor _ in 0..\u0026lt;taskCount {\rlet taskA2Result = await taskA2()\rcontinuation.yield(taskA2Result) // Yield the result as soon as it\u0026#39;s ready\r}\rc += 1\rif c == 2 {\rcontinuation.finish() // Finish the stream when all taskA1 are done\r}\r}\r}\rfor await a1 in taskAStream {\rlet b2Result = await taskB2(a1: a1)\rresult += b2Result\r}\rreturn result\r} 这样我们就完成了现代语言怎样支持Parallel和Concurrent的介绍.\n","permalink":"https://kmnemon.github.io/posts/2025-01-02-parallel-concurrent/","summary":"\u003ch1 id=\"parallel和concurrent\"\u003eParallel和Concurrent\u003c/h1\u003e\n\u003cp\u003e我们先来回顾一下概念:\nParallel是指同时执行多个任务或计算.通常在多核或多处理器的硬件上并行执行多个操作,每个操作独立运行,并且是同步的(并行的任务在同一时刻发生).并行计算的目标是通过同时使用多个计算资源来加速程序的执行.\u003c/p\u003e\n\u003cp\u003eConcurrent是指系统在同一时间段内处理多个任务的能力.并发并不意味着任务是同时执行的,而是任务在某一时刻轮流执行.\u003c/p\u003e\n\u003cp\u003e举个例子就更容易理解：\n你有一个奶茶店,制作奶茶需要三个步骤,分别是收银,调制奶茶配料和用设备制作奶茶.假设现在有两个角色,A负责收银,B负责调制奶茶配料和用设备制作奶茶.整个步骤是A-\u0026gt;B.作为店主你很快发现A收银很快,B调制配料和制作奶茶很慢造成了瓶颈,这是你选择解决方案是再雇佣了另外一个人和B一起负责调制奶茶配料和用设备制作奶茶,现在整个步骤是A-\u0026gt;B1 or B2.在这个场景中增加B2就是我们说的Parallel.当然你还可以用另一个方案解决,把原步骤调制奶茶配料和用设备制作奶茶拆分为两个步骤,分别让B负责调制奶茶配料,再雇佣一个人去负责用设备制作奶茶,步骤变为A-\u0026gt;B-\u0026gt;C,在这个场景中增加C就是增加了Concurrent.\u003c/p\u003e\n\u003ch1 id=\"现代语言的并发模型\"\u003e现代语言的并发模型\u003c/h1\u003e\n\u003cp\u003e现代语言支持并发模型一般会在操作系统线程和应用程序之间增加一层,在这层中使用预先分配的线程池和调度器来实现应用程序的并发能力.如在Go语言中称为协程(Coroutine).\nGo语言的并发模型如下:\n\u003cimg loading=\"lazy\" src=\"/images/2025-01-02-parallel-concurrent/go-concurrency-model.png\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eG—Goroutine\u003c/li\u003e\n\u003cli\u003eM—OS thread (stands for machine)\u003c/li\u003e\n\u003cli\u003eP—CPU core (stands for processor)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e默认情况每一个CPU核心(P)里面会有一个线程(M),每个线程会不断切换去运行协程(G).\u003c/p\u003e\n\u003cp\u003eSwift语言的并发模型,同样也是在操作系统线程和应用程序之间增加了一层.稍有不同的是他通过把代码划分为逻辑单元称为局部任务(Partial Tasks),通过调度器把局部任务分配到线程池不同的线程运行来实现并发能力.\n\u003cimg loading=\"lazy\" src=\"/images/2025-01-02-parallel-concurrent/partialtask.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"现代语言中支持并发的语言特性\"\u003e现代语言中支持并发的语言特性\u003c/h1\u003e\n\u003cp\u003e那么在这些语言中怎么支持并发的呢？这里我们举例三个场景:\u003c/p\u003e\n\u003ch3 id=\"场景1-增加parallel就是我们前面说的第一个方案增加另一个人和b一起负责调制奶茶配料和用设备制作奶茶\"\u003e场景1: 增加Parallel,就是我们前面说的第一个方案增加另一个人和B一起负责调制奶茶配料和用设备制作奶茶\u003c/h3\u003e\n\u003cp\u003eGo实现\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efunc taskA() int {\r\n    time.Sleep(2 * time.Second)\r\n    return 5\r\n}\r\n\r\nfunc parallelExample() int {\r\n    c := make(chan int)\r\n\r\n    go func() {\r\n        c \u0026lt;- taskA()\r\n    }()\r\n    go func() {\r\n        c \u0026lt;- taskA()\r\n    }()\r\n\r\n    r1 := \u0026lt;-c\r\n    r2 := \u0026lt;-c\r\n\r\n    return r1 + r2\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSwift实现\u003c/p\u003e","title":"现代语言怎么支持Parallel和Concurrent"},{"content":"@State 用途 struct 1.私有的View State，使用当前View维护状态生命周期 2.保持struct不可变性的同时修改内部变量值\nclass 1.私有的View State，使用当前View维护状态生命周期\n使用方式 struct Counter: View {\r@State private var value = 0\rvar body: some View {\rButton(\u0026#34;Increment: \\(value)\u0026#34;) {\rvalue += 1\r}\r}\r} 内部实现 struct Counter: View {\rprivate var _value = State(initialValue: 0)\rprivate var value: Int {\rget { _value.wrappedValue }\rnonmutating set { _value.wrappedValue = newValue }\r}\rvar body: some View {\rButton(\u0026#34;Increment: \\(value)\u0026#34;) {\rvalue += 1\r}\r}\r} SwiftUI给value state在render tree里面分配内存并赋予initialValue:0，并建立链接使value指向这个内存值 Counter\u0026rsquo;s body依赖这个内存值，一旦内存值变化会重新构建Counter\u0026rsquo;s body.\n@Observable 用途 1.给Object增加Observable marker protocol 2.追踪Object\u0026rsquo;s properties的读和写\n使用方式 1.使用CounterView管理model生命周期\n@Observable final class Model {\rvar value = 0\r}\rstruct Counter: View {\r@State private var model = Model()\rvar body: some View {\rButton(\u0026#34;Increment: \\(model.value)\u0026#34;) {\rmodel.value += 1\r}\r}\r} 2.外部传递，由外部对象管理生命周期\n@Observable final class Model {\rvar value = 0\rstatic let shared = Model()\r}\rstruct Counter: View {\rvar model: Model\rvar body: some View {\rButton(\u0026#34;Increment: \\(model.value)\u0026#34;) {\rmodel.value += 1\r}\r}\r}\rstruct ContentView: View {\rvar body: some View {\rCounter(model: Model.shared)\r}\r} 内部实现 @Observable final class Model {\rvar value = 0 {\rget {\raccess(keyPath: \\.value )\rreturn _value\r}\rset {\rwithMutation(keyPath: \\.value ) {\r_value = newValue\r}\r}\r}\r@ObservationIgnored private var _value = 0\r//…\r}\r//展开access和withMutatio\r@Observable final class Model {\r//…\r@ObservationIgnored private let _$observationRegistrar = ObservationRegistrar()\rinternal nonisolated func access\u0026lt;Member\u0026gt;(keyPath: KeyPath\u0026lt;Model , Member\u0026gt;) {\r_$observationRegistrar.access(self, keyPath: keyPath)\r}\rinternal nonisolated func withMutation\u0026lt;Member, T\u0026gt;(\rkeyPath: KeyPath\u0026lt;Model , Member\u0026gt;,\r_ mutation: () throws -\u0026gt; T\r) rethrows -\u0026gt; T {\rtry _$observationRegistrar.withMutation(of: self, keyPath: keyPath, mutation)\r}\r} access和withMutation两个方法会被observationRegistrar调用. registrar负责保持observers订阅的properties，并通知observers这些properties的变化. SwiftUI有个withObservationTracking(_ apply:onChange:)全局函数. 其中apply闭包会立即执行，帮助observation订阅对象. onChange闭包是observer，当observable properties变化时被调用.\napply调用后，object的accessd properties和observer闭包，建立关联性.\n类似如下：\nwithObservationTracking {\rview.body\r} onChange: {\rview.needsUpdate()\r} 上述代码表示任何view.body内的observable property都通过object\u0026rsquo;s observation registrar注册.并将property和当前view.body形成关联关系.\n@Binding 用途 1.确保app的状态一致性，每个状态都有一个单一源(source of truth) 2.property从外面传递进来\n使用方式 struct Counter: View {\r@Binding var value: Int\rvar body: some View {\rButton(\u0026#34;Increment: \\(value)\u0026#34;) { value += 1 }\r}\r}\rstruct ContentView: View {\r@State private var value = 0\rvar body: some View {\rCounter(value: $value)\r}\r} 内部实现 //1.简单实现\rstruct Counter: View {\rvar value: Int\rvar setValue: (Int) -\u0026gt; ()\rvar body: some View {\rButton(\u0026#34;Increment: \\(value)\u0026#34;) { setValue(value + 1) }\r}\r}\rstruct ContentView: View {\r@State private var value = 0\rvar body: some View {\rCounter(value: value, setValue: { value = $0 })\r}\r}\r//2.使用Binding类型\rstruct Counter: View {\rvar value: Binding\u0026lt;Int\u0026gt;\rvar body: some View {\rButton(\u0026#34;Increment: \\(value.wrappedValue)\u0026#34;) {\rvalue.wrappedValue += 1\r}\r}\r}\r//使用computed value 简化使用，避免直接调用wrappedValue\rstruct Counter: View {\rvar _value: Binding\u0026lt;Int\u0026gt;\rvar value: Int {\rget { _value.wrappedValue }\rset { _value.wrappedValue = newValue }\r}\rinit(value: Binding\u0026lt;Int\u0026gt;) {\rself._value = value\r}\rvar body: some View {\rButton(\u0026#34;Increment: \\(value)\u0026#34;) { value += 1 }\r}\r}\rstruct ContentView: View {\r@State private var value = 0\rvar body: some View {\rCounter(value: Binding(get: { value }, set: { value = $0 }))\r}\r} 在ContentView里面set:把 $0和@State private property value关联起来，当Counter里面使用$0改变value值，会导致Counter view被重新构建 前面使用$value,是取用@State property的projectedValue($是取用property wrapper\u0026rsquo;s projectedValue的语法糖), 该projectedValue实现Binding(get: { value }, set: { value = $0 }),实现如下:\nstruct ContentView: View {\rprivate var _value = State(initialValue: 0)\rprivate var value: Int {\rget { _value.wrappedValue }\rset { _value.wrappedValue = newValue }\r}\rvar body: some View {\rCounter(value: _value.projectedValue)\r}\r} @Bindable 用途 1.解决Observable Object没有使用@State warpper,因此没有projectedValue,无法使用$value进行唯一源绑定,如下示例使用Bindable可以直接传递model对象进Counter 2.@Binable 构建了projectedValue, 如下例可以在Counter里面使用$语法糖进行object property的绑定\n使用方式 1.使用property wrapper\n@Observable final class Model {\rvar value = 0\rstatic let shared = Model()\r}\rstruct Counter: View {\r@Bindable var model: Model\rvar body: some View {\rStepper(\u0026#34;\\(model.value)\u0026#34;, value: $model.value)\r}\r}\rstruct ContentView: View {\rvar model = Model.shared\rvar body: some View {\rCounter(model: model)\r}\r} 2.使用inline方式\nstruct ContentView: View {\rvar model = Model.shared\rvar body: some View {\rStepper(\u0026#34;\\(model.value)\u0026#34;, value: Bindable(model).value)\r}\r} 不使用Counter View,直接使用Bindable(model).value建立联接\n内部实现 struct Counter: View {\rvar _model: Bindable\u0026lt;Model\u0026gt;\rvar model: Model { _model.wrappedValue }\rinit(model: Model) {\r_model = Bindable(wrappedValue: model)\r}\rvar body: some View {\rStepper(\u0026#34;\\(model.value)\u0026#34;, value: _model.projectedValue[dynamicMember: \\.value])\r}\r} 使用动态成员查找语法projectedValue[dynamicMember: .value],查找需要修改的object property\n怎么选择 优先选择不使用任何property wrapper,如果我们只是传递值给view, view并不需要改变这个值 关于value,如果view需要改变这个值,view自己管理对象使用@State,由外部传入使用@Binding 关于object,view自己管理对象使用@State, @Observable, 如果由外部传入使用@Observable 关于object由外部传入使用@Observable, 还想进行后续使用$进行关联,还需使用@Bindable ","permalink":"https://kmnemon.github.io/posts/2024-11-29-state-binding-bindable/","summary":"\u003ch1 id=\"state\"\u003e@State\u003c/h1\u003e\n\u003ch3 id=\"用途\"\u003e用途\u003c/h3\u003e\n\u003cp\u003estruct\n1.私有的View State，使用当前View维护状态生命周期\n2.保持struct不可变性的同时修改内部变量值\u003c/p\u003e\n\u003cp\u003eclass\n1.私有的View State，使用当前View维护状态生命周期\u003c/p\u003e\n\u003ch3 id=\"使用方式\"\u003e使用方式\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003estruct Counter: View {\r\n    @State private var value = 0\r\n\r\n    var body: some View {\r\n        Button(\u0026#34;Increment: \\(value)\u0026#34;) {\r\n            value += 1\r\n        }\r\n    }\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"内部实现\"\u003e内部实现\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003estruct Counter: View {\r\n    private var _value = State(initialValue: 0)\r\n    private var value: Int {\r\n        get { _value.wrappedValue }\r\n        nonmutating set { _value.wrappedValue = newValue }\r\n    }\r\n\r\n    var body: some View {\r\n        Button(\u0026#34;Increment: \\(value)\u0026#34;) {\r\n            value += 1\r\n        }\r\n    }\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSwiftUI给value state在render tree里面分配内存并赋予initialValue:0，并建立链接使value指向这个内存值\nCounter\u0026rsquo;s body依赖这个内存值，一旦内存值变化会重新构建Counter\u0026rsquo;s body.\u003c/p\u003e","title":"SwiftUI @State、@Observable、@Binding、@Bindable实现原理"},{"content":"近段时间编程语言开始往安全方面进行发展，类型安全，内存安全，并发安全等，如新兴的Rust语言，Swift 6.0都在安全性上发力，并都在编译器方面下功夫，添加了诸多规则，当你和编译器战斗通过后，理论上你的代码具备某种程度的安全性。\n这类安全性同时也影响着语言的发展，比如在面向接口编程中Swift语言里面对于接口还增加了some和any两个关键字，一时让我疑惑不解，其他语言没有这类概念为啥这个语言需要，他想要解决了什么问题？然后又引入两个类型概念Opaque Types和Boxed Protocol Types。\n官方文档描述如下：\n\u0026ldquo;You can think of an opaque type like being the reverse of a generic type. \u0026hellip; An opaque type lets the function implementation pick the type for the value it returns in a way that’s abstracted away from the code that calls the function. \u0026hellip; An opaque type refers to one specific type, although the caller of the function isn’t able to see which type\u0026rdquo;\n看的云里雾里不知道要干嘛，这些描述不是就是接口要达到的效果吗，让模块外调用者不用知道模块内部细节类型，通过接口抽象进行调用。经过一番探索发现其实Opaque Types是让编译器增加了一层保护机制，由编译器进行检查让返回的接口类型保持底层类型的一致性。这样说还是太抽象举个例子就明白了。\nprotocol Fighter: Equatable {}\rstruct XWing: Fighter {}\rstruct YWing: Fighter {}\rfunc lanchXFighter() -\u0026gt; some Fighter {return XWing()}\rfunc lanchYFighter() -\u0026gt; some Fighter {return YWing()}\rfunc compareFighter() { let x = lanchXFighter() let x2 = lanchXFighter() let y = lanchYFighter() if x == x2 { print(\u0026#34;x == y\u0026#34;) {\r}\r//do not compile if x == y {\r}\r} 这里我们写两个方法通过接口返回这两个不同的类型，因为这两个类型实现的同样的接口Fighter。compareFighter方法想通过接口类型去比较前两个方法返回的类型是否一致。 在lanchXFighter返回增加了some关键字表示返回的是Opaque类型，因此编译器会记录实际的底层类型用于检查。 在compareFighter通过返回的接口类型比较的时候，如果接口的底层类型不一致，那么在编译阶段就会不通过，比如上面代码想比较“x == y”，因为x的底层类型是XWing，y的底层类型是YWing。所以在编译时期进行检查不通过。 这个就是some关键字和Opaque带来的编译时期的安全性。\n那么其他语言是怎么设计的呢？比如简洁的Go语言没有这个关键字。同样的代码如下：\nfunc lanchXFighter() Fighter { return XWing{}\r}\rfunc lanchYFighter() Fighter { return YWing{}\r}\rfunc compareFighter() { x := lanchXFighter() x1 := lanchXFighter() y := lanchYFighter()\rif x == x1 { fmt.Println(\u0026#34;x == x1\u0026#34;) }\rif x == y { fmt.Println(\u0026#34;x == y\u0026#34;) }\r} Go语言设计并没提供编译时期底层类型的检查，编译直接通过，在运行期如果类型不一致比较直接返回不一致。\n个人不喜欢编译时期检查过多，原本思路很清晰的代码，结果编译还报错，你还要花时间费劲和编译器斗争，最后编译通过，证明了你的代码是安全的。同时为了帮助编译器检查增加过多的关键字，也增加了程序员认知负担。作为程序员应该具备写清晰代码的能力，自己去保证比如底层类型的一致性等问题，这样才能写出更加流畅清晰的代码逻辑。\n","permalink":"https://kmnemon.github.io/posts/2024-11-19-does-compilor-do-to-much/","summary":"\u003cp\u003e近段时间编程语言开始往安全方面进行发展，类型安全，内存安全，并发安全等，如新兴的Rust语言，Swift 6.0都在安全性上发力，并都在编译器方面下功夫，添加了诸多规则，当你和编译器战斗通过后，理论上你的代码具备某种程度的安全性。\u003c/p\u003e\n\u003cp\u003e这类安全性同时也影响着语言的发展，比如在面向接口编程中Swift语言里面对于接口还增加了some和any两个关键字，一时让我疑惑不解，其他语言没有这类概念为啥这个语言需要，他想要解决了什么问题？然后又引入两个类型概念Opaque Types和Boxed Protocol Types。\u003c/p\u003e\n\u003cp\u003e官方文档描述如下：\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;You can think of an opaque type like being the reverse of a generic type. \u0026hellip; An opaque type lets the function implementation pick the type for the value it returns in a way that’s abstracted away from the code that calls the function. \u0026hellip; An opaque type refers to one specific type, although the caller of the function isn’t able to see which type\u0026rdquo;\u003c/em\u003e\u003c/p\u003e","title":"编译器是否帮我们做的过多？"},{"content":"类似枪械有手动步枪-M1903春田，半自动步枪-M1，自动步枪-M16之分，程序语言的内存管理也有手动、半自动和全自动三种方式。手动内存管理的代表语言：C、C++，半自动内存管理的代码语言：Modern C++，Swift，Rust，全自动的代表语言：Java，C#，Go，Python。本文通过不同程序语言来描述三种内存管理方式，以及如何应对循环引用的典型场景。\n手动内存管理： 为了实现代码的极致效率以及灵活性C和C++语言采用了手动内存管理方式，通过自己编写代码实现堆上的内存分配与回收。\n//C++代码示例\rexport class Manual {\rpublic:\rManual(int s) :elem{ new double[s] }, sz{ s } {}\r~Manual() {\rdelete[] elem;\r}\rprivate:\rdouble* elem;\rint sz;\r}; 半自动内存管理： 内存泄漏是手动内存管理遇到最大的挑战，在复杂的场景下可能出现分配的内存没有释放，导致程序在特殊的情况下内存耗尽停止工作。为了保证内存安全，新一代语言为了不牺牲效率采用编译时期来分析内存的分配与释放，典型的方式是自动引用计数（Automatic Reference Counting ）\n//swift代码示例\rclass ARC {\r}\rfunc usingARC() {\rvar ref1: ARC? = ARC()\rvar ref2: ARC? = ref1\rref1 = nil\rref2 = nil\r//ref1、ref2 已释放\r} //Modern C++\rexport class SmartPointers {\rpublic:\r//represents unique ownership (its destructor destroys its object)\rvoid uniquePtr() {\rstd::unique_ptr\u0026lt;X\u0026gt; sp{ new X };\rstd::unique_ptr\u0026lt;X\u0026gt; sp3 = std::make_unique\u0026lt;X\u0026gt;();\rstd::unique_ptr\u0026lt;X\u0026gt; sp2 = std::move(sp);\r}\r//represents shared ownership (the last shared pointer¡¯s destructor destroys the object)\rvoid sharedPtr() {\rstd::shared_ptr\u0026lt;X\u0026gt; sp = std::make_shared\u0026lt;X\u0026gt;();\rstd::shared_ptr\u0026lt;X\u0026gt; sp2 = sp;\rsp.reset();\rsp2.reset();\r}\r//A pointer to an object owned by a shared_ptr\rvoid weakPtr() {\rstd::shared_ptr\u0026lt;X\u0026gt; sharedPtr = std::make_shared\u0026lt;X\u0026gt;();\r// Creating a weak pointer from the shared pointer\rstd::weak_ptr\u0026lt;X\u0026gt; weakPtr = sharedPtr;\r// Using the weak pointer to access the object\rif (auto ptr = weakPtr.lock()) {\r}\relse {\rstd::cout \u0026lt;\u0026lt; \u0026#34;Weak pointer is expired.\u0026#34; \u0026lt;\u0026lt; std::endl;\r}\r// Resetting the shared pointer\rsharedPtr.reset();\r// Using the weak pointer again after resetting the shared pointer\rif (auto ptr = weakPtr.lock()) {\r}\relse {\rstd::cout \u0026lt;\u0026lt; \u0026#34;Weak pointer is expired.\u0026#34; \u0026lt;\u0026lt; std::endl;\r}\r}\r}; 全自动内存管理： 同样保证内存安全，同时减少内存管理心智负担，还有一种全自动内存管理-垃圾回收机制（GC）。但这种方式引入了臭名昭著的STOP THE WORLD。\n//Go代码示例\rtype Automate struct {\r}\rfunc usingGC() {\ra := Automate{}\rfmt.Println(a)\r} 循环引用问题： 两个类的成员相互引用对方，导致内存分配永远无法释放。\nclass A {\rvar b: B?\r}\rclass B {\rvar a: A?\r}\rfunc rc() {\rvar ca: A? = A()\rvar cb: B? = B()\rca!.b = cb\rcb!.a = ca\rca = nil\rcb = nil\r//ca、cb并未释放\r} 该场景其实是半自动内存管理引入的问题，因为手动内存管理不管有没有循环引用只要代码进行delete就会释放内存，而全自动内存管理会自己分析出循环引用在GC的时候释放掉相应的内存。\n半自动内存管理这方面加重了程序员的心智负担，需要开发者分析出循环引用场景，并采用弱引用的方式打破循环引用。\n//通过引入weak弱引用关键字来解决循环引用问题\rclass Person {\rvar apartment: Apartment?\rdeinit { print(\u0026#34;Person deinit\u0026#34;) }\r}\rclass Apartment {\rweak var tenant: Person?\rdeinit { print(\u0026#34;Apartment deinit\u0026#34;) }\r}\rfunc weakReference() {\rvar tom: Person? = Person()\rvar apartment: Apartment? = Apartment()\rtom?.apartment = apartment\rapartment?.tenant = tom\rtom = nil\r//Person deinit\rapartment = nil\r//Apartment deinit\r} ","permalink":"https://kmnemon.github.io/posts/2024-03-26-do-not-stop-the-world/","summary":"\u003cp\u003e类似枪械有手动步枪-M1903春田，半自动步枪-M1，自动步枪-M16之分，程序语言的内存管理也有手动、半自动和全自动三种方式。手动内存管理的代表语言：C、C++，半自动内存管理的代码语言：Modern C++，Swift，Rust，全自动的代表语言：Java，C#，Go，Python。本文通过不同程序语言来描述三种内存管理方式，以及如何应对循环引用的典型场景。\u003c/p\u003e\n\u003ch1 id=\"手动内存管理\"\u003e手动内存管理：\u003c/h1\u003e\n\u003cp\u003e为了实现代码的极致效率以及灵活性C和C++语言采用了手动内存管理方式，通过自己编写代码实现堆上的内存分配与回收。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e//C++代码示例\r\nexport class Manual {\r\npublic:\r\n  Manual(int s) :elem{ new double[s] }, sz{ s } {}\r\n\r\n  ~Manual() {\r\n    delete[] elem;\r\n  }\r\n\r\nprivate:\r\n  double* elem;\r\n  int sz;\r\n};\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"半自动内存管理\"\u003e半自动内存管理：\u003c/h1\u003e\n\u003cp\u003e内存泄漏是手动内存管理遇到最大的挑战，在复杂的场景下可能出现分配的内存没有释放，导致程序在特殊的情况下内存耗尽停止工作。为了保证内存安全，新一代语言为了不牺牲效率采用编译时期来分析内存的分配与释放，典型的方式是自动引用计数（Automatic Reference Counting ）\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e//swift代码示例\r\nclass ARC {\r\n    \r\n}\r\n\r\nfunc usingARC() {\r\n    var ref1: ARC? = ARC()\r\n    var ref2: ARC? = ref1\r\n\r\n    ref1 = nil\r\n    ref2 = nil\r\n    //ref1、ref2 已释放\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e//Modern C++\r\nexport class SmartPointers {\r\npublic:\r\n  //represents unique ownership (its destructor destroys its object)\r\n  void uniquePtr() {\r\n    std::unique_ptr\u0026lt;X\u0026gt; sp{ new X };\r\n    std::unique_ptr\u0026lt;X\u0026gt; sp3 = std::make_unique\u0026lt;X\u0026gt;();\r\n\r\n    std::unique_ptr\u0026lt;X\u0026gt; sp2 = std::move(sp);\r\n  }\r\n\r\n  //represents shared ownership (the last shared pointer¡¯s destructor destroys the object)\r\n  void sharedPtr() {\r\n    std::shared_ptr\u0026lt;X\u0026gt; sp = std::make_shared\u0026lt;X\u0026gt;();\r\n    std::shared_ptr\u0026lt;X\u0026gt; sp2 = sp;\r\n\r\n    sp.reset();\r\n    sp2.reset();\r\n  }\r\n\r\n  //A pointer to an object owned by a shared_ptr\r\n  void weakPtr() {\r\n    std::shared_ptr\u0026lt;X\u0026gt; sharedPtr = std::make_shared\u0026lt;X\u0026gt;();\r\n\r\n    // Creating a weak pointer from the shared pointer\r\n    std::weak_ptr\u0026lt;X\u0026gt; weakPtr = sharedPtr;\r\n\r\n    // Using the weak pointer to access the object\r\n    if (auto ptr = weakPtr.lock()) {\r\n    }\r\n    else {\r\n      std::cout \u0026lt;\u0026lt; \u0026#34;Weak pointer is expired.\u0026#34; \u0026lt;\u0026lt; std::endl;\r\n    }\r\n\r\n    // Resetting the shared pointer\r\n    sharedPtr.reset();\r\n\r\n    // Using the weak pointer again after resetting the shared pointer\r\n    if (auto ptr = weakPtr.lock()) {\r\n    }\r\n    else {\r\n      std::cout \u0026lt;\u0026lt; \u0026#34;Weak pointer is expired.\u0026#34; \u0026lt;\u0026lt; std::endl;\r\n    }\r\n  }\r\n};\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"全自动内存管理\"\u003e全自动内存管理：\u003c/h1\u003e\n\u003cp\u003e同样保证内存安全，同时减少内存管理心智负担，还有一种全自动内存管理-垃圾回收机制（GC）。但这种方式引入了臭名昭著的STOP THE WORLD。\u003c/p\u003e","title":"程序语言中内存管理-DO NOT STOP THE WORLD"},{"content":" 自从AI统治了世界，编成语言宝座一直由Python占据，但近几年编程语言热度排名变化，让我感到有些奇怪。 在TIOBE中23年不出意外C#成为年度语言，22年年度语言C++，Java跌出前三，24年很可能被C#反超，Rust进入前20。\n同时这几年新一代语言层出不穷，Mojo在AI领域挑战python，名不见经传的zig语言写出个Bun准备在js领域掀起浪花，Rust对C++发起冲击多年。不禁在想老一代语言除了生态的保护，还有什么能应对新一代语言的挑战。\nC++98,03是C++的黄金时代，后来随着Java，C#成长发展，C++领域逐渐萎缩。处境一度变得十分尴尬，在企业级市场Java解决了内存管理问题变得流行，在嵌入式领域C语言有简单性和性能上的优势，还剩下游戏领域的引擎部分还是C++一家独大。\n当时C++遇到的问题：\n复杂性，太过于复杂导致编码的认知复杂度太高，C++是一把屠龙宝刀，威力太大，用好他需要专业程序员，多年的沉淀，特别10倍程序员，市场上这类人才太少，中国企业大多急功近利不愿培养。 内存泄漏，内存安全问题突出。在复杂业务逻辑下，遗漏内存释放，程序长时间运行后崩溃，定位这类问题难度很大。 标准库不完善，三方库种类繁多，不像Java的Spring全家桶，不同的程序，用不同的三方库，维护困难。你想象一下几十年的语言还没有统一的并发库就知道了。所以像腾讯这类使用C++为主都需要自建所有的基础库。 但为什么近几年C++热度突然上升，我想可能是因为：\nAI火热，Python虽然是AI领域使用最广泛的语言，但一般用于模型训练这类，但AI的核心机器学习框架就只有C++能胜任了 C++自从03后加速发展，在进一步提升复杂度上一去不回，随后加入线程，协程，所有权，模块化等等等等，和Go语言设计理念完全相反 硬件摩尔定律失效，3nm技术再往下继续发展，投入成本和时间都急剧攀升，CPU单核频率提升到达瓶颈，市场又开始关注怎么充分利用有限的硬件资源 网上有人说C++03是“经典C++（classic）”，C++11开始是“现代C++（modern）”，那么C++吸取了哪些有意思的东西，准备折腾一番\n","permalink":"https://kmnemon.github.io/posts/2024-01-05-programming-monster-dance-copy/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2024-01-05-programming-monster-dance/tiobe.png\"\u003e\n自从AI统治了世界，编成语言宝座一直由Python占据，但近几年编程语言热度排名变化，让我感到有些奇怪。 在TIOBE中23年不出意外C#成为年度语言，22年年度语言C++，Java跌出前三，24年很可能被C#反超，Rust进入前20。\u003c/p\u003e\n\u003cp\u003e同时这几年新一代语言层出不穷，Mojo在AI领域挑战python，名不见经传的zig语言写出个Bun准备在js领域掀起浪花，Rust对C++发起冲击多年。不禁在想老一代语言除了生态的保护，还有什么能应对新一代语言的挑战。\u003c/p\u003e\n\u003cp\u003eC++98,03是C++的黄金时代，后来随着Java，C#成长发展，C++领域逐渐萎缩。处境一度变得十分尴尬，在企业级市场Java解决了内存管理问题变得流行，在嵌入式领域C语言有简单性和性能上的优势，还剩下游戏领域的引擎部分还是C++一家独大。\u003c/p\u003e\n\u003cp\u003e当时C++遇到的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e复杂性，太过于复杂导致编码的认知复杂度太高，C++是一把屠龙宝刀，威力太大，用好他需要专业程序员，多年的沉淀，特别10倍程序员，市场上这类人才太少，中国企业大多急功近利不愿培养。\u003c/li\u003e\n\u003cli\u003e内存泄漏，内存安全问题突出。在复杂业务逻辑下，遗漏内存释放，程序长时间运行后崩溃，定位这类问题难度很大。\u003c/li\u003e\n\u003cli\u003e标准库不完善，三方库种类繁多，不像Java的Spring全家桶，不同的程序，用不同的三方库，维护困难。你想象一下几十年的语言还没有统一的并发库就知道了。所以像腾讯这类使用C++为主都需要自建所有的基础库。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e但为什么近几年C++热度突然上升，我想可能是因为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAI火热，Python虽然是AI领域使用最广泛的语言，但一般用于模型训练这类，但AI的核心机器学习框架就只有C++能胜任了\u003c/li\u003e\n\u003cli\u003eC++自从03后加速发展，在进一步提升复杂度上一去不回，随后加入线程，协程，所有权，模块化等等等等，和Go语言设计理念完全相反\u003c/li\u003e\n\u003cli\u003e硬件摩尔定律失效，3nm技术再往下继续发展，投入成本和时间都急剧攀升，CPU单核频率提升到达瓶颈，市场又开始关注怎么充分利用有限的硬件资源\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e网上有人说C++03是“经典C++（classic）”，C++11开始是“现代C++（modern）”，那么C++吸取了哪些有意思的东西，准备折腾一番\u003c/p\u003e","title":"编程语言，群魔乱舞的时代"},{"content":"Java的Stream编程 自从Java 8将函数式编程引入语言后，该语言通过Lambda表达式和Stream库两者的结合，展现了全新的编码方式。实现了简洁，高效，以及类似声明式的编码风格。\n举个例子，如我们有个集合里面存放的是颜色的标签，我们想在集合中找出以“b”字符开头的标签，并进行排序，然后转换成大写字符标签，最后输出。如果用Java 8以前的编码方式，我们会进行多次轮询，最后输出结果：\npublic static void main(String[] args) {\rList\u0026lt;String\u0026gt; colors = Arrays.asList(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;brown\u0026#34;, \u0026#34;grey\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;beige\u0026#34;, \u0026#34;purple\u0026#34;);\rList\u0026lt;String\u0026gt; filteredAndSortedColors = new ArrayList\u0026lt;\u0026gt;();\rfor (String color : colors) {\rif (color.startsWith(\u0026#34;b\u0026#34;)) {\rfilteredAndSortedColors.add(color);\r}\r}\rCollections.sort(filteredAndSortedColors);\rfor (String color : filteredAndSortedColors) {\rSystem.out.println(color.toUpperCase());\r}\r} 如果用Java 8的Lambda、Stream来实现，则代码会更加简洁、易懂，执行效率也会提高：\npublic static void main(String args[]) {\rStream.of(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;brown\u0026#34;, \u0026#34;grey\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;beige\u0026#34;, \u0026#34;purple\u0026#34;)\r.filter(s -\u0026gt; s.startsWith(\u0026#34;b\u0026#34;))\r.sorted()\r.map(s -\u0026gt; s.toUpperCase())\r.forEach(System.out::println);\r} Go的Stream编程 go语言中函数是第一公民，理论上我们可以实现更简洁的Stream框架。Stream的核心有以下几个方面：\n基于流的操作 支持并行计算 声明式编程风格 基于流的操作 是指数据不断流入，对每个数据依次执行相应的操作并得到最后结果，然后再处理下一个数据，直到所有数据处理完成，最终程序结束。举例说明比较直观，我们有数据集Z，对应操作A，B，C。以前我们对数据的处理方式是对整个数据集Z进行遍历执行操作A得到数据集Z1，然后再对数据集Z1进行遍历执行操作B得到Z2，遍历Z2执行操作C得到最后结果Z3，这里我们有多少操作就需要遍历多少次。基于流的操作方式针对数据集只需遍历一次，对数据集Z进行遍历，对遍历到的第一个数据执行A、B、C三个操作，然后依次对后面的数据执行同样的操作，直至遍历完成。\n在实现中这里有两个难点：\n每个stage怎么连接起来，操作怎么连接起来？ 操作怎样惰性求值？ 在go stream的实现中，建立了一个pipeline结构体代表stage，这个结构体是一个双向链表同时指向前一个和后一个stage。在每个pipeline初始化的时候通过链表指针指向了前后的stage，这样就把所有操作的stage连接起来。\ntype pipeline[T any] struct {\rpreviousStage *pipeline[T]\rnextStage *pipeline[T]\rsourceStage *pipeline[T]\rdepth int\rstreamOpFlag stateType\rstreamSink sink[T]\rsourceData []T\r}\rfunc (p *pipeline[T]) init(previousStage *pipeline[T], opFlag stateType, sink sink[T]) {\rif opFlag == head {\rp.previousStage = nil\rp.sourceStage = p\rp.depth = 0\r} else {\rp.previousStage = previousStage\rp.previousStage.nextStage = p\rp.sourceStage = previousStage.sourceStage\rp.depth = p.previousStage.depth + 1\rp.streamSink = sink\r}\rp.streamOpFlag = opFlag\r} 那我们操作怎么惰性求值的呢？注意在pipeline结构体里面有个sink[T]接口，实现这个接口的结构体含有具体的操作。我们以map操作为例，map操作里的pipeline实现了mapSink[T any]这个结构体，结构体里面mapper函数就是具体对数据集里数据的操作。\ntype sink[T any] interface {\rbegin(int)\raccept(T)\rend()\risCancellationWasRequested() bool\rcancellationRequested() bool\rcanParallel() bool\rsetDownStreamSink(sink[T])\r}\rtype mapSink[T any] struct {\rmapper func(T) T\rdownstream sink[T]\r} 在最后一个stage里，我们会调用evaluate函数，这个函数会对所有的sink结构体进行叠加，这里只进行wrap操作，等所有sink都叠加完成后，调用copyInto函数遍历每个数据进行sink操作的真正执行。这样我们就完成了惰性求值。\nfunc (p *pipeline[T]) evaluate(s sink[T]) {\rp.copyInto(p.wrapSink(s), p.sourceStage.sourceData)\r}\rfunc (p *pipeline[T]) wrapSink(sink sink[T]) sink[T] {\rfor ; p.depth \u0026gt; 0; p = p.previousStage {\rsink = p.opWrapSink(sink)\r}\rreturn sink\r}\rfunc (p *pipeline[T]) copyInto(wrapSink sink[T], slice []T) {\r....\rwrapSink.begin(len(slice))\rif !wrapSink.isCancellationWasRequested() {\rfor _, v := range slice {\rwrapSink.accept(v)\r}\r} else {\rfor _, v := range slice {\rif wrapSink.cancellationRequested() {\rbreak\r}\rwrapSink.accept(v)\r}\r}\rwrapSink.end()\r} 支持并行计算 有了上面基于流的操作，以及go协程的强大，并行计算就采用协程来实现。在go stream中新增方法Parallel()来表示要对数据集进行并行计算。在并行计算中监测当前平台具备多少核心的CPU，通过把数据集按核心数等分，调用go协程并行执行流的操作来加快整个计算速度。\nfunc (s *parallelSink[T]) end() {\rif s.canparallel {\rvar wg sync.WaitGroup\rcores := runtime.NumCPU()\rfor _, slice := range splitSlice(s.list, cores) {\rwg.Add(1)\rgo func(slice []T) {\rdefer wg.Done()\rfor _, v := range slice {\rs.downstream.accept(v)\r}\r}(slice)\r}\rwg.Wait()\r}\rs.downstream.end()\r} 声明式编程风格 stream带来编程风格的转变，便是这种声明式的编程风格，你告诉程序需要对数据集进行什么样的操作，比如filter，sort，然后你再给它需要的规则filter里哪些特征的数据为true，sort里数据大小比较规则等，不用关注内部算法细节，框架自己完成整个计算过程。这里我们通过stream接口定义了整个操作集。\ntype stream[T any] interface {\rParallel() stream[T]\rMap(func(T) T) stream[T]\rReduce(func(T, T) T) T\rReduceWithInitValue(T, func(T, T) T) T\rForEach(func(T))\rSorted() stream[T]\rSortedWith(func(T, T) bool) stream[T]\rFilter(func(T) bool) stream[T]\rLimit(int) stream[T]\rFindFirst() T\rToList() []T\rDistinct() stream[T]\rDistinctWith(func(T, T) bool) stream[T]\r} 上面我针对go stream这个框架，介绍了基于流的操作，怎样支持并行计算，以及声明式编程风格。这个框架我在实现时并行计算部分实现采用了比较基础的方式，还可以再进一步实现更多的功能，改进算法得到更高的效率。大家有兴趣可以一起研究。\n该项目开源地址：gostream\n基于Go-1.18实现\n","permalink":"https://kmnemon.github.io/posts/2023-12-29-go-stream-flow/","summary":"\u003ch1 id=\"java的stream编程\"\u003eJava的Stream编程\u003c/h1\u003e\n\u003cp\u003e自从Java 8将函数式编程引入语言后，该语言通过Lambda表达式和Stream库两者的结合，展现了全新的编码方式。实现了简洁，高效，以及类似声明式的编码风格。\u003c/p\u003e\n\u003cp\u003e举个例子，如我们有个集合里面存放的是颜色的标签，我们想在集合中找出以“b”字符开头的标签，并进行排序，然后转换成大写字符标签，最后输出。如果用Java 8以前的编码方式，我们会进行多次轮询，最后输出结果：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epublic static void main(String[] args) {\r\n        List\u0026lt;String\u0026gt; colors = Arrays.asList(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;brown\u0026#34;, \u0026#34;grey\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;beige\u0026#34;, \u0026#34;purple\u0026#34;);\r\n        List\u0026lt;String\u0026gt; filteredAndSortedColors = new ArrayList\u0026lt;\u0026gt;();\r\n\r\n        for (String color : colors) {\r\n            if (color.startsWith(\u0026#34;b\u0026#34;)) {\r\n                filteredAndSortedColors.add(color);\r\n            }\r\n        }\r\n\r\n        Collections.sort(filteredAndSortedColors);\r\n\r\n        for (String color : filteredAndSortedColors) {\r\n            System.out.println(color.toUpperCase());\r\n        }\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e如果用Java 8的Lambda、Stream来实现，则代码会更加简洁、易懂，执行效率也会提高：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epublic static void main(String args[]) {\r\n      Stream.of(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;brown\u0026#34;, \u0026#34;grey\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;beige\u0026#34;, \u0026#34;purple\u0026#34;)\r\n      .filter(s -\u0026gt; s.startsWith(\u0026#34;b\u0026#34;))\r\n      .sorted()\r\n      .map(s -\u0026gt; s.toUpperCase())\r\n      .forEach(System.out::println);\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"go的stream编程\"\u003eGo的Stream编程\u003c/h1\u003e\n\u003cp\u003ego语言中函数是第一公民，理论上我们可以实现更简洁的Stream框架。Stream的核心有以下几个方面：\u003c/p\u003e","title":"Go stream让go流动起来～"},{"content":"最近敏捷圈发起一阵讨论：敏捷、瀑布，在中国存在过吗，不禁思考在中国敏捷与瀑布，真没相遇过吗？\n2000年前后,CMM思想流入中国，01年《程序员》杂志开始以《CMM布道中国》为专题进行一系列讲述。从这时起CMM在中国如火如荼的发展，IPD-CMMI一度成为众多企业的学习对象。在这股思潮下，软件开发以瀑布V模型为主，该流程要求软件发现缺陷后，需向上回溯到最早缺陷引入点，随后从缺陷引入点开始进行一系列后续变更。举个例子在测试阶段发现程序缺陷，通过分析后得知是需求文档描述有误，那么需要先变更需求文档，接着变更概要设计，详细设计，测试用例，代码修改，单元测试，代码评审，最后该功能重新进入测试阶段。\n这个流程里需求分析，开发，测试人员通常属于各自职能部门，由于职能竖井（KPI，部门墙等），软件开发过程中经常需要开会协调。但只要时间充足，上线软件倒也质量尚可。但问题就出在时间充足这个假设前提，当时中国IT企业大多是以倒排期和版本火车方式进行项目计划。团队成员在同一时间会投入到多个软件版本中，时间紧，任务重，同时白天大部分时间又用于开会和扯皮，晚上才能安静的进行软件开发，长此以往团队陷入软件泥潭，疲惫不堪。\n这时团队往往采取流程裁剪这样的骚操作，概要设计，详细设计，测试用例，单元测试，代码评审等非直接编码活动统统拆剪掉。剩下哪些活动呢？总得有需求文档吧，不然团队用什么开发，最主要的编码活动不能裁剪掉，就这两个活动就可以交付软件了，可团队TL心里没底啊，测试环节也留下。于是乎V模型只剩下“需求-开发-测试”三个活动。如果企业流程不能随意裁剪，那么你仔细观察上线前一天团队在做什么，就会发现所有团队成员都在补写文档，至于这些文档和当前上线代码有什么关系，没人知道。你问这些团队这是什么开发方式，他们会说这是裁剪后的“瀑布流程”。\n2008年前后，敏捷思潮开始在企业发芽，《硝烟中的Scrum和XP》和《持续集成》成为敏捷支持者的床头书，迭代增量开发，快速反馈成为敏捷的重要指导思想，上一活动的问题，尽量在下一活动反馈中找到并修复。自动化测试成为保证质量，快速反馈，快速发布的重要标志。团队实在受不了每夜写代码，开始纷纷上马敏捷开发。可是采用敏捷开发，之前的问题就解决了吗？\n敏捷宣言第二句“工作的软件高于详尽的文档”，但团队选择性无视左边，专注到右边，你看敏捷不用写任何文档了，一阵欢呼。于是敏捷3355会议开起，需求澄清会议一开就是2，3天，会议室里面坐满黑压压一片，产品经理卖力念着需求文档，团队里三层，外三层各自玩手机。​总算结束，团队开始拆卡片，随后进入迭代开发，后期进入迭代测试。你看这个敏捷开发不就是换了个名词的“敏捷3355+裁剪后的瀑布流程”。久而久之团队开始抱怨，以前瀑布流程的时候可没那么多会议，敏捷开发咋那么烦琐，要不我们也把迭代演示，迭代回顾，代码评审，自动化测试，小批量交付等裁剪了，最后敏捷开发成为迭代进行的“需求-开发-测试”三个活动。你问这些团队这是什么开发方式，他们会说这是“敏捷开发”。\n你看中国企业采取了”瀑布流程“、”敏捷开发“，怎么最后都是一个样子？这里原因很多，有人认为是企业倒排期文化，有人认为是需求变化太快，但有一个很重要的问题，团队里面真的是合格程序员吗？真的理解计算机科学吗？以下一些问题作为参考:\n哪些算法，语言设计，操作系统，分布式计算，运用了fork-join思想？ Java为什么放弃绿色线程，现在为什么又要开始支持虚拟线程？ 设计模式，面向对象编程是灵丹妙药吗？ 你写的代码会覆盖必要的单元测试吗？ 抽象能力是计算机基础，编程语言，框架，系统，硬件进行大量的抽象，尽量隐藏细节，但并不意味着你可以不理解计算机基础，就到处调用框架，运用大量并发技术。深入团队编码，会发现并不是团队不愿意写单元测试，而是团队写的代码根本无法测试，更不用说从未写过单元测试。\n选人的时候，从未考虑候选人计算机基础能力，编码内功，只要这个人能尽快上手项目就行，这个语言，那个框架玩的飞起来。你仔细观察这些团队，会发现他们的流程再次升级，变成“需求-拷贝、粘贴-人肉点点点”。中国IT发展了20,30年，系统升级了，语言升级了，框架升级了，工具也升级了，可团队能力升级了吗？\n","permalink":"https://kmnemon.github.io/posts/2023-01-03-agile-waterfall/","summary":"\u003cp\u003e最近敏捷圈发起一阵讨论：敏捷、瀑布，在中国存在过吗，不禁思考在中国敏捷与瀑布，真没相遇过吗？\u003c/p\u003e\n\u003cp\u003e2000年前后,CMM思想流入中国，01年《程序员》杂志开始以《CMM布道中国》为专题进行一系列讲述。从这时起CMM在中国如火如荼的发展，IPD-CMMI一度成为众多企业的学习对象。在这股思潮下，软件开发以瀑布V模型为主，该流程要求软件发现缺陷后，需向上回溯到最早缺陷引入点，随后从缺陷引入点开始进行一系列后续变更。举个例子在测试阶段发现程序缺陷，通过分析后得知是需求文档描述有误，那么需要先变更需求文档，接着变更概要设计，详细设计，测试用例，代码修改，单元测试，代码评审，最后该功能重新进入测试阶段。\u003c/p\u003e\n\u003cp\u003e这个流程里需求分析，开发，测试人员通常属于各自职能部门，由于职能竖井（KPI，部门墙等），软件开发过程中经常需要开会协调。但只要时间充足，上线软件倒也质量尚可。但问题就出在时间充足这个假设前提，当时中国IT企业大多是以倒排期和版本火车方式进行项目计划。团队成员在同一时间会投入到多个软件版本中，时间紧，任务重，同时白天大部分时间又用于开会和扯皮，晚上才能安静的进行软件开发，长此以往团队陷入软件泥潭，疲惫不堪。\u003c/p\u003e\n\u003cp\u003e这时团队往往采取流程裁剪这样的骚操作，概要设计，详细设计，测试用例，单元测试，代码评审等非直接编码活动统统拆剪掉。剩下哪些活动呢？总得有需求文档吧，不然团队用什么开发，最主要的编码活动不能裁剪掉，就这两个活动就可以交付软件了，可团队TL心里没底啊，测试环节也留下。于是乎V模型只剩下“需求-开发-测试”三个活动。如果企业流程不能随意裁剪，那么你仔细观察上线前一天团队在做什么，就会发现所有团队成员都在补写文档，至于这些文档和当前上线代码有什么关系，没人知道。你问这些团队这是什么开发方式，他们会说这是裁剪后的“瀑布流程”。\u003c/p\u003e\n\u003cp\u003e2008年前后，敏捷思潮开始在企业发芽，《硝烟中的Scrum和XP》和《持续集成》成为敏捷支持者的床头书，迭代增量开发，快速反馈成为敏捷的重要指导思想，上一活动的问题，尽量在下一活动反馈中找到并修复。自动化测试成为保证质量，快速反馈，快速发布的重要标志。团队实在受不了每夜写代码，开始纷纷上马敏捷开发。可是采用敏捷开发，之前的问题就解决了吗？\u003c/p\u003e\n\u003cp\u003e敏捷宣言第二句“工作的软件高于详尽的文档”，但团队选择性无视左边，专注到右边，你看敏捷不用写任何文档了，一阵欢呼。于是敏捷3355会议开起，需求澄清会议一开就是2，3天，会议室里面坐满黑压压一片，产品经理卖力念着需求文档，团队里三层，外三层各自玩手机。​总算结束，团队开始拆卡片，随后进入迭代开发，后期进入迭代测试。你看这个敏捷开发不就是换了个名词的“敏捷3355+裁剪后的瀑布流程”。久而久之团队开始抱怨，以前瀑布流程的时候可没那么多会议，敏捷开发咋那么烦琐，要不我们也把迭代演示，迭代回顾，代码评审，自动化测试，小批量交付等裁剪了，最后敏捷开发成为迭代进行的“需求-开发-测试”三个活动。你问这些团队这是什么开发方式，他们会说这是“敏捷开发”。\u003c/p\u003e\n\u003cp\u003e你看中国企业采取了”瀑布流程“、”敏捷开发“，怎么最后都是一个样子？这里原因很多，有人认为是企业倒排期文化，有人认为是需求变化太快，但有一个很重要的问题，团队里面真的是合格程序员吗？真的理解计算机科学吗？以下一些问题作为参考:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e哪些算法，语言设计，操作系统，分布式计算，运用了fork-join思想？\u003c/li\u003e\n\u003cli\u003eJava为什么放弃绿色线程，现在为什么又要开始支持虚拟线程？\u003c/li\u003e\n\u003cli\u003e设计模式，面向对象编程是灵丹妙药吗？\u003c/li\u003e\n\u003cli\u003e你写的代码会覆盖必要的单元测试吗？\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e抽象能力是计算机基础，编程语言，框架，系统，硬件进行大量的抽象，尽量隐藏细节，但并不意味着你可以不理解计算机基础，就到处调用框架，运用大量并发技术。深入团队编码，会发现并不是团队不愿意写单元测试，而是团队写的代码根本无法测试，更不用说从未写过单元测试。\u003c/p\u003e\n\u003cp\u003e选人的时候，从未考虑候选人计算机基础能力，编码内功，只要这个人能尽快上手项目就行，这个语言，那个框架玩的飞起来。你仔细观察这些团队，会发现他们的流程再次升级，变成“需求-拷贝、粘贴-人肉点点点”。中国IT发展了20,30年，系统升级了，语言升级了，框架升级了，工具也升级了，可团队能力升级了吗？\u003c/p\u003e","title":"“敏捷”与“瀑布”，在中国还真相遇过，只不过不是你认为的方式"},{"content":"敏捷宣言诞生至今已20多年，在众多挑战瀑布的方法中，它完美的完成了这次反叛，成为主流的方式。敏捷最早作为软件行业的开发方式，现在逐渐渗透到其他行业。\n随着敏捷方法流行，越来越多的概念，方法论，实践被加了进来，“敏捷”开始变得臃肿，很多和敏捷八杆子打不着的方法也号称“敏捷”。人们开始在各种概念中迷失，敏捷的本质被逐渐掩盖。\n敏捷首要解决的问题是小团队开发，两个披萨可以喂饱的团队（6～12个人），如下图敏捷的核心实践，都是针对小团队的一系列活动： 我认为整个敏捷开发活动最重要的是BDD和TDD两个实践，再辅以过程透明化，快速反馈与持续改进。 为什么这两个实践如此重要，整个软件开发活动中我们要解决的三个核心问题是：\n如何确保充分理解了业务需求\n如果确保技术上能实现该需求\n如何确保开发出来的功能满足业务需求\nBDD通过与业务达成一致的实例化需求，来确保我们理解了业务需求，如果我们不能写出验收用例，证明我们还没理解业务需求。验收测试用例用来衡量我们是否真正理解业务需求。\n同时我们把验收用例自动化，通过自动化验收测试，来确保我们开发出来的功能是满足业务需求的。\nTDD通过自动化测试，来确保我们技术上是可行的，如果不能写出自动化测试，就无法确保在当前技术框架下可以完成该功能开发。\n这两个实践使我们的开发活动工程化，只有通过工程化，才能确保我们的需求透明化，开发透明化，验收透明化，才能得到快速反馈，最后才能根据反馈持续改进。\n关于规模化敏捷，人类历史上是不缺乏大规模的组织活动（金字塔，巴拿马运河，登陆月球，原子弹等等等），敏捷是通过首要解决小团队问题，然后把大规模团队划分为小团队，来达到规模化效果。但如果不先解决小团队问题，规模化敏捷就会流于形式。举个例子，规模化敏捷的核心问题就是团队间协作，版本火车中投入最大，耗时最长就是整个版本开发活动，多个团队要在估算的时间完成某功能联调活动，如果团队不具备TDD能力，那么团队的任务估算无法保证，导致该功能无法按时联调，团队间产生等待，连锁反应到迭代末团队继续追赶任务，无法投入到下迭代需求分析活动中，影响一直持续到后续迭代。\n最后关于敏捷价值观，在眼花缭乱的各种方法中，以及在我们教练辅导中，是否还秉承着Kent Beck提到最核心的敏捷价值观：勇气，沟通，反馈，简单。\n","permalink":"https://kmnemon.github.io/posts/2022-08-14-agile-essence/","summary":"\u003cp\u003e敏捷宣言诞生至今已20多年，在众多挑战瀑布的方法中，它完美的完成了这次反叛，成为主流的方式。敏捷最早作为软件行业的开发方式，现在逐渐渗透到其他行业。\u003c/p\u003e\n\u003cp\u003e随着敏捷方法流行，越来越多的概念，方法论，实践被加了进来，“敏捷”开始变得臃肿，很多和敏捷八杆子打不着的方法也号称“敏捷”。人们开始在各种概念中迷失，敏捷的本质被逐渐掩盖。\u003c/p\u003e\n\u003cp\u003e敏捷首要解决的问题是小团队开发，两个披萨可以喂饱的团队（6～12个人），如下图敏捷的核心实践，都是针对小团队的一系列活动：\n\u003cimg loading=\"lazy\" src=\"/images/2022-08-14-agile-essence/xp.png\"\u003e\u003c/p\u003e\n\u003cp\u003e我认为整个敏捷开发活动最重要的是BDD和TDD两个实践，再辅以过程透明化，快速反馈与持续改进。\n\u003cimg loading=\"lazy\" src=\"/images/2022-08-14-agile-essence/agile-essence.png\"\u003e\u003c/p\u003e\n\u003cp\u003e为什么这两个实践如此重要，整个软件开发活动中我们要解决的三个核心问题是：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e如何确保充分理解了业务需求\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e如果确保技术上能实现该需求\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e如何确保开发出来的功能满足业务需求\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBDD通过与业务达成一致的实例化需求，来确保我们理解了业务需求，如果我们不能写出验收用例，证明我们还没理解业务需求。验收测试用例用来衡量我们是否真正理解业务需求。\u003c/p\u003e\n\u003cp\u003e同时我们把验收用例自动化，通过自动化验收测试，来确保我们开发出来的功能是满足业务需求的。\u003c/p\u003e\n\u003cp\u003eTDD通过自动化测试，来确保我们技术上是可行的，如果不能写出自动化测试，就无法确保在当前技术框架下可以完成该功能开发。\u003c/p\u003e\n\u003cp\u003e这两个实践使我们的开发活动工程化，只有通过工程化，才能确保我们的需求透明化，开发透明化，验收透明化，才能得到快速反馈，最后才能根据反馈持续改进。\u003c/p\u003e\n\u003cp\u003e关于规模化敏捷，人类历史上是不缺乏大规模的组织活动（金字塔，巴拿马运河，登陆月球，原子弹等等等），敏捷是通过首要解决小团队问题，然后把大规模团队划分为小团队，来达到规模化效果。但如果不先解决小团队问题，规模化敏捷就会流于形式。举个例子，规模化敏捷的核心问题就是团队间协作，版本火车中投入最大，耗时最长就是整个版本开发活动，多个团队要在估算的时间完成某功能联调活动，如果团队不具备TDD能力，那么团队的任务估算无法保证，导致该功能无法按时联调，团队间产生等待，连锁反应到迭代末团队继续追赶任务，无法投入到下迭代需求分析活动中，影响一直持续到后续迭代。\u003c/p\u003e\n\u003cp\u003e最后关于敏捷价值观，在眼花缭乱的各种方法中，以及在我们教练辅导中，是否还秉承着Kent Beck提到最核心的敏捷价值观：\u003cstrong\u003e勇气，沟通，反馈，简单\u003c/strong\u003e。\u003c/p\u003e","title":"敏捷本质"},{"content":"今年3月随着Go 1.18版发布，引入了一个重大的语言特性：泛型编程。这个特性在发布前引起了一定的争议。崇尚少即是多的一边认为这个特性不是很必要，应该谨慎引入。另一边则认为这是语言必不可少的特性。最后Go的泛型还是如期而至\n泛型编程在其他编程语言也遇到了不同的问题，比如在Java 1.0时是没有引入泛型编程支持，到了Java 1.5的时候引入了泛型，但由于引入时间过晚，有大量的标准库和第三方库无法支持，Java选择了妥协采用间接的类型擦除方式来实现泛型编程，导致泛型的使用复杂度增加，同时场景受限。而C++比较明智，一开始就支持泛型，所以在C++ STL标准库里面大量的算法都是采用泛型实现，整个语言体系中泛型占据了核心位置\n学习一个语言的特性可以参考其他语言同样的特性，这样就可以了解这个语言特性实现是否设计合理，是否优雅，存在哪些局限性\n语言版本：\nC++11\nJava 11\nGo 1.18\n1. 泛型函数 泛型函数用来支持当一个算法用在多种数据类型上，为了避免重复的定义函数，而用泛型函数来支持\n两个数据进行取小操作\n//C++\rtemplate \u0026lt;class T\u0026gt;\rT min(T a, T b){\rreturn a \u0026lt; b ? a : b;\r}\r//Java不支持\r//Go\rfunc Min[T int|float64](a, b T) T {\rif a \u0026lt; b {\rreturn a\r} else {\rreturn b\r}\r} 2. 泛型函数-显示特化 当泛型函数用来支持一个算法用在多种数据类型上，但在某个类型数据上泛型函数的实现不适合该类型，那么我们可以显示特化该类型的实现算法\n/C++独有\rtemplate\u0026lt;\u0026gt; string min\u0026lt;string\u0026gt;(string a, string b){\rreturn a.size() \u0026lt; b.size() ? a : b;\r} 3.泛型类 泛型类的目的是创建一个集合类型，里面的各种数据类型可以进行相同的操作，泛型类避免了多个数据类型的重复定义\n//C++\rtemplate\u0026lt;class T\u0026gt;\rclass Queue{\rpublic:\rQueue();\r~Queue();\rT\u0026amp; remove();\rvoid add( const T\u0026amp;);\rbool isEmpty();\r}\r//Java\rpublic class Queue\u0026lt;T\u0026gt; {\rpublic Queue(){\r}\rpublic T remove(){\r//...\r}\rpublic void add(final T a){\r//...\r}\r}\r//Go\rtype Queue[T interface{}] struct{\relement []T\r}\rfunc (q *Queue[T]) remove() *T{\r//...\rfunc (q *Queue[T]) add(a *T){\r//...\r} 类型擦除 前面说到Java是在1.5版本时才引入泛型支持，这个时候已经有大量的工程，类库基于非泛型代码，这个时候引入泛型就会相当复杂，因为不能导致历史代码不兼容。\n这时Java做出了妥协，采用类型擦除的方式实现了泛型，并保持历史代码的兼容性。采用这种方式有一个明显的缺陷是在泛型代码内部，无法获取有关任何泛型参数的信息\n当在代码尝试调用泛型特有的信息时，Java的实现就会变得复杂\n//C++\rtemplate\u0026lt;class T\u0026gt; class Manipulator {\rT obj;\rpublic:\rManipulator(T x) { obj = x; }\rvoid manipulate() { obj.f(); }//compiler check\r};\rclass HasF {\rpublic:\rvoid f() { cout \u0026lt;\u0026lt; \u0026#34;HasF::f()\u0026#34; \u0026lt;\u0026lt; endl; }\r}; 上面代码调用泛型T的f()方法，在C++的实现中编译器会检查泛型T是否含有f()方法，如果有则编译通过。\n在Java中由于类型被擦除，在编译时刻，编译器无法检查是否含有f()方法，这个调用会编译报错。\nclass Manipulator\u0026lt;T\u0026gt; {\rprivate T obj;\rManipulator(T x) {\robj = x;\r}\r// Error: cannot find symbol: method f():\rpublic void manipulate() {\robj.f();\r}\r} 为了解决这个问题Java在泛型支持中引入新关键字extends，表示该泛型T是后续类型或其子类\npublic class Manipulator2\u0026lt;T extends HasF\u0026gt; {\rprivate T obj;\rManipulator2(T x) {\robj = x;\r}\rpublic void manipulate() {\robj.f();\r}\r} 这样引入复杂度才解决这个问题。\n为了缓解类型擦除带来的问题，Java同时还引入通配符?, 逆变super等关键字支持泛型，可见开始语言特性设计考虑不慎，后续就会引入大量不必要的复杂性\n在Go的泛型实现中，就算指定了类型限制，编译器也无法检查调用类型，这方面Go的泛型限制更大，下面代码编译不过\ntype Manipulator[T HasF] struct{\robj T\r}\rfunc (m Manipulator[T]) manipulate(){\rm.obj.f() //compile error: undefined\r}\rtype HasF struct{\r}\rfunc (h HasF) f(){\r} 泛型类特化与偏特化 C++同时还支持泛型类的特化与偏特化能力，这些都是Java与Go泛型不支持的特性，这里就不举例了\n4.泛型方法 当类中少数方法需要泛化，并不需要全面泛化类时，泛型方法就登场了\n//C++\rclass Queue{\rpublic:\rtemplate\u0026lt;class Iter\u0026gt;\rvoid assign(Iter first, Iter last){\r//...\r}\r}\r//Java\rpublic class Queue {\rpublic \u0026lt;Iter\u0026gt; void assign(Iter first, Iter last){\r//...\r}\r}\r//Go不支持泛型方法 5.泛型接口 当设计接口支持多种数据类型时，就会用到泛型接口\n//C++\rtemplate class\u0026lt;T\u0026gt;\rclass MinMax{\rpublic:\rvirtual T max()=0；\r};\r//Java\rinterface MinMax\u0026lt;T extends Comparable\u0026lt;T\u0026gt;\u0026gt; {\rT max();\r}\rclass MyClass\u0026lt;T extends Comparable\u0026lt;T\u0026gt;\u0026gt; implements MinMax\u0026lt;T\u0026gt; {\rpublic T max() {\r//...\r}\r}\r//Go\rtype MinMax[T any] interface{\rmax() T\r} 这篇文章介绍了主要的泛型场景，我们看到三种语言泛型能力C++\u0026gt;Java\u0026gt;Go，C++从语言开始设计就考虑泛型没有历史包袱，所以泛型能力最强，表达力最优秀。Java借鉴了C++语言，但在泛型设计上慢了一步后期加入泛型只有采用妥协方式（类型擦除）来实现，在泛型支持场景上受限，同时复杂度增加。Go语言受到原作者的影响，一开始并不想支持泛型，在后期社区反馈中才考虑加入泛型，也作出妥协，增加了复杂度，场景也受限更多。\n","permalink":"https://kmnemon.github.io/posts/2022-06-28-generic-programming/","summary":"\u003cp\u003e今年3月随着Go 1.18版发布，引入了一个重大的语言特性：泛型编程。这个特性在发布前引起了一定的争议。崇尚少即是多的一边认为这个特性不是很必要，应该谨慎引入。另一边则认为这是语言必不可少的特性。最后Go的泛型还是如期而至\u003c/p\u003e\n\u003cp\u003e泛型编程在其他编程语言也遇到了不同的问题，比如在Java 1.0时是没有引入泛型编程支持，到了Java 1.5的时候引入了泛型，但由于引入时间过晚，有大量的标准库和第三方库无法支持，Java选择了妥协采用间接的类型擦除方式来实现泛型编程，导致泛型的使用复杂度增加，同时场景受限。而C++比较明智，一开始就支持泛型，所以在C++ STL标准库里面大量的算法都是采用泛型实现，整个语言体系中泛型占据了核心位置\u003c/p\u003e\n\u003cp\u003e学习一个语言的特性可以参考其他语言同样的特性，这样就可以了解这个语言特性实现是否设计合理，是否优雅，存在哪些局限性\u003c/p\u003e\n\u003cp\u003e语言版本：\u003cbr\u003e\nC++11\u003cbr\u003e\nJava 11\u003cbr\u003e\nGo 1.18\u003c/p\u003e\n\u003ch3 id=\"1-泛型函数\"\u003e1. 泛型函数\u003c/h3\u003e\n\u003cp\u003e泛型函数用来支持当一个算法用在多种数据类型上，为了避免重复的定义函数，而用泛型函数来支持\u003c/p\u003e\n\u003cp\u003e两个数据进行取小操作\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e//C++\r\ntemplate \u0026lt;class T\u0026gt;\r\nT min(T a, T b){\r\n    return a \u0026lt; b ? a : b;\r\n}\r\n\r\n//Java不支持\r\n\r\n//Go\r\nfunc Min[T int|float64](a, b T) T {\r\n  if a \u0026lt; b {\r\n    return a\r\n  } else {\r\n    return b\r\n  }\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2-泛型函数-显示特化\"\u003e2. 泛型函数-显示特化\u003c/h3\u003e\n\u003cp\u003e当泛型函数用来支持一个算法用在多种数据类型上，但在某个类型数据上泛型函数的实现不适合该类型，那么我们可以显示特化该类型的实现算法\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e/C++独有\r\ntemplate\u0026lt;\u0026gt; string min\u0026lt;string\u0026gt;(string a, string b){\r\n    return a.size() \u0026lt; b.size() ? a : b;\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3泛型类\"\u003e3.泛型类\u003c/h3\u003e\n\u003cp\u003e泛型类的目的是创建一个集合类型，里面的各种数据类型可以进行相同的操作，泛型类避免了多个数据类型的重复定义\u003c/p\u003e","title":"泛型编程浅入浅出(C++, Java, Go)"},{"content":"最近因为未控制饮食，以及家附近游泳池关闭，导致体重持续上升，已经到了自己难以忍受的状态，148.5。 一直知道有一种可能比较健康的生活方式，轻断食，但一直不知道怎么实践，通过搜索发现有部记录片《进食 断食 长寿》，介绍了轻断食的理念。决定先尝试一下正常断食，计划断食4天半，每天吃一些蔬菜汤，维生素，卡路里在200左右，完成后采用5+2轻断食法维持健康。\n4月开始 第一天 23号晚上暴饮暴食后，不再进食，24号白天中午，未感觉任何饥饿感，可能是头天晚上吃太多了，出去溜达溜达，中午也没午觉，下午继续办公，办公后进行骑行锻炼1.5小时。晚上回来感觉头有点晕，吃了半碗饭+一小份莴笋烧兔子，补充了一颗维生素，肚子咕咕叫，后面整体正常。晚上睡觉质量变差，睡眠变浅。网上查询是因为身体激素变化的原因，断食期间睡眠会出现没有以前好的状况。\n第二天 25号早晨体重145.5，没有饥饿感，工作到中午一样没有多少睡意，中午出去溜达一圈。下午工作到16点时，困意来袭，小眯了一会儿。进行骑行锻炼1.7小时，感觉力气没有昨天多。晚上自制蔬菜+西红柿汤，大概卡路里在200以内，补充一颗维生素。 肚子继续咕咕叫，并伴有轻微腹泻，持续时间一整夜。晚上睡眠还是变浅，醒来几次。\n第三天 26日早晨体重143.5斤。无头晕感觉，但觉得力气不足。喝水，补充一颗维生素。腹泻状态暂时消失。今天工作比较忙，晚上回家感觉心跳加快，有些不适，怕影响健康，停止断食，开始正常晚餐。\n后续开展5+2轻断食+运动，5.9号测量体重为142斤，正常开始降低体重。\n7月期间 加大运动量，体重降到130以下，身体并无不适\n9～10月期间 由于疫情运动量减小，加强了断食间隔，断食日整天不吃。体重维持到126左右。但出现营养不良型脱发。在10月下旬恢复正常饮食，脱发继续。\n11月初脱发减少恢复正常。考虑轻断食太重可能影响健康。开始恢复正常饮食，同时加强运动消耗。体重126左右。\n","permalink":"https://kmnemon.github.io/posts/2022-03-23-intermittent-fasting/","summary":"\u003cp\u003e最近因为未控制饮食，以及家附近游泳池关闭，导致体重持续上升，已经到了自己难以忍受的状态，148.5。\n一直知道有一种可能比较健康的生活方式，轻断食，但一直不知道怎么实践，通过搜索发现有部记录片《进食 断食 长寿》，介绍了轻断食的理念。决定先尝试一下正常断食，计划断食4天半，每天吃一些蔬菜汤，维生素，卡路里在200左右，完成后采用5+2轻断食法维持健康。\u003c/p\u003e\n\u003cp\u003e4月开始 第一天 23号晚上暴饮暴食后，不再进食，24号白天中午，未感觉任何饥饿感，可能是头天晚上吃太多了，出去溜达溜达，中午也没午觉，下午继续办公，办公后进行骑行锻炼1.5小时。晚上回来感觉头有点晕，吃了半碗饭+一小份莴笋烧兔子，补充了一颗维生素，肚子咕咕叫，后面整体正常。晚上睡觉质量变差，睡眠变浅。网上查询是因为身体激素变化的原因，断食期间睡眠会出现没有以前好的状况。\u003c/p\u003e\n\u003cp\u003e第二天 25号早晨体重145.5，没有饥饿感，工作到中午一样没有多少睡意，中午出去溜达一圈。下午工作到16点时，困意来袭，小眯了一会儿。进行骑行锻炼1.7小时，感觉力气没有昨天多。晚上自制蔬菜+西红柿汤，大概卡路里在200以内，补充一颗维生素。 肚子继续咕咕叫，并伴有轻微腹泻，持续时间一整夜。晚上睡眠还是变浅，醒来几次。\u003c/p\u003e\n\u003cp\u003e第三天 26日早晨体重143.5斤。无头晕感觉，但觉得力气不足。喝水，补充一颗维生素。腹泻状态暂时消失。今天工作比较忙，晚上回家感觉心跳加快，有些不适，怕影响健康，停止断食，开始正常晚餐。\u003c/p\u003e\n\u003cp\u003e后续开展5+2轻断食+运动，5.9号测量体重为142斤，正常开始降低体重。\u003c/p\u003e\n\u003cp\u003e7月期间 加大运动量，体重降到130以下，身体并无不适\u003c/p\u003e\n\u003cp\u003e9～10月期间 由于疫情运动量减小，加强了断食间隔，断食日整天不吃。体重维持到126左右。但出现营养不良型脱发。在10月下旬恢复正常饮食，脱发继续。\u003c/p\u003e\n\u003cp\u003e11月初脱发减少恢复正常。考虑轻断食太重可能影响健康。开始恢复正常饮食，同时加强运动消耗。体重126左右。\u003c/p\u003e","title":"断食·轻断食"},{"content":"上一篇文章《理解响应式编程（reactive programming)》我们谈到响应式编程四个核心概念：\n发布者(The Publisher): 发布者就是数据的生产者，这个是为系统生产数据的组件，这里的服务B就是一个发布者，他收到服务A的请求后就开始生产数据。\n订阅者(The Subscriber): 订阅者订阅发布者生产的数据。这里服务A就是订阅者，他订阅来自服务B的数据。\n订阅过程(The Subscription):订阅过程是一份服务之间的合约（contract)，它被用于订阅者获取数据，或者取消订阅。\n处理者(The Processor):处理者是一个响应式实体，他能够消费发布者的数据，并进行再加工，然后发布自己的数据，上面的例子并未体现这层逻辑。举个例子，排序处理者，他可以作为订阅者获取发布者的随机序数据，然后进行排序，然后作为发布者生产出排序后的数据。\n一个典型的响应式交互如下：\n订阅者和发布者签订订阅契约(Publisher.subscribe),一旦契约签订完成，订阅者向发布者请求数据(Subscription.request),发布者准备好数据后传输数据给订阅者(调用订阅者onNext)，订阅者再次请求新数据(request)，直到发布者告诉订阅者数据已经发送完成(onComplete)，本次契约完成。\nReactive REST Appplication\n现在我们使用WebFlux开始构建一个简单的响应式应用.\n使用一个简单的领域模型-Employee 使用RestController返回发布者生产的数据 使用WebClient构建订阅者获取发布者数据 WebFlux Maven依赖如下：\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-webflux\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt; 发布者（Publisher）\nWebFlux底层使用Project Reactor，所以我们这里使用Project Reactor的命名来介绍。\n发布者有两个类型：\nMono类型表示生产0个或者至多1个数据 Flux类型表示生产多个数据 示例代码分为三层分别是：\ncontroller-获取REST请求，并返回订阅数据 model-包含Employee领域模型 repository-构建内存数据库（采用HashMap) controller:\n可以看到方法返回类型为Mono或者Flux，表示生产者会生产对应类型个数的数据\n@RestController\r@RequestMapping(\u0026#34;/employees\u0026#34;)\rpublic class EmployeeController {\rprivate static final Logger logger = LoggerFactory.getLogger(EmployeeController.class);\rprivate final EmployeeRepository employeeRepository;\rpublic EmployeeController(EmployeeRepository employeeRepository) {\rthis.employeeRepository = employeeRepository;\r}\r@GetMapping(\u0026#34;/{id}\u0026#34;)\rprivate Mono\u0026lt;Employee\u0026gt; getEmployeeById(@PathVariable String id) {\rlogger.debug(\u0026#34;getEmplyeeById controller get called\u0026#34;);\rreturn employeeRepository.findEmployeeById(id);\r}\r@GetMapping\rprivate Flux\u0026lt;Employee\u0026gt; getAllEmployees() {\rlogger.debug(\u0026#34;getAllEmployees controller get called\u0026#34;);\rreturn employeeRepository.findAllEmployees();\r}\r@PostMapping(\u0026#34;/update\u0026#34;)\rprivate Mono\u0026lt;Employee\u0026gt; updateEmployee(@RequestBody Employee employee) {\rreturn employeeRepository.updateEmployee(employee);\r}\r} model：\n很简单的领域模型Employee包含id和name两个字段\n@Data\r@AllArgsConstructor\r@NoArgsConstructor\rpublic class Employee {\rprivate String id;\rprivate String name;\r// standard getters and setters\r} repository:\n这里不是重点记住使用HashMap内存数据库.\n@Repository\rpublic class EmployeeRepository {\rstatic Map\u0026lt;String, Employee\u0026gt; employeeData;\rstatic Map\u0026lt;String, String\u0026gt; employeeAccessData;\r...\r} 订阅者(Subscriber)\n订阅者订阅发布者数据，有三种情况会通知订阅者：1.发布者准备好数据后，2.错误发生时，3.发布者生产完数据.\n所以订阅者有三个数据通道，每一个通道都是订阅者的内部方法：\nOnNext-当发布者有1个或多个数据生产出来会调用这个方法 OnError-当发布者在生产过程中出现错误会调用这个方法，注意当这个方法被调用，发布者将不再生产数据。 OnComplete-当发布者数据生产完成会调用订阅者这个方法。 订阅者我们使用WebClient是一个非阻塞客户端并支持响应式流。\n在订阅者服务，我们自定义consumeMono方法来订阅单个数据，consumeFlux订阅多个数据。\n在consumeMono方法里面，我们在签订契约的时候(employeeMono.subscribe)只定义了OnNext数据通道(employee -\u0026gt; logger.debug(\u0026ldquo;Employee: {}\u0026rdquo;, employee)) 在consumeFlux方法里，我们在签订契约的时候(employeeFlux.subscribe)定义了上述的三个数据通道: OnNext-employee -\u0026gt; logger.debug(\u0026ldquo;Employee: {}\u0026rdquo;, employee)\nOnError-err -\u0026gt; err.printStackTrace()\nOnComplete-() -\u0026gt; logger.debug(\u0026ldquo;completed\u0026rdquo;) public class EmployeeWebClient {\rprivate static final Logger logger = LoggerFactory.getLogger(EmployeeWebClient.class);\rWebClient client = WebClient.create(\u0026#34;http://localhost:8071\u0026#34;);\rpublic void consumeMono() {\rMono\u0026lt;Employee\u0026gt; employeeMono = client.get()\r.uri(\u0026#34;/employees/{id}\u0026#34;, \u0026#34;1\u0026#34;)\r.retrieve()\r.bodyToMono(Employee.class);\remployeeMono.subscribe(employee -\u0026gt; logger.debug(\u0026#34;Employee: {}\u0026#34;, employee));\rlogger.debug(\u0026#34;comsumeMono thread continue\u0026#34;);\r}\rpublic void consumeFlux() {\rFlux\u0026lt;Employee\u0026gt; employeeFlux = client.get()\r.uri(\u0026#34;/employees\u0026#34;)\r.retrieve()\r.bodyToFlux(Employee.class);\remployeeFlux.subscribe(employee -\u0026gt; logger.debug(\u0026#34;Employee: {}\u0026#34;, employee),\rerr -\u0026gt; err.printStackTrace(),\r() -\u0026gt; logger.debug(\u0026#34;completed\u0026#34;));\r}\r} 当我们调用consumeMono方法签订契约消费发布者数据，会得到：\n主线程签订完契约后继续执行后续逻辑，不被发布者阻塞，打印输出“comsumeMono thread continue”\n发布者生产数据后，订阅者OnNext方法被调用，订阅者消费数据打印 “Employee: Employee(id=1, name=Employee 1)”.\n背压机制(Backpressure Mechanism)\n上篇文章说到，背压有三种策略：\n控制发布者发送数据的速率（推荐） 订阅者使用缓存来存储暂时无法处理的数据 订阅者丢弃所有无法处理的数据 我们聚焦第一种策略（控制发布者发送数据的速率）有三种实现方式：\n拉取方式-订阅者请求数据的时候发布者才发送 限制推送方式-限制发布者发布速率 取消订阅-订阅者可以随时取消订阅，待后续有消费能力后再次订阅 拉取方式代码示例. 我们使用subscription.request(2)每次请求2个数据.\nemployeeFlux.subscribe(employee -\u0026gt; logger.debug(\u0026#34;Employee: {}\u0026#34;, employee),\rerr -\u0026gt; err.printStackTrace(),\r() -\u0026gt; logger.debug(\u0026#34;completed\u0026#34;),\rsubscription -\u0026gt; {\rfor (int i = 0; i \u0026lt; 5; i++) {\rlogger.debug(\u0026#34;Requesting the next 2 elements!!!\u0026#34;);\rsubscription.request(2);\r}\r}\r); 这里我们完成了一个简单的具有背压的响应式代码示例。\n结束语 响应式编程作为利用现有物理资源，提供了有效提升服务响应效率的方式，通过两篇文章介绍了响应式编程的原理和WebFlux代码示例，使我们可以继续深入研究响应式编程，以便在大规模请求场景采用响应式编程作为解决用户体验的有效解决方案。\n","permalink":"https://kmnemon.github.io/posts/2022-03-21-using-webflux-in-reactive-programming/","summary":"\u003cp\u003e上一篇文章《理解响应式编程（reactive programming)》我们谈到响应式编程四个核心概念：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e发布者(The Publisher): \u003c/strong\u003e发布者就是数据的生产者，这个是为系统生产数据的组件，这里的服务B就是一个发布者，他收到服务A的请求后就开始生产数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e订阅者(The Subscriber): \u003c/strong\u003e订阅者订阅发布者生产的数据。这里服务A就是订阅者，他订阅来自服务B的数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e订阅过程(The Subscription):\u003c/strong\u003e订阅过程是一份服务之间的合约（contract)，它被用于订阅者获取数据，或者取消订阅。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e处理者(The Processor):\u003c/strong\u003e处理者是一个响应式实体，他能够消费发布者的数据，并进行再加工，然后发布自己的数据，上面的例子并未体现这层逻辑。举个例子，排序处理者，他可以作为订阅者获取发布者的随机序数据，然后进行排序，然后作为发布者生产出排序后的数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e一个典型的响应式交互如下：\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2022-03-21-using-webflux-in-reactive-programming/weflux-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e订阅者和发布者签订订阅契约(Publisher.subscribe),一旦契约签订完成，订阅者向发布者请求数据(Subscription.request),发布者准备好数据后传输数据给订阅者(调用订阅者onNext)，订阅者再次请求新数据(request)，直到发布者告诉订阅者数据已经发送完成(onComplete)，本次契约完成。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReactive REST Appplication\u003c/strong\u003e\u003cbr\u003e\n现在我们使用WebFlux开始构建一个简单的响应式应用.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用一个简单的领域模型-Employee\u003c/li\u003e\n\u003cli\u003e使用RestController返回发布者生产的数据\u003c/li\u003e\n\u003cli\u003e使用WebClient构建订阅者获取发布者数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebFlux Maven依赖如下：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e  \u0026lt;dependency\u0026gt;\r\n      \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\n      \u0026lt;artifactId\u0026gt;spring-boot-starter-webflux\u0026lt;/artifactId\u0026gt;\r\n  \u0026lt;/dependency\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e发布者（Publisher）\u003c/strong\u003e\u003cbr\u003e\nWebFlux底层使用Project Reactor，所以我们这里使用Project Reactor的命名来介绍。\u003c/p\u003e\n\u003cp\u003e发布者有两个类型：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMono类型表示生产0个或者至多1个数据\u003c/li\u003e\n\u003cli\u003eFlux类型表示生产多个数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e示例代码分为三层分别是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003econtroller-获取REST请求，并返回订阅数据\u003c/li\u003e\n\u003cli\u003emodel-包含Employee领域模型\u003c/li\u003e\n\u003cli\u003erepository-构建内存数据库（采用HashMap)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003econtroller:\u003cbr\u003e\n可以看到方法返回类型为Mono或者Flux，表示生产者会生产对应类型个数的数据\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e@RestController\r\n@RequestMapping(\u0026#34;/employees\u0026#34;)\r\npublic class EmployeeController {\r\n    private static final Logger logger = LoggerFactory.getLogger(EmployeeController.class);\r\n\r\n    private final EmployeeRepository employeeRepository;\r\n\r\n    public EmployeeController(EmployeeRepository employeeRepository) {\r\n        this.employeeRepository = employeeRepository;\r\n    }\r\n\r\n    @GetMapping(\u0026#34;/{id}\u0026#34;)\r\n    private Mono\u0026lt;Employee\u0026gt; getEmployeeById(@PathVariable String id) {\r\n        logger.debug(\u0026#34;getEmplyeeById controller get called\u0026#34;);\r\n        return employeeRepository.findEmployeeById(id);\r\n    }\r\n\r\n    @GetMapping\r\n    private Flux\u0026lt;Employee\u0026gt; getAllEmployees() {\r\n        logger.debug(\u0026#34;getAllEmployees controller get called\u0026#34;);\r\n        return employeeRepository.findAllEmployees();\r\n    }\r\n\r\n    @PostMapping(\u0026#34;/update\u0026#34;)\r\n    private Mono\u0026lt;Employee\u0026gt; updateEmployee(@RequestBody Employee employee) {\r\n        return employeeRepository.updateEmployee(employee);\r\n    }\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003emodel：\u003cbr\u003e\n很简单的领域模型Employee包含id和name两个字段\u003c/p\u003e","title":"使用WebFlux进行响应式编程（using webflux in reactive programming)"},{"content":"过去十年互联网用户数呈指数级增长，各类网络服务访问数量也随之持续增长。为了应对持续增长的访问需求，各种技术被重新赋予了新的活力。微服务，DDD，响应式编程等技术被重新改进用于应对以上问题。本文着重讨论响应式编程背后的原理，帮助读者理解并应用于实际的开发中。\n响应式宣言\n说到响应式编程首先要引入一个概念响应式系统（Reactvie Systems)。回到2013年Jonas Boner领导的开发团队提出了响应式宣言，其中定义了响应式系统一系列核心原则.主要描述了该系统应具备灵活性，松耦合以及可扩展性.原则描述了响应式系统的基础特性：\n可响应性：一个响应式系统应提供快速和一致的响应时间，以及一致的服务质量 可复原性：一个响应式系统在随机失败的情况下，通过复制和隔离能力保持响应 可伸缩性：一个响应式系统在不可预测的负载下，通过经济的可扩展性保持响应 消息驱动：系统组件之间应通过异步消息机制进行通信 响应式编程要解决什么问题\n在非响应式同步调用的系统中两个服务是怎么调用的呢？假设我们有A，B，2个服务，当服务A调用服务B后（request），服务B开始处理收到的请求，这个时候服务A的线程会被阻塞住（idle），等待服务B处理完成后返回响应给服务A（respond），这时服务A线程被唤起继续处理接下来的逻辑。 这是我们常用的同步调用方式，他最大的问题是会使资源经常处于idle状态，没有充分利用我们的资源，对资源浪费很大。例如服务A调用服务B的线程在调用后就被阻塞住，不能做其他的事情，直到服务B响应为止。我们知道系统的线程要占用CPU周期，内存等硬件资源，并且极其有限。\n那么响应式编程的目标就是解决资源浪费问题，最高效地使用资源。这里我们看到服务A线程调用服务B后，并未等待服务B处理完成，便开始处理其他逻辑，所以服务B的单个线程可以不断调用服务B。那么服务B也可以不间断的收到大量的请求进行处理，这里A，B两个服务都高效的利用了资源。\n响应式编程背后的原理\n这怎么实现呢？当服务A调用服务B的时候，AB服务之间建立了一个订阅通道，通道建立好以后，服务A线程就去处理其他逻辑，等服务B处理完请求准备好数据后，便会通知服务A数据已经准备好了，这个时候服务A会有一个独立的线程池去获取服务B的数据，这样就实现了同步调用/异步响应的调用方式。\n这里有几个响应式编程重要的核心概念：\n发布者(The Publisher): 发布者就是数据的生产者，这个是为系统生产数据的组件，这里的服务B就是一个发布者，他收到服务A的请求后就开始生产数据。\n订阅者(The Subscriber): 订阅者订阅发布者生产的数据。这里服务A就是订阅者，他订阅来自服务B的数据。\n订阅过程(The Subscription):订阅过程是一份服务之间的合约（contract)，它被用于订阅者获取数据，或者取消订阅。\n处理者(The Processor):处理者是一个响应式实体，他能够消费发布者的数据，并进行再加工，然后发布自己的数据，上面的例子并未体现这层逻辑。举个例子，排序处理者，他可以作为订阅者获取发布者的随机序数据，然后进行排序，然后作为发布者生产出排序后的数据。\n背压机制(Backpressure Mechanism)\n前面说到响应式编程包含发布者生产数据，订阅者订阅数据，很自然想到当发布者生产数据的速度和订阅者消费数据的速度不匹配的问题，特别是快于订阅者能消费数据的速度，这时系统就是出现问题，订阅者就会被过量的数据淹没。\n响应式编程是为了高效的利用系统资源，总不能把系统服务打垮了吧。这时我们在设计系统的时候会引入背压机制来控制发布者和订阅者之间的平衡。\n一般我们通过三种策略来调控速率：\n控制发布者发送数据的速率（推荐） 订阅者使用缓存来存储暂时无法处理的数据 订阅者丢弃所有无法处理的数据 为了达到系统的高效运行，通过背压机制，使发布者和订阅者速率达到平衡，也就是根据消费能力来按需生产和发送数据，生产多少，就消费多少，用前面的A，B服务的例子来说明：\n服务A给服务B发送一个request请求1个数据，服务B的生产完成1个数据的时候，就通知服务A（onNext）有个数据就绪了,服务A就以同样的速率处理数据，这样服务B生产速率就被服务A限制，A，B两个服务就工作在同样的速率，这样系统效率达到最佳。\n在这里讲完了响应式编程的核心原理，下一篇《使用WebFlux进行响应式编程》会继续深入讨论响应式编程在代码中的实现。\n","permalink":"https://kmnemon.github.io/posts/2022-03-20-understanding-reactive-programming/","summary":"\u003cp\u003e过去十年互联网用户数呈指数级增长，各类网络服务访问数量也随之持续增长。为了应对持续增长的访问需求，各种技术被重新赋予了新的活力。微服务，DDD，响应式编程等技术被重新改进用于应对以上问题。本文着重讨论响应式编程背后的原理，帮助读者理解并应用于实际的开发中。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e响应式宣言\u003c/strong\u003e\u003cbr\u003e\n说到响应式编程首先要引入一个概念响应式系统（Reactvie Systems)。回到2013年Jonas Boner领导的开发团队提出了响应式宣言，其中定义了响应式系统一系列核心原则.主要描述了该系统应具备灵活性，松耦合以及可扩展性.原则描述了响应式系统的基础特性：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e可响应性：一个响应式系统应提供快速和一致的响应时间，以及一致的服务质量\u003c/li\u003e\n\u003cli\u003e可复原性：一个响应式系统在随机失败的情况下，通过复制和隔离能力保持响应\u003c/li\u003e\n\u003cli\u003e可伸缩性：一个响应式系统在不可预测的负载下，通过经济的可扩展性保持响应\u003c/li\u003e\n\u003cli\u003e消息驱动：系统组件之间应通过异步消息机制进行通信\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e响应式编程要解决什么问题\u003c/strong\u003e\u003cbr\u003e\n在非响应式同步调用的系统中两个服务是怎么调用的呢？假设我们有A，B，2个服务，当服务A调用服务B后（request），服务B开始处理收到的请求，这个时候服务A的线程会被阻塞住（idle），等待服务B处理完成后返回响应给服务A（respond），这时服务A线程被唤起继续处理接下来的逻辑。 \u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2022-03-20-understanding-reactive-programming/reactive-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这是我们常用的同步调用方式，他最大的问题是会使资源经常处于idle状态，没有充分利用我们的资源，对资源浪费很大。例如服务A调用服务B的线程在调用后就被阻塞住，不能做其他的事情，直到服务B响应为止。我们知道系统的线程要占用CPU周期，内存等硬件资源，并且极其有限。\u003c/p\u003e\n\u003cp\u003e那么响应式编程的目标就是解决资源浪费问题，最高效地使用资源。这里我们看到服务A线程调用服务B后，并未等待服务B处理完成，便开始处理其他逻辑，所以服务B的单个线程可以不断调用服务B。那么服务B也可以不间断的收到大量的请求进行处理，这里A，B两个服务都高效的利用了资源。\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2022-03-20-understanding-reactive-programming/reactive-2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e响应式编程背后的原理\u003c/strong\u003e\u003cbr\u003e\n这怎么实现呢？当服务A调用服务B的时候，AB服务之间建立了一个订阅通道，通道建立好以后，服务A线程就去处理其他逻辑，等服务B处理完请求准备好数据后，便会通知服务A数据已经准备好了，这个时候服务A会有一个独立的线程池去获取服务B的数据，这样就实现了同步调用/异步响应的调用方式。\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2022-03-20-understanding-reactive-programming/reactive-3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这里有几个响应式编程重要的核心概念：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e发布者(The Publisher): \u003c/strong\u003e发布者就是数据的生产者，这个是为系统生产数据的组件，这里的服务B就是一个发布者，他收到服务A的请求后就开始生产数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e订阅者(The Subscriber): \u003c/strong\u003e订阅者订阅发布者生产的数据。这里服务A就是订阅者，他订阅来自服务B的数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e订阅过程(The Subscription):\u003c/strong\u003e订阅过程是一份服务之间的合约（contract)，它被用于订阅者获取数据，或者取消订阅。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e处理者(The Processor):\u003c/strong\u003e处理者是一个响应式实体，他能够消费发布者的数据，并进行再加工，然后发布自己的数据，上面的例子并未体现这层逻辑。举个例子，排序处理者，他可以作为订阅者获取发布者的随机序数据，然后进行排序，然后作为发布者生产出排序后的数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e背压机制(Backpressure Mechanism)\u003c/strong\u003e\u003cbr\u003e\n前面说到响应式编程包含发布者生产数据，订阅者订阅数据，很自然想到当发布者生产数据的速度和订阅者消费数据的速度不匹配的问题，特别是快于订阅者能消费数据的速度，这时系统就是出现问题，订阅者就会被过量的数据淹没。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2022-03-20-understanding-reactive-programming/reactive-4.png\"\u003e\u003c/p\u003e\n\u003cp\u003e响应式编程是为了高效的利用系统资源，总不能把系统服务打垮了吧。这时我们在设计系统的时候会引入背压机制来控制发布者和订阅者之间的平衡。\u003c/p\u003e\n\u003cp\u003e一般我们通过三种策略来调控速率：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e控制发布者发送数据的速率（推荐）\u003c/li\u003e\n\u003cli\u003e订阅者使用缓存来存储暂时无法处理的数据\u003c/li\u003e\n\u003cli\u003e订阅者丢弃所有无法处理的数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2022-03-20-understanding-reactive-programming/reactive-5.png\"\u003e\u003c/p\u003e\n\u003cp\u003e为了达到系统的高效运行，通过背压机制，使发布者和订阅者速率达到平衡，也就是根据消费能力来按需生产和发送数据，生产多少，就消费多少，用前面的A，B服务的例子来说明：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2022-03-20-understanding-reactive-programming/reactive-6.png\"\u003e\u003c/p\u003e\n\u003cp\u003e服务A给服务B发送一个request请求1个数据，服务B的生产完成1个数据的时候，就通知服务A（onNext）有个数据就绪了,服务A就以同样的速率处理数据，这样服务B生产速率就被服务A限制，A，B两个服务就工作在同样的速率，这样系统效率达到最佳。\u003c/p\u003e\n\u003cp\u003e在这里讲完了响应式编程的核心原理，下一篇《使用WebFlux进行响应式编程》会继续深入讨论响应式编程在代码中的实现。\u003c/p\u003e","title":"理解响应式编程（reactive programming)"},{"content":"我们常说代码除了满足功能需求以外，还应该满足以后的可读性，可测性，可扩展性，可维护性等。我们常常看到两种类型的团队，一类团队软件开发流程里面只有开发+测试，常常处于加班状态，不断的赶新功能上线。另一类团队有完善的软件开发过程，迭代开发，同行评审，单元测试，自动化测试等。主观觉得第二类团队的代码质量应该比较高，可我们对这两类团队的代码到底怎么样，除了一般常用的sonar，findbugs等静态扫描工具的数据，就没太多的了解。除非深入学习业务逻辑，并剖析源代码。\n代码的抽象性，决定了代码以后是否容易扩展，抽象性高的代码易于通过继承的方式进行扩展，抽象性低的代码更容易出现复制-粘贴的扩展方式。代码被别的类依赖多，导致代码不容易变化，反之代码可变性就很高。如果从这两个方面考虑代码的设计，就提供了更多的维度了解团队代码的健康度。\n我们以模块为基本单位，统计整个系统每个模块的抽象性和依赖性:\n代码抽象性\nNc:模块内类的数量 Na:模块内抽象类和接口的数量 A：代码抽象性 A = Na / Nc 那么这个值的区间是[0,1]\n代码依赖易变性\nFan-in:进入的依赖。模块外有多少个类依赖于该模块内部类。 Fan-out:出去的依赖。模块内有多少个类依赖于模块外部的类。 代码依赖易变性： I = Fan-out/(Fan-in + Fan-out) 值区间[0,1]\n举个例子: 上图Fan-in=3, Fan-out=1 模块依赖易变性 I=1/(3+1)\n如果我们把代码抽象性和依赖性放入到二维坐标轴，x坐标是代码依赖易变性，Y坐标是代码的抽象性。然后在图里面最高抽象性（左上角）到最高抽象易变性（右下角）划一条对角线，这条线叫主道线。 我们在上图可以看到三个区域1.痛苦区 2.无用区 3.主道线区\n处在痛苦区的模块里面类的抽象性不足，同时极度的稳定，依赖易变性低。这种模块可扩展性不足因为抽象性低，同时被多个模块依赖，不能轻易改变。如果要扩展这个模块的功能，就会产生大量的复制-粘贴重复代码。有一个例外就是基础工具模块，这类模块的特征就是处于极度稳定，并不需要抽象性，所以这类工具模块处于这个区间是合理的。\n处在无用区的模块里面类的抽象性很高，但没有类去使用所以依赖易变性也很高。这个区间的模块包含大量的抽象类和接口，但没有外部模块使用它，所以变成了无用的模块。\n结论是我们期望一个系统大部分的模块都处于主道线区，不要偏离主道线太远。如果一个模块的二维坐标到主道线的距离过远比如达到0.5，那么这个模块值得打开深入分析里面的类的抽象性与依赖性是否合理。\n这里我写了一个工具可以分析java代码的抽象性与依赖性供参考： GitHub\n","permalink":"https://kmnemon.github.io/posts/2021-08-10-programming-dependency/","summary":"\u003cp\u003e我们常说代码除了满足功能需求以外，还应该满足以后的可读性，可测性，可扩展性，可维护性等。我们常常看到两种类型的团队，一类团队软件开发流程里面只有开发+测试，常常处于加班状态，不断的赶新功能上线。另一类团队有完善的软件开发过程，迭代开发，同行评审，单元测试，自动化测试等。主观觉得第二类团队的代码质量应该比较高，可我们对这两类团队的代码到底怎么样，除了一般常用的sonar，findbugs等静态扫描工具的数据，就没太多的了解。除非深入学习业务逻辑，并剖析源代码。\u003c/p\u003e\n\u003cp\u003e代码的抽象性，决定了代码以后是否容易扩展，抽象性高的代码易于通过继承的方式进行扩展，抽象性低的代码更容易出现复制-粘贴的扩展方式。代码被别的类依赖多，导致代码不容易变化，反之代码可变性就很高。如果从这两个方面考虑代码的设计，就提供了更多的维度了解团队代码的健康度。\u003c/p\u003e\n\u003cp\u003e我们以模块为基本单位，统计整个系统每个模块的抽象性和依赖性:\u003cbr\u003e\n\u003cstrong\u003e代码抽象性\u003c/strong\u003e\u003cbr\u003e\nNc:模块内类的数量\nNa:模块内抽象类和接口的数量\nA：代码抽象性 A = Na / Nc\n那么这个值的区间是[0,1]\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e代码依赖易变性\u003c/strong\u003e\u003cbr\u003e\nFan-in:进入的依赖。模块外有多少个类依赖于该模块内部类。\nFan-out:出去的依赖。模块内有多少个类依赖于模块外部的类。\n代码依赖易变性： I = Fan-out/(Fan-in + Fan-out)\n值区间[0,1]\u003c/p\u003e\n\u003cp\u003e举个例子:\n\u003cimg loading=\"lazy\" src=\"/images/2021-08-10-programming-dependency/class_instability.png\"\u003e\n上图Fan-in=3, Fan-out=1\n模块依赖易变性 I=1/(3+1)\u003c/p\u003e\n\u003cp\u003e如果我们把代码抽象性和依赖性放入到二维坐标轴，x坐标是代码依赖易变性，Y坐标是代码的抽象性。然后在图里面最高抽象性（左上角）到最高抽象易变性（右下角）划一条对角线，这条线叫主道线。\n\u003cimg loading=\"lazy\" src=\"/images/2021-08-10-programming-dependency/code_coordinate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e我们在上图可以看到三个区域1.痛苦区 2.无用区 3.主道线区\u003c/p\u003e\n\u003cp\u003e处在痛苦区的模块里面类的抽象性不足，同时极度的稳定，依赖易变性低。这种模块可扩展性不足因为抽象性低，同时被多个模块依赖，不能轻易改变。如果要扩展这个模块的功能，就会产生大量的复制-粘贴重复代码。有一个例外就是基础工具模块，这类模块的特征就是处于极度稳定，并不需要抽象性，所以这类工具模块处于这个区间是合理的。\u003c/p\u003e\n\u003cp\u003e处在无用区的模块里面类的抽象性很高，但没有类去使用所以依赖易变性也很高。这个区间的模块包含大量的抽象类和接口，但没有外部模块使用它，所以变成了无用的模块。\u003c/p\u003e\n\u003cp\u003e结论是我们期望一个系统大部分的模块都处于主道线区，不要偏离主道线太远。如果一个模块的二维坐标到主道线的距离过远比如达到0.5，那么这个模块值得打开深入分析里面的类的抽象性与依赖性是否合理。\u003c/p\u003e\n\u003cp\u003e这里我写了一个工具可以分析java代码的抽象性与依赖性供参考：\n\u003ca href=\"https://github.com/kmnemon/codeAnalysis.git\"\u003eGitHub\u003c/a\u003e\u003c/p\u003e","title":"代码抽象性与依赖性"},{"content":"经历了太多乱七八糟的产品和项目，听到了很多有趣的猜想和假设，我把他称之为\u0026quot;研发大猜想\u0026quot;\n猜想1：这个系统架构和代码太烂了，我们重新做个2.0系统吧，前面的问题就都解决了 感觉好像新做的2.0代码就不会和1.0系统一样烂了，结果就是和以前一样前期赶需求，后期集中测试，什么设计，什么内建质量都是太浪费时间，最后搞了大半年搞出了跟1.0一模一样的代码烂泥。怎么办喃，还可以3.0嘛。\n\u0026ldquo;如果不改变做事的方式，永远都只能做出一样的系统\u0026rdquo;\n猜想2：因为业务要的太急，所以我们没有时间写单元测试，没有时间做代码评审 听着很有道理，就好像不那么忙的时候，他们就会写单元测试了。实际上他们从来没写过单元测试，也永远不会去写。因为从思想上就没有理解什么是合格的代码。一个合格的程序员交付给测试人员的代码应该是很难再测出问题，测试人员花大量的努力都无法验伪的程序。这个才是一个刚刚合格的程序，因为这方面仅仅是功能无问题，还要涉及设计的合理性，抽象性，耦合性，代码可测性等代码结构事宜。\n\u0026ldquo;一个合格的程序员，应该有这样的品质：自己写的代码，应该在功能上很难验伪，在设计上保持代码健康。\u0026rdquo;\n猜想3：业务两周就要一个版本，连回归测试的时间就不够，我们干脆把版本周期加长，然后搞几个前后并行的版本，这样人处于最忙状态，研发就最快了 在集成测试阶段开发人员有空闲，所以下个并行版本要进入到开发阶段。最好在第三个并行版本进入到需求分析阶段，这样大家就看起来都很忙了。下面的人保持最忙的状态，才显得上面的人员指挥恰当。 结果就是搞需求的时候，还要同时搞开发，搞缺陷，搞开发的时候还要同时搞上版本缺陷修复，每个事情都没做好。结果是需求没有搞清楚，开发设计一团乱，缺陷一大堆，就这样往复循环。但每个人都很忙，真的很忙。\n\u0026ldquo;好好体验一下，做好每件事情，大脑处于专注流的状态\u0026rdquo;\n猜想4：一个功能需求写了很多复杂逻辑，各种场景覆盖，产品经理的价值体现就在能把事情考虑周全 写产品需求是很枯燥的事情，不是某个领域熟悉的人，却想写出解决这个领域问题的产品需求，还要能读懂使用者最终怎么用这个产品，同时还想产品功能面面俱到。遇到这样的产品经理，研发团队是痛苦的，平白的做了大量的复杂业务逻辑。最后用户认为功能难用，不能解决问题，推翻重做，产品经理美其名曰“我在试错”。这样的产品经理从来考虑不清楚，这些功能的价值是什么，能解决什么问题。拍脑袋写大量的文档是他们最喜欢的事情，为什么呢？因为不用思考。 殊不知就算你熟悉这个领域，也不该一开始设计复杂的功能逻辑。简单即是美，往往是简单的功能才能解决用户问题。\n\u0026ldquo;优秀的产品经理真的很稀有\u0026rdquo;\n猜想5：项目会有紧急需求，遇到紧急需求的项目要加人，我的项目总是缺人，要多补充人，就能把事情完成 人能解决所有的问题，人多我就什么都能搞。不了解沟通的耗费，不了解优秀程序员和劣质能写hello world 人的区别，不了解往进行中项目加人的影响。只想通过加人解决问题。问题真的是人不够吗？ 你见过谁说我的项目人太多了，需求太少的事情吗？\n\u0026ldquo;问题的本质真的很重要\u0026rdquo;\n猜想6：项目大部分是倒排期，不合理 按照估算排期就是正确的？怎么证明按照估算排期就是正确的？我倒是觉得估算排期证伪比较容易。看看历史数据估算和实际偏差有多大就知道了。 \u0026ldquo;所以动态规划就很重要了\u0026rdquo;，实时的适应变化，这个迭代需求多了，减少点， 需求少了，增加点。要满足某个倒排期的市场需求，去找寻mvp。\n猜想7: 我们团队没有产品经理，团队无法明确需求，需求经常做偏 程序员要做好两件事情，搞明白要做什么，正确的做出来。有了产品经理，就指望这个人把做什么搞明白，再告诉你。做的东西用户不满意就是产品经理的问题。你再不用了解用户遇到什么问题，也不用思考怎样能解决用户的问题。没有产品经理，你就什么都不会了。 你都不想理解问题，就开始写代码.\n\u0026ldquo;难道真的是不要把爱好变成工作？\u0026rdquo;\n","permalink":"https://kmnemon.github.io/posts/2021-07-27-programming-conjecture/","summary":"\u003cp\u003e经历了太多乱七八糟的产品和项目，听到了很多有趣的猜想和假设，我把他称之为\u0026quot;研发大猜想\u0026quot;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e猜想1：这个系统架构和代码太烂了，我们重新做个2.0系统吧，前面的问题就都解决了\u003c/strong\u003e\n感觉好像新做的2.0代码就不会和1.0系统一样烂了，结果就是和以前一样前期赶需求，后期集中测试，什么设计，什么内建质量都是太浪费时间，最后搞了大半年搞出了跟1.0一模一样的代码烂泥。怎么办喃，还可以3.0嘛。\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;如果不改变做事的方式，永远都只能做出一样的系统\u0026rdquo;\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e猜想2：因为业务要的太急，所以我们没有时间写单元测试，没有时间做代码评审\u003c/strong\u003e\n听着很有道理，就好像不那么忙的时候，他们就会写单元测试了。实际上他们从来没写过单元测试，也永远不会去写。因为从思想上就没有理解什么是合格的代码。一个合格的程序员交付给测试人员的代码应该是很难再测出问题，测试人员花大量的努力都无法验伪的程序。这个才是一个刚刚合格的程序，因为这方面仅仅是功能无问题，还要涉及设计的合理性，抽象性，耦合性，代码可测性等代码结构事宜。\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;一个合格的程序员，应该有这样的品质：自己写的代码，应该在功能上很难验伪，在设计上保持代码健康。\u0026rdquo;\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e猜想3：业务两周就要一个版本，连回归测试的时间就不够，我们干脆把版本周期加长，然后搞几个前后并行的版本，这样人处于最忙状态，研发就最快了\u003c/strong\u003e\n在集成测试阶段开发人员有空闲，所以下个并行版本要进入到开发阶段。最好在第三个并行版本进入到需求分析阶段，这样大家就看起来都很忙了。下面的人保持最忙的状态，才显得上面的人员指挥恰当。 结果就是搞需求的时候，还要同时搞开发，搞缺陷，搞开发的时候还要同时搞上版本缺陷修复，每个事情都没做好。结果是需求没有搞清楚，开发设计一团乱，缺陷一大堆，就这样往复循环。但每个人都很忙，真的很忙。\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;好好体验一下，做好每件事情，大脑处于专注流的状态\u0026rdquo;\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e猜想4：一个功能需求写了很多复杂逻辑，各种场景覆盖，产品经理的价值体现就在能把事情考虑周全\u003c/strong\u003e\n写产品需求是很枯燥的事情，不是某个领域熟悉的人，却想写出解决这个领域问题的产品需求，还要能读懂使用者最终怎么用这个产品，同时还想产品功能面面俱到。遇到这样的产品经理，研发团队是痛苦的，平白的做了大量的复杂业务逻辑。最后用户认为功能难用，不能解决问题，推翻重做，产品经理美其名曰“我在试错”。这样的产品经理从来考虑不清楚，这些功能的价值是什么，能解决什么问题。拍脑袋写大量的文档是他们最喜欢的事情，为什么呢？因为不用思考。\n殊不知就算你熟悉这个领域，也不该一开始设计复杂的功能逻辑。简单即是美，往往是简单的功能才能解决用户问题。\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;优秀的产品经理真的很稀有\u0026rdquo;\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e猜想5：项目会有紧急需求，遇到紧急需求的项目要加人，我的项目总是缺人，要多补充人，就能把事情完成\u003c/strong\u003e\n人能解决所有的问题，人多我就什么都能搞。不了解沟通的耗费，不了解优秀程序员和劣质能写hello world\n人的区别，不了解往进行中项目加人的影响。只想通过加人解决问题。问题真的是人不够吗？\n你见过谁说我的项目人太多了，需求太少的事情吗？\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;问题的本质真的很重要\u0026rdquo;\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e猜想6：项目大部分是倒排期，不合理\u003c/strong\u003e\n按照估算排期就是正确的？怎么证明按照估算排期就是正确的？我倒是觉得估算排期证伪比较容易。看看历史数据估算和实际偏差有多大就知道了。\n\u003cem\u003e\u0026ldquo;所以动态规划就很重要了\u0026rdquo;\u003c/em\u003e，实时的适应变化，这个迭代需求多了，减少点， 需求少了，增加点。要满足某个倒排期的市场需求，去找寻mvp。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e猜想7: 我们团队没有产品经理，团队无法明确需求，需求经常做偏\u003c/strong\u003e\n程序员要做好两件事情，搞明白要做什么，正确的做出来。有了产品经理，就指望这个人把做什么搞明白，再告诉你。做的东西用户不满意就是产品经理的问题。你再不用了解用户遇到什么问题，也不用思考怎样能解决用户的问题。没有产品经理，你就什么都不会了。\n你都不想理解问题，就开始写代码.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;难道真的是不要把爱好变成工作？\u0026rdquo;\u003c/em\u003e\u003c/p\u003e","title":"研发大猜想"},{"content":"组建团队的时候从算法到数据结构，从OO到template，从并发到协程，每个人都各有擅长。可整个团队交付的代码总是一团糟，总觉得还不如自己一个写全部代码好。本文尝试从软件流程和开发实践的角度分析内在原因。\n“软件工程”，我们先来看工程学wiki定义：“工程学、工程科学或工学，是通过研究与实践应用数学、自然科学、 社会学等基础学科的知识，以达到改良各行业中现有材料、土木建筑、机械、电机电子、仪器、系统、 化学和加工步骤的设计和应用方式一门学科，而实践与研究工程学的人称为工程师。在高等学府中， 将自然科学原理应用至服务业、工业、农业等各个生产部门所形成的诸多工程学科也称为工科和工学。”\n个人不是很喜欢这个词，因为早期软件工程和土木工程建筑设计流程很相识。无法确定瀑布开发方式是否参照了土木工程。\n如果我们要造一座桥大致会有如下关键流程：\n如果用瀑布流程开发软件：\n流程是不是很相似，建筑行业几千年的经验总结，沉淀，产生了无数的建筑奇迹。这套建筑工程流程经过了无数的实践，会有很大问题吗？我认为不会。那软件行业参照这套流程设计可行吗？看隔壁日本这套流程玩的溜起来，但这套流程需满足建筑行业的几个基本条件。\n条件1:施工人员严格按照流程的要求施工\n条件2:一开始问题想的很清楚，到了施工阶段，需求变更很少，甚至几乎没有\n条件3:足够的时间完成项目\n瀑布流程里面每个流程都是环环相扣，a.每个流程都是由具备相应能力的人员完成，b.缺少任何一个环节都会导致后续动作直接变形。\n建筑行业中“初步设计，技术设计，施工设计”都是由相应具备能力的建设设计师，结构力学工程师等协作完成。对应于软件行业里面“架构设计，概要设计，详细设计”，现实中架构设计由架构师参与完成，但概要设计，详细设计架构师很少参与，大多是由负责相应开发功能的开发人员完成。如果要类比建筑行业就是技术设计和施工设计由施工人员完成？！所以团队成员是否具备概要设计和详细设计能力会直接影响你后续的编码活动。\n裁剪，瀑布流程里面我听到最多的就是这个词语。“详细设计浪费时间裁剪掉”，“单元测试没能力做，裁剪掉”，“代码检视没时间做，裁剪掉”，一个好端端的流程被你裁剪成只剩开发和测试，你说团队做出的东西不是一坨翔，你信吗？软件开发是你想的那么简单吗。\n但软件毕竟不是建筑。软件的要解决的问题千奇百怪，很难一次想明白，软件变更成本相比建筑行业低太多。同时很多时候产品需要快速上线，无法接受瀑布流程的一个月甚至几个月的交付周期。所以瀑布流程需要满足的几个条件，在现在看来很难满足。在这种环境下用这套流程开发，自己是有多想不开。\n敏捷开发流程就是在这种环境下应运而生。解决方案一开始想不清楚，先做个MVP来看看。需求变化多，采用迭代的方式缓解。用户量随时间增长，架构根据需要调整。\n但敏捷开发在缩短迭代周期到2周以后，相应的开发实践都需要做相应的调整来适应开发流程的变化。\n极限编程基本实践：\n越是缩短交付周期，这些基础实践越重要，可以说如果不进行这些基础实践，根本不可能高质量1～2周交付。可经历过所谓瀑布开发流程的裁剪者们又来实践敏捷了，“UT太难写了，不写了”，“重构，不存在的”，“代码检视，太浪费时间了”，最后敏捷开发又变成了，两周只有开发和测试的活动。\n这些裁剪者们往往从来没有写过UT，没有感受过UT对调试代码的益处，对重构的帮助。也没从来了解过优秀团队怎么做代码检视(https://google.github.io/eng-practices/review/), 然后他们拍脑袋本能的觉得除了本能开发一切都不重要。不去借鉴业界优秀的实践。\n任何开发流程我认为有两个核心作用：帮助团队高效协作，帮助不同能力的团队成员都输出较高质量的代码。\n如果你有幸和一群技术高手共事，那你可以看到他们用更多的开发实践去高效协作。\n如果你所在的团队成员能力高低不平，做扎实基础实践和流程去帮助团队成员。\n如果你所在的团队能力一般，整个交付过程，只有开发和测试，自求多福吧。\n","permalink":"https://kmnemon.github.io/posts/2021-04-08-agile-team-deliver/","summary":"\u003cp\u003e组建团队的时候从算法到数据结构，从OO到template，从并发到协程，每个人都各有擅长。可整个团队交付的代码总是一团糟，总觉得还不如自己一个写全部代码好。本文尝试从软件流程和开发实践的角度分析内在原因。\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e“软件工程”，我们先来看工程学wiki定义：“工程学、工程科学或工学，是通过研究与实践应用数学、自然科学、\n社会学等基础学科的知识，以达到改良各行业中现有材料、土木建筑、机械、电机电子、仪器、系统、\n化学和加工步骤的设计和应用方式一门学科，而实践与研究工程学的人称为工程师。在高等学府中，\n将自然科学原理应用至服务业、工业、农业等各个生产部门所形成的诸多工程学科也称为工科和工学。”\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e个人不是很喜欢这个词，因为早期软件工程和土木工程建筑设计流程很相识。无法确定瀑布开发方式是否参照了土木工程。\u003c/p\u003e\n\u003cp\u003e如果我们要造一座桥大致会有如下关键流程：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2021-04-08-agile--team-deliver/engineer_phase.png\"\u003e\u003c/p\u003e\n\u003cp\u003e如果用瀑布流程开发软件：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2021-04-08-agile--team-deliver/waterfall_phase.png\"\u003e\u003c/p\u003e\n\u003cp\u003e流程是不是很相似，建筑行业几千年的经验总结，沉淀，产生了无数的建筑奇迹。这套建筑工程流程经过了无数的实践，会有很大问题吗？我认为不会。那软件行业参照这套流程设计可行吗？看隔壁日本这套流程玩的溜起来，但这套流程需满足建筑行业的几个基本条件。\u003c/p\u003e\n\u003cp\u003e条件1:施工人员严格按照流程的要求施工\u003c/p\u003e\n\u003cp\u003e条件2:一开始问题想的很清楚，到了施工阶段，需求变更很少，甚至几乎没有\u003c/p\u003e\n\u003cp\u003e条件3:足够的时间完成项目\u003c/p\u003e\n\u003cp\u003e瀑布流程里面每个流程都是环环相扣，a.每个流程都是由具备相应能力的人员完成，b.缺少任何一个环节都会导致后续动作直接变形。\u003c/p\u003e\n\u003cp\u003e建筑行业中“初步设计，技术设计，施工设计”都是由相应具备能力的建设设计师，结构力学工程师等协作完成。对应于软件行业里面“架构设计，概要设计，详细设计”，现实中架构设计由架构师参与完成，但概要设计，详细设计架构师很少参与，大多是由负责相应开发功能的开发人员完成。如果要类比建筑行业就是技术设计和施工设计由施工人员完成？！所以团队成员是否具备概要设计和详细设计能力会直接影响你后续的编码活动。\u003c/p\u003e\n\u003cp\u003e裁剪，瀑布流程里面我听到最多的就是这个词语。“详细设计浪费时间裁剪掉”，“单元测试没能力做，裁剪掉”，“代码检视没时间做，裁剪掉”，一个好端端的流程被你裁剪成只剩开发和测试，你说团队做出的东西不是一坨翔，你信吗？软件开发是你想的那么简单吗。\u003c/p\u003e\n\u003cp\u003e但软件毕竟不是建筑。软件的要解决的问题千奇百怪，很难一次想明白，软件变更成本相比建筑行业低太多。同时很多时候产品需要快速上线，无法接受瀑布流程的一个月甚至几个月的交付周期。所以瀑布流程需要满足的几个条件，在现在看来很难满足。在这种环境下用这套流程开发，自己是有多想不开。\u003c/p\u003e\n\u003cp\u003e敏捷开发流程就是在这种环境下应运而生。解决方案一开始想不清楚，先做个MVP来看看。需求变化多，采用迭代的方式缓解。用户量随时间增长，架构根据需要调整。\u003c/p\u003e\n\u003cp\u003e但敏捷开发在缩短迭代周期到2周以后，相应的开发实践都需要做相应的调整来适应开发流程的变化。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e极限编程基本实践：\u003c/strong\u003e\u003c/p\u003e\n\u003cimg src=\"/images/2021-04-08-agile--team-deliver/XP.png\" width = \"400\" height=\"500\" /\u003e  \r\n\u003cp\u003e越是缩短交付周期，这些基础实践越重要，可以说如果不进行这些基础实践，根本不可能高质量1～2周交付。可经历过所谓瀑布开发流程的裁剪者们又来实践敏捷了，“UT太难写了，不写了”，“重构，不存在的”，“代码检视，太浪费时间了”，最后敏捷开发又变成了，两周只有开发和测试的活动。\u003c/p\u003e\n\u003cp\u003e这些裁剪者们往往从来没有写过UT，没有感受过UT对调试代码的益处，对重构的帮助。也没从来了解过优秀团队怎么做代码检视(\u003cem\u003e\u003ca href=\"https://google.github.io/eng-practices/review/\"\u003ehttps://google.github.io/eng-practices/review/\u003c/a\u003e\u003c/em\u003e),  然后他们拍脑袋本能的觉得除了本能开发一切都不重要。不去借鉴业界优秀的实践。\u003c/p\u003e\n\u003cp\u003e任何开发流程我认为有两个核心作用：帮助团队高效协作，帮助不同能力的团队成员都输出较高质量的代码。\u003c/p\u003e\n\u003cp\u003e如果你有幸和一群技术高手共事，那你可以看到他们用更多的开发实践去高效协作。\u003c/p\u003e\n\u003cp\u003e如果你所在的团队成员能力高低不平，做扎实基础实践和流程去帮助团队成员。\u003c/p\u003e\n\u003cp\u003e如果你所在的团队能力一般，整个交付过程，只有开发和测试，自求多福吧。\u003c/p\u003e","title":"明明每个人能力感觉还好，为啥整个团队交付的代码很糟糕？"},{"content":"在敏捷开发中，我们用Product Backlog来承载需求的集合，里面包括需求的优先级以及排序等。进入迭代后用Sprint Backlog来表示迭代内的需求和任务。单个需求用User Story卡片来沟通。高效需求协作在团队规模较小时比较容易开展，但如果团队上了规模，多团队间怎么有效的进行需求沟通，怎么在多团队间进行高效的需求协作呢？以下分三种规模的敏捷团队进行探讨。\n1.单团队敏捷 在单团队敏捷中，采用典型的端到端交付敏捷特性团队，整个团队可以完成从需求到产品开发上线等一系列事情。从需求协作的角度来说，一般会经历3个重要的会议：\n1.Product Backlog Refinement工作坊\n2.Sprint Planning 1 会议\n3.Sprint Planning 2 会议\nProduct Backlog Refinement（PBR）工作坊，主要用于业务方，PO，用户，和团队一起了解下阶段业务目标，分析产品功能以支持业务目标，并对User Story进行拆分，组合，初步估算，同时对Product Backlog进行优先级排序\nSprint Planning 1 会议，PO和团队设定迭代目标，确定迭代内能完成多少User Story卡片，对卡片模糊部分进行再次澄清，对卡片进行再次估算和调整\nSprint Planning 2 会议，团队创建Sprint Backlog，并对迭代内要做的User Story卡片进行任务拆分，估算任务时间，同时领取任务（有些团队采用将Sprint Planning 1\u0026amp;2会议合并为一个会议）\n会议发生时间线如图：\n可以看出PBR会议在整个迭代期间多次进行，主要集中在迭代后期举行比较多，Sprint Planning会议一般集中在迭代第一天进行，但也有将Sprint Planning 1 会议在前一个迭代末进行，Sprint Planning 2在新迭代开始进行，这就是迭代内敏捷需求协作开展的活动。\n2.多团队敏捷 随着市场增长，对产品功能需求增多，产品特性上线时间要求更急迫，单个团队无法满足市场对软件推出速度的期望，这时就需要建立多个敏捷团队并行迭代开发。而且多个团队之间的需求可能具有依赖关系，这时需求协作就比单个敏捷团队复杂一些。敏捷团队结构可以有多种变化。针对PO角色来说一般有3种团队结构。\n最常见的一种是多个团队之间有主PO（CPO），每个团队内部有各自的团队PO（TPO）。\n第一种PO组织方式-CPO和Team PO\n在这种团队结构中，CPO负责整体Product Backlog的梳理，TPO负责迭代内需求的卡片的细化，为团队澄清需求，以及团队间依赖需求的协作沟通\n第二种是多团队之间有主PO（CPO），团队内部不再安排团队PO（TPO）。\n第二种PO组织方式-CPO\n这种结构要求团队和CPO紧密协作，CPO负责整体Product Backlog的安排，同时团队经常参与Product Backlog Refinement和CPO一起进行Product Backlog的梳理。团队也需要经常和业务方进行沟通，了解产品业务目标，以及设计怎样的产品方案以满足业务目标。在这种组织结构下团队对产品方案有更多的设计决策权。\n第三种是无主PO，团队里面有团队PO。\n第三种PO组织方式-只有团队PO\n这种方式并不推荐，但经常出现在采用敏捷的组织结构中，这个组织结构很容易造成团队各自为政，每个TPO只考虑自己团队的需求，需求依赖的团队间需求协作效率降低。容易出现A团队由于依赖B团队的一个需求，而产生等待现象。\n不管是哪种团队结构，有个原则是一个产品只建立一个Product Backlog，而不管内部有多少个敏捷特性团队。这里容易出现的敏捷反模式是每个团队都有一个Product Backlog.试想一下针对一个产品每个团队都有自己的PB，就会出现每个团队只关心团队内的PBI，失去对产品全景的理解，同时对PBI的排序只会针对本团队需求进行局部排序优化，缺乏对整个产品需求优先级进行调整的灵活性。而第三种PO结构最容易出现每个团队一个PB，没有一个统一的PB，团队间为了对齐需求花费大量沟通协调成本。\n在多团队敏捷中需求协作活动大致有如下几种：\n1.总体Product Backlog Refinement工作坊\n2.单团队或多团队Product Backlog Refinement工作坊\n3.总体Sprint Planning 1 会议\n4.单团队或多团队Sprint Planning 2 会议\n总体Product Backlog Refinement工作坊，由主PO发起，团队PO，团队代表，业务方等一起参加，主要对下迭代涉及到的Epic进行沟通，拆分，同时每个团队选取Epic或User Story卡片进行后续单团队或多团队Product Backlog Refinement工作坊分析，识别团队间需求的依赖关系\n单团队或多团队Product Backlog Refinement工作坊，需求间没有依赖的团队举行单团队PBR工作坊，团队内部进行Epic或User Story沟通，拆分，估算等，如果是需求间有依赖的多个团队，则举行多团队PBR，多个团队一起分析，沟通，拆分，并估算依赖部分的User Story\n总体Sprint Planning 1 会议，主PO，团队PO，团队代表一起参加，之前已经举行了PBR工作坊，再次对剩余模糊的需求问题进行澄清，同时多团队领取下迭代User Story卡片\n单团队或多团队Sprint Planning 2 会议，领取比较独立US卡片的团队召开单团队Sprint Planning 2 会议（和单敏捷团队的会议一致），领取卡片有关联关系的多个团队间举行多团队Sprint Planning 2 会议，团队间创建各自的Sprint Backlog，针对依赖部分进行集体澄清，估算，优先级调整，比较独立部分则团队各自进行澄清，估算。\n这些会议开展时间，如总体Product Backlog Refinement，单团队或多团队PBR工作坊会在一个迭代中持续开展，针对下个迭代的User Story进行沟通，拆分，AC编写，实例化需求编写。而总体Sprint Planning会议和单团队或多团队Sprint Planning 2 会议是在迭代第一天依次开展针对本迭代需求进行最后澄清，还有就是任务分解，评估，团队领取卡片等。\n3.规模化敏捷团队 产品进一步扩大，团队进一步扩充，现在一个产品可能由几十上百个团队，上千人一起协作开发。这时多敏捷团队模式无法高效进行协作，需求沟通效率降低。我们需要对组织结构进一步升级，对产品和团队进行领域划分。每个产品会产生多个领域，每个领域里面由8～10个团队在里面协作开发，同时多个领域并行开发，所有团队采用统一迭代的方式（迭代起止时间相同）。那么在需求协作方面有哪些变化呢？我们先来看看团队组织结构的变化：\n规模化敏捷组织\n在规模化团队的场景里，我们有个主PO（CPO），下面分别有领域PO（APO）进行协助，同时APO下面可能会有团队PO（TPO）。这时需求量变得庞大，有些组织继续使用每个产品一个Product Backlog的优秀实践，同时辅以User story mapping进行产品规划，还有些组织采用一个主Product Backlog，并拆分出几个Area Product Backlog，因为领域之间一般没有太多需求交集，不需要花很多时间对齐Area Product Backlog。在规模化敏捷里面，有点需要注意的是虽然敏捷里面推荐端到端的全特性团队，但在规模化的产品里会有中台或者PAAS等横向平台级的团队出现（如上图黄色部分），单个团队很难端到端完成整体需求交付，一个需求会跨越多个团队协作开发才能完成，规模化需求协作活动会有如下变化：\n1.Product Owner 团队会议\n2.领域总体Product Backlog Refinement工作坊\n3.领域单团队或多团队Product Backlog Refinement工作坊\n4.领域总体Sprint Planning 1 会议\n5.领域单团队或多团队Sprint Planning 2 会议\n新增Product Owner 团队会议\u0026ndash;CPO，APO，TPO参加，用来对齐组织战略，业务目标，产品目标，领域之间需要协作部分的讨论，同时拟定发布计划，一般每个迭代举行一次，为下个迭代的产品需求进行沟通。\n后面4个活动和“多敏捷团队“里面的活动基本一样，要注意的一点是，这些活动要让平台级团队TPO或技术代表参加，特别平台级团队横跨多个领域，就需要派团队代表参加所有涉及领域的会议，因为上层业务团队是平台级团队的用户。\n最后简述CPO，APO的职责：\nCPO作为主PO，负责产品方向，对齐公司战略和业务目标，对产品级的Product Backlog有决定权，并定义优先级，召开Product Owner 团队会议。还有就是参与评估Sprint review会议等。\nAPO作为领域PO，维护Product Backlog的领域部分，或者Area Product Backlog，参与Product Owner 团队会议，为Area Product Backlog优先级排序， 为多个团队澄清领域内需求，参与领域总体Product Backlog Refinement工作坊，领域总体Sprint Planning 1 会议。\n后记，XP和scrum提出的时候对大规模采用敏捷并无太多考虑，如果简单套用这些方法，会出现单团队的情况下效果提升，规模化后效率并不理想，就像一个巨人发育不良，左手大，右脚小，规模化敏捷还处于摸索状态，对银弹的摸索不会停歇，组织在采用规模化敏捷的道路上，会遇到各种问题，解决这些问题的核心思想是敏捷和精益的文，根据这些可以创造出属于自己且多样性的敏捷实践。\n","permalink":"https://kmnemon.github.io/posts/2020-10-25-agile-at-scale/","summary":"\u003cp\u003e在敏捷开发中，我们用Product Backlog来承载需求的集合，里面包括需求的优先级以及排序等。进入迭代后用Sprint Backlog来表示迭代内的需求和任务。单个需求用User Story卡片来沟通。高效需求协作在团队规模较小时比较容易开展，但如果团队上了规模，多团队间怎么有效的进行需求沟通，怎么在多团队间进行高效的需求协作呢？以下分三种规模的敏捷团队进行探讨。\u003c/p\u003e\n\u003ch2 id=\"1单团队敏捷\"\u003e1.单团队敏捷\u003c/h2\u003e\n\u003cp\u003e在单团队敏捷中，采用典型的端到端交付敏捷特性团队，整个团队可以完成从需求到产品开发上线等一系列事情。从需求协作的角度来说，一般会经历3个重要的会议：\u003c/p\u003e\n\u003cp\u003e1.Product Backlog Refinement工作坊\u003c/p\u003e\n\u003cp\u003e2.Sprint Planning 1 会议\u003c/p\u003e\n\u003cp\u003e3.Sprint Planning 2 会议\u003c/p\u003e\n\u003cp\u003eProduct Backlog Refinement（PBR）工作坊，主要用于业务方，PO，用户，和团队一起了解下阶段业务目标，分析产品功能以支持业务目标，并对User Story进行拆分，组合，初步估算，同时对Product Backlog进行优先级排序\u003c/p\u003e\n\u003cp\u003eSprint Planning 1 会议，PO和团队设定迭代目标，确定迭代内能完成多少User Story卡片，对卡片模糊部分进行再次澄清，对卡片进行再次估算和调整\u003c/p\u003e\n\u003cp\u003eSprint Planning 2 会议，团队创建Sprint Backlog，并对迭代内要做的User Story卡片进行任务拆分，估算任务时间，同时领取任务（有些团队采用将Sprint Planning 1\u0026amp;2会议合并为一个会议）\u003c/p\u003e\n\u003cp\u003e会议发生时间线如图：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2020-10-25-agile-at-scale/sprint-planning.png\"\u003e\u003c/p\u003e\n\u003cp\u003e可以看出PBR会议在整个迭代期间多次进行，主要集中在迭代后期举行比较多，Sprint Planning会议一般集中在迭代第一天进行，但也有将Sprint Planning 1 会议在前一个迭代末进行，Sprint Planning 2在新迭代开始进行，这就是迭代内敏捷需求协作开展的活动。\u003c/p\u003e\n\u003ch2 id=\"2多团队敏捷\"\u003e2.多团队敏捷\u003c/h2\u003e\n\u003cp\u003e随着市场增长，对产品功能需求增多，产品特性上线时间要求更急迫，单个团队无法满足市场对软件推出速度的期望，这时就需要建立多个敏捷团队并行迭代开发。而且多个团队之间的需求可能具有依赖关系，这时需求协作就比单个敏捷团队复杂一些。敏捷团队结构可以有多种变化。针对PO角色来说一般有3种团队结构。\u003c/p\u003e\n\u003cp\u003e最常见的一种是多个团队之间有主PO（CPO），每个团队内部有各自的团队PO（TPO）。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2020-10-25-agile-at-scale/less_team1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e第一种PO组织方式-CPO和Team PO\u003c/p\u003e\n\u003cp\u003e在这种团队结构中，CPO负责整体Product Backlog的梳理，TPO负责迭代内需求的卡片的细化，为团队澄清需求，以及团队间依赖需求的协作沟通\u003c/p\u003e\n\u003cp\u003e第二种是多团队之间有主PO（CPO），团队内部不再安排团队PO（TPO）。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2020-10-25-agile-at-scale/less_team2.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e第二种PO组织方式-CPO\u003c/p\u003e\n\u003cp\u003e这种结构要求团队和CPO紧密协作，CPO负责整体Product Backlog的安排，同时团队经常参与Product Backlog Refinement和CPO一起进行Product Backlog的梳理。团队也需要经常和业务方进行沟通，了解产品业务目标，以及设计怎样的产品方案以满足业务目标。在这种组织结构下团队对产品方案有更多的设计决策权。\u003c/p\u003e\n\u003cp\u003e第三种是无主PO，团队里面有团队PO。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2020-10-25-agile-at-scale/less_team3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e第三种PO组织方式-只有团队PO\u003c/p\u003e\n\u003cp\u003e这种方式并不推荐，但经常出现在采用敏捷的组织结构中，这个组织结构很容易造成团队各自为政，每个TPO只考虑自己团队的需求，需求依赖的团队间需求协作效率降低。容易出现A团队由于依赖B团队的一个需求，而产生等待现象。\u003c/p\u003e\n\u003cp\u003e不管是哪种团队结构，有个原则是一个产品只建立一个Product Backlog，而不管内部有多少个敏捷特性团队。这里容易出现的敏捷反模式是每个团队都有一个Product Backlog.试想一下针对一个产品每个团队都有自己的PB，就会出现每个团队只关心团队内的PBI，失去对产品全景的理解，同时对PBI的排序只会针对本团队需求进行局部排序优化，缺乏对整个产品需求优先级进行调整的灵活性。而第三种PO结构最容易出现每个团队一个PB，没有一个统一的PB，团队间为了对齐需求花费大量沟通协调成本。\u003c/p\u003e\n\u003cp\u003e在多团队敏捷中需求协作活动大致有如下几种：\u003c/p\u003e\n\u003cp\u003e1.总体Product Backlog Refinement工作坊\u003c/p\u003e","title":"规模化敏捷需求协作"},{"content":"最近项目组发版质量持续降低，生产事故接连不断，回家的路上陷入深思，明明几个月前还做的相当不错，质量稳步提升，虽不完美，但总算还在持续进步。到底什么原因导致现在的情况？随着思考不断深入，更多本质的问题浮到面上。（本文着重讨论开发，不涉及敏捷需求价值部分）\n人的素养： 手工艺人制造商品，从设计，制作，检验，并摆上商铺进行销售往往都是一个人完成。逛街的时候会遇到现场制作的手工艺人，一道工序，接另一道工序，最后组合成可用的商品，其中并没有看到做出来的东西需要另一个人单独测试，才能摆上商铺才能销售。大家往往习惯于此，但为什么我们的软件制作（开发）需要单独一个人或一组人帮你验证（测试），你自己开发的东西？你自己开发出来的东西，为什么有如此多的缺陷，如果不经过别人的验证，甚至不敢摆上商铺销售（上线）？\n优秀的软件工程师，完成一段代码，一个功能，无论从内在质量，还是外在质量都经得起推敲，甚至根本不用任何人帮助他验证，即可上线。他们在做自己功能的时候，会主动构建自动化测试，开发过程中不断重构自己代码，完成后还要经过自己多次验证，同时为了避免思维盲区，他们会采用结对编程或同行评审的方式再次验证功能的逻辑。然后和测试，产品一起看看还有没有遗漏的部分。完成上述事情，他们才认为开发完成。\n平庸的\u0026hellip;..（我觉得都不应该称为工程师），接到需求，不经思索就匆忙开始，写完代码，不做任何自动化验证，不做重构，简单测试功能（happy path），甚至happy path都没跑完，然后就扔给测试人员一堆垃圾代码，就让别人测试。这是软件开发吗？这就是中国当前大多数企业的开发现状。\n我觉得这是人的素养问题，有涵养的人对自己的事都有高度的责任心，做任何事都抱着不麻烦别人的利他精神，自己的事情做到极致的工匠精神，自己的代码自己负责，需要他人协作也是借鉴他人思路，而不是假他人之手来做。和这样人相处整个团队都会处于正向上升，效率，质量都会不断进步。但是如果团队大量存在平庸的人，那么这个团队只能处于向下的循环，开发效率低下， 质量差，开发埋怨测试不够快，测试埋怨开发质量差，整个团队士气低下，几乎无可救药。\n意识与技能 “功能都做不完，还写什么自动化测试，做什么重构？”，能力平庸的开发人员往往搬出这套说法告诉你，做这些浪费时间，影响交付。往往说这种话的人，从没写过自动化测试，重构是什么根本不了解。他们不知道CI，TDD，refactoring三件套实际是加速整个交付效率。这种人既没有良好的软件开发意识，同时也不具备基本的软件开发技能。在一个企业留下一堆垃圾代码，然后仓皇而逃，继续祸害下个企业。\n这里企业并不是无辜的，只要“性价比高”就招进来，宁愿招一群能力平庸的人，也不愿高薪聘请少量的优秀工程师。软件在欧美是一个令人羡慕的行业，薪资常年Top5，engineer这个职位是被人尊敬的。但在这里廉价劳动力获得野蛮生长，真正的劣币驱逐良币。\n磨刀不误砍柴工 我们有句谚语：“磨刀不误砍柴工”，这句话用在开发里面解释就是，如果我在加入一个新功能前，能有结构清晰的代码（重构完成），有良好的自动化测试守护，那么在加入新功能时就能加快速度。总体做完一个功能花费的时间比在一个内部质量差，且没有自动化守护的代码基上加入新功能花的时间更短。\n重构+自动化测试+新功能+测试+修改bug所花费的时间 \u0026lt; 直接开发新功能+测试+修改bug的时间。\n有时大家明明理解这个道理，却还是不愿意去做，是因为工作量的原因。敏捷期望团队提升协作，提升能力，达到提升效率。但很多组织在团队还没有提升的时候加大工作量。上个迭代完成60个点，下个迭代就要求完成80个点。导致团队明知道磨刀会加快速度，但却不愿意磨刀，直接去砍柴。结果越砍越慢，越慢越加班，越加班，越不愿磨刀，形成恶性循环。\n管理文化 敏捷体系是建立在信任的基础上。有了信任才有了协作，不同性格的人才有发挥空间。敏捷强调管理者、团队关注未完成的事情。一旦管理者，团队不仅仅关注事情，还更关注人是否忙碌，这个直接破坏了敏捷的基础。这样每个人都处在微观管理下，协作变的不顺畅，团队无法自组织，更无法持续提升。\n要让敏捷发展，管理层要有魄力信任个人，团队，让他们自主决定做哪些事，怎么协作，怎么提升，不到万不得已，不干涉团队的决定。这个对管理者能力是个极大的考验。\n#绩效\n还记得“绩效毁掉sony这个故事吗？”讲述sony公司在引入绩效考核后，大家都盯着kpi做事，有一个很有价值的事，产品老化测试，但由于耗时长，体现不出绩效，而无人问津，最后导致sony的产品质量急剧下降。\n虽然不知道这个故事真假，不过绩效可以很轻易的破坏敏捷文化。敏捷文化很重要的一点就是协作，无论个人还是团队之间。如果一个组织过度注重绩效，人人都盯着绩效做事，凡事都问：“这个事对我绩效有什么帮助吗？”。那么会导致人与人之间，团队与团队之间协作困难。每个人和团队都在做局部优化，整体优化丢失，组织整体效率变的低下。\n总结一下：\n要开展敏捷，以下几点很重要：\n需要高素养的人，技能可以学习，但高素养的人需要从小培养\n开发中经常使用UT，TDD，refactoring，pair programming，code review\n支持团队成长，合理化工作量，通过团队成长，效率提升来提升工作量\n扁平组织架构，基于信任的管理\n注重整体绩效，尽量基于团队，甚至多个团队进行整体绩效管理\n看起来很简单，实际上每一条都很难，敏捷就是这样难。\n","permalink":"https://kmnemon.github.io/posts/2020-07-02-agile-dev-difficulty/","summary":"\u003cp\u003e最近项目组发版质量持续降低，生产事故接连不断，回家的路上陷入深思，明明几个月前还做的相当不错，质量稳步提升，虽不完美，但总算还在持续进步。到底什么原因导致现在的情况？随着思考不断深入，更多本质的问题浮到面上。（本文着重讨论开发，不涉及敏捷需求价值部分）\u003c/p\u003e\n\u003ch1 id=\"人的素养\"\u003e人的素养：\u003c/h1\u003e\n\u003cp\u003e手工艺人制造商品，从设计，制作，检验，并摆上商铺进行销售往往都是一个人完成。逛街的时候会遇到现场制作的手工艺人，一道工序，接另一道工序，最后组合成可用的商品，其中并没有看到做出来的东西需要另一个人单独测试，才能摆上商铺才能销售。大家往往习惯于此，但为什么我们的软件制作（开发）需要单独一个人或一组人帮你验证（测试），你自己开发的东西？你自己开发出来的东西，为什么有如此多的缺陷，如果不经过别人的验证，甚至不敢摆上商铺销售（上线）？\u003c/p\u003e\n\u003cp\u003e优秀的软件工程师，完成一段代码，一个功能，无论从内在质量，还是外在质量都经得起推敲，甚至根本不用任何人帮助他验证，即可上线。他们在做自己功能的时候，会主动构建自动化测试，开发过程中不断重构自己代码，完成后还要经过自己多次验证，同时为了避免思维盲区，他们会采用结对编程或同行评审的方式再次验证功能的逻辑。然后和测试，产品一起看看还有没有遗漏的部分。完成上述事情，他们才认为开发完成。\u003c/p\u003e\n\u003cp\u003e平庸的\u0026hellip;..（我觉得都不应该称为工程师），接到需求，不经思索就匆忙开始，写完代码，不做任何自动化验证，不做重构，简单测试功能（happy path），甚至happy path都没跑完，然后就扔给测试人员一堆垃圾代码，就让别人测试。这是软件开发吗？这就是中国当前大多数企业的开发现状。\u003c/p\u003e\n\u003cp\u003e我觉得这是人的素养问题，有涵养的人对自己的事都有高度的责任心，做任何事都抱着不麻烦别人的利他精神，自己的事情做到极致的工匠精神，自己的代码自己负责，需要他人协作也是借鉴他人思路，而不是假他人之手来做。和这样人相处整个团队都会处于正向上升，效率，质量都会不断进步。但是如果团队大量存在平庸的人，那么这个团队只能处于向下的循环，开发效率低下， 质量差，开发埋怨测试不够快，测试埋怨开发质量差，整个团队士气低下，几乎无可救药。\u003c/p\u003e\n\u003ch1 id=\"意识与技能\"\u003e意识与技能\u003c/h1\u003e\n\u003cp\u003e“功能都做不完，还写什么自动化测试，做什么重构？”，能力平庸的开发人员往往搬出这套说法告诉你，做这些浪费时间，影响交付。往往说这种话的人，从没写过自动化测试，重构是什么根本不了解。他们不知道CI，TDD，refactoring三件套实际是加速整个交付效率。这种人既没有良好的软件开发意识，同时也不具备基本的软件开发技能。在一个企业留下一堆垃圾代码，然后仓皇而逃，继续祸害下个企业。\u003c/p\u003e\n\u003cp\u003e这里企业并不是无辜的，只要“性价比高”就招进来，宁愿招一群能力平庸的人，也不愿高薪聘请少量的优秀工程师。软件在欧美是一个令人羡慕的行业，薪资常年Top5，engineer这个职位是被人尊敬的。但在这里廉价劳动力获得野蛮生长，真正的劣币驱逐良币。\u003c/p\u003e\n\u003ch1 id=\"磨刀不误砍柴工\"\u003e磨刀不误砍柴工\u003c/h1\u003e\n\u003cp\u003e我们有句谚语：“磨刀不误砍柴工”，这句话用在开发里面解释就是，如果我在加入一个新功能前，能有结构清晰的代码（重构完成），有良好的自动化测试守护，那么在加入新功能时就能加快速度。总体做完一个功能花费的时间比在一个内部质量差，且没有自动化守护的代码基上加入新功能花的时间更短。\u003c/p\u003e\n\u003cp\u003e重构+自动化测试+新功能+测试+修改bug所花费的时间 \u0026lt; 直接开发新功能+测试+修改bug的时间。\u003c/p\u003e\n\u003cp\u003e有时大家明明理解这个道理，却还是不愿意去做，是因为工作量的原因。敏捷期望团队提升协作，提升能力，达到提升效率。但很多组织在团队还没有提升的时候加大工作量。上个迭代完成60个点，下个迭代就要求完成80个点。导致团队明知道磨刀会加快速度，但却不愿意磨刀，直接去砍柴。结果越砍越慢，越慢越加班，越加班，越不愿磨刀，形成恶性循环。\u003c/p\u003e\n\u003ch1 id=\"管理文化\"\u003e管理文化\u003c/h1\u003e\n\u003cp\u003e敏捷体系是建立在信任的基础上。有了信任才有了协作，不同性格的人才有发挥空间。敏捷强调管理者、团队关注未完成的事情。一旦管理者，团队不仅仅关注事情，还更关注人是否忙碌，这个直接破坏了敏捷的基础。这样每个人都处在微观管理下，协作变的不顺畅，团队无法自组织，更无法持续提升。\u003c/p\u003e\n\u003cp\u003e要让敏捷发展，管理层要有魄力信任个人，团队，让他们自主决定做哪些事，怎么协作，怎么提升，不到万不得已，不干涉团队的决定。这个对管理者能力是个极大的考验。\u003c/p\u003e\n\u003cp\u003e#绩效\u003cbr\u003e\n还记得“绩效毁掉sony这个故事吗？”讲述sony公司在引入绩效考核后，大家都盯着kpi做事，有一个很有价值的事，产品老化测试，但由于耗时长，体现不出绩效，而无人问津，最后导致sony的产品质量急剧下降。\u003c/p\u003e\n\u003cp\u003e虽然不知道这个故事真假，不过绩效可以很轻易的破坏敏捷文化。敏捷文化很重要的一点就是协作，无论个人还是团队之间。如果一个组织过度注重绩效，人人都盯着绩效做事，凡事都问：“这个事对我绩效有什么帮助吗？”。那么会导致人与人之间，团队与团队之间协作困难。每个人和团队都在做局部优化，整体优化丢失，组织整体效率变的低下。\u003c/p\u003e\n\u003cp\u003e总结一下：\u003c/p\u003e\n\u003cp\u003e要开展敏捷，以下几点很重要：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e需要高素养的人，技能可以学习，但高素养的人需要从小培养\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e开发中经常使用UT，TDD，refactoring，pair programming，code review\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e支持团队成长，合理化工作量，通过团队成长，效率提升来提升工作量\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e扁平组织架构，基于信任的管理\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e注重整体绩效，尽量基于团队，甚至多个团队进行整体绩效管理\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e看起来很简单，实际上每一条都很难，敏捷就是这样难。\u003c/p\u003e","title":"为什么敏捷开发落地那么难？"},{"content":"在日常辅导团队的过程中有一个问题是大家问的比较多，直观上理解有些困难，更别说实际的使用。“敏捷需要文档吗？”这个问题，在一个组织对于不同的角色，同一个角色但不同开发背景的人，答案都不一样。这篇文章想由浅入深的对敏捷开发需要的文档进行讨论。\n简单的答案是“需要”。\n敏捷开发和瀑布流程对文档的要求 我们知道敏捷开发和瀑布流程在开发周期时间上明显不同，一个是迭代开发，迭代周期（1～4周），一个是阶段-门限开发，周期（1～n月），在交付一个可运行的小功能上两种开发方式需要的时间明显不同。敏捷只需要几周，瀑布则需要按月来交付。这个周期时间的不同会导致在文档上花的时间的不同。 如上图我们说敏捷开发是轻文档，而瀑布是重文档式的流程。\n重量级文档流程 先来说重量级文档，在瀑布流程下，我们被要求从商业分析，市场分析，产品需求收集，产品设计，开发分析，开发，UT，测试，集成测试，系统测试，到发布这些阶段，对应于商业需求文档（BRD）， 市场需求文档（MRD），产品需求文档（PRD），概要设计（HLS），详细设计（LLS），测试策略，测试计划，测试用例，测试报告，整个开发流程大概需要这些文档。Winston W. Royce(瀑布流程发明者，1970年发表）认为开发流程和制造业的流程相似，如果在每个阶段我们都做好充分的分析设计，那么整个项目最终是不会有很大偏差的。 到这里我们要回答两个问题：\n这个理论正确吗？ 1970发明的方法还适用于现在的市场环境，商业环境和研发技术吗？ 这个理论正确吗？在不考虑任何成本的情况下，花更多的时间在每个阶段可以提升每个阶段的正确性。在后续任何阶段发现错误，都可以回到最初的阶段。比如在测试阶段发现前面有个功能的设计错误了，那么完全可以回到产品需求收集阶段进行修改，同时进行相应文档变更，PRD，HLS，LLS，测试用例变更。那么这个理论正确吗？在不考虑任何成本的情况下，这个理论可行。但如果考虑成本呢？\n我们在一个产品或项目构建的早期，能想清楚所有要解决的用户问题，所有的功能，所有的技术依赖吗？ 经验说明根本不可能，不然变更控制委员会(CCB)设立来做什么？就是变更太多控制不住，需要一群人来控制。\n我们的业务，领域知识是随着产品不断的开发过程中，不断学习获得的，如果前期在缺乏大量产品知识的时候，我们要进行大量的需求设计，这时期会产生大量的低质量需求，大量错误的假设导致后期的返工。\n1970发明的方法还适用于现在的市场环境，商业环境和研发技术吗？\n大家回想一下1970年代的产品与技术,那个时候以科研系统为主流，unix系统在那时诞生，使用汇编和C语言为主要编程语言。那个时候市场竞争并不激烈，计算机还没有用于个人。所以在70年代左右开发的系统复杂，昂贵，而且没有多少市场竞争，开发一套系统往往耗时几年。这个时候开发一套系统成本很高，周期很长，使用重文档的流程开发，产生的浪费，往往被高成本，长时间的交付掩盖住了。\n到了现在个人市场，商业市场都有了长足的发展，交付周期被缩短到了几周，甚至于每天上线多次。重文档的流程弊端凸显，要么根本就无法完成这些文档，要么对文档进行大量的裁剪，要么文档落后代码几公里再也无法同步。在快速高效的开发流程里写出这些高质量的文档变得不可能，也不必要，因为这些文档从一开始价值就不高。重文档流程的组织在商业交付上越来越慢，最后深陷泥潭，被新型的独角兽企业一遍又一遍的冲击，最后不得不转型开发流程寻求突破。\n敏捷开发中的文档 敏捷文化在90年代后期开始逐渐重塑了整个软件行业。以重视反馈，减少浪费，团队协作为核心，整个开发文档也遵循其核心价值。\n那么在敏捷中我们怎么写文档，才能高效，高质量，低成本的完成我们的交付呢？\n关于需求文档： 之前说到在前期业务人员，市场人员，产品经理会输出BRD，MRD，PRD，这些文档的目的和价值是什么呢？\n这些文档的核心目的是帮助组织的业务目标和产品对齐，在敏捷里面不仅希望目标对齐，同时还希望最大化使用这些文档，通过这些文档实现以下目的：\n业务目标和产品目标对齐 理解的一致性 文档和代码保持一致 自动化验收系统 这样可以最大化的提升文档的价值，文档用于业务人员，产品经理，开发人员，测试人员理解一致，文档和代码始终一致可以实时反应代码情况，同时文档又用于产品交付的自动化验收。\n用户故事 敏捷里面提倡使用用户故事来描述需求，通过用户故事团队随时讨论，澄清需求，同时通过用户故事的验收标准（AC），帮助开发团队各角色明确需求的验收范围。 通过用户故事的INVEST原则，帮助我们提高交付效率，理解需求价值。\n用户故事的INVEST原则\n实例化需求 敏捷里面提出了实例化需求的一组模式，帮助达到上述的目标，在实例化需求里面提倡：\n产品要从商业目标去得到需求的范围，要理解需求背后的\u0026quot;why\u0026quot;\u0026ldquo;who\u0026rdquo;，理解商业用户期望的结果是什么 需求是协作产生的，通过工作坊商业干系人，领域专家，开发团队一起完成需求的梳理和澄清 使用实例来描述需求，开发团队和商业用户一起识别系统的关键实例 精炼实例，实例需要呈现用户的需要，避免过多的实现细节 实例化需求实现自动化验收 前面几点还是比较容易理解，主要第5点很多产品经理觉得不可思议了，我写的需求还可以变为自动化验收测试系统？是的，现在有很多支持实例化需求的平台,如： Concordion,FitNesse.\nConcordion实例化需求：\n自动化验收框架：\n这里不具体讲解实例化需求验收部分，这个以后专题讲解。\n关于设计文档： 说了需求部分，那么开发设计部分呢？以前的HLS，LLS怎么更有价值，减少浪费呢？\n敏捷里面认为：\n代码的设计体现在代码自动化测试里面，这样代码的设计通过自动化测试代码实现，这时测试代码和实现代码保持一致，通过测试反应方法设计意图，反应功能设计的意图。 领域模型，领域的知识用领域模型反映，通过领域模型实现开发人员和领域专家理解一致性 通过富文本注释实现，代码不仅要自注释，而且通过图文并茂的富文本注释体现设计思路 关于测试文档： 在测试方面，提倡代码质量集体负责，测试人员并不是最后的守门员，而是作为测试专家，把测试方面的技能传递给开发人员，让开发人员对自己的功能充分测试，并完成自动化单元测试，自动化验收测试。最后测试文档变成了一个一个的自动化测试用例代码。\n总结： 在如今要求高效率，高质量快速交付的环境下，敏捷的轻量级文档流程，并不是真的“轻”了，而是聚焦于消灭成本高，浪费高，价值低的文档，通过自动化的方式提升文档的价值。作为产品，开发，测试的人员更需要锻炼基本功，提升整个交付过程的效率和质量。\n","permalink":"https://kmnemon.github.io/posts/2020-06-08-agile-document/","summary":"\u003cp\u003e在日常辅导团队的过程中有一个问题是大家问的比较多，直观上理解有些困难，更别说实际的使用。“敏捷需要文档吗？”这个问题，在一个组织对于不同的角色，同一个角色但不同开发背景的人，答案都不一样。这篇文章想由浅入深的对敏捷开发需要的文档进行讨论。\u003c/p\u003e\n\u003cp\u003e简单的答案是“需要”。\u003c/p\u003e\n\u003ch1 id=\"敏捷开发和瀑布流程对文档的要求\"\u003e敏捷开发和瀑布流程对文档的要求\u003c/h1\u003e\n\u003cp\u003e我们知道敏捷开发和瀑布流程在开发周期时间上明显不同，一个是迭代开发，迭代周期（1～4周），一个是阶段-门限开发，周期（1～n月），在交付一个可运行的小功能上两种开发方式需要的时间明显不同。敏捷只需要几周，瀑布则需要按月来交付。这个周期时间的不同会导致在文档上花的时间的不同。 \u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2020-06-08-agile-document/agile-document.png\"\u003e\u003c/p\u003e\n\u003cp\u003e如上图我们说敏捷开发是轻文档，而瀑布是重文档式的流程。\u003c/p\u003e\n\u003ch1 id=\"重量级文档流程\"\u003e重量级文档流程\u003c/h1\u003e\n\u003cp\u003e先来说重量级文档，在瀑布流程下，我们被要求从商业分析，市场分析，产品需求收集，产品设计，开发分析，开发，UT，测试，集成测试，系统测试，到发布这些阶段，对应于商业需求文档（BRD）， 市场需求文档（MRD），产品需求文档（PRD），概要设计（HLS），详细设计（LLS），测试策略，测试计划，测试用例，测试报告，整个开发流程大概需要这些文档。Winston W. Royce(瀑布流程发明者，1970年发表）认为开发流程和制造业的流程相似，如果在每个阶段我们都做好充分的分析设计，那么整个项目最终是不会有很大偏差的。\n到这里我们要回答两个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e这个理论正确吗？\u003c/li\u003e\n\u003cli\u003e1970发明的方法还适用于现在的市场环境，商业环境和研发技术吗？\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这个理论正确吗？在不考虑任何成本的情况下，花更多的时间在每个阶段可以提升每个阶段的正确性。在后续任何阶段发现错误，都可以回到最初的阶段。比如在测试阶段发现前面有个功能的设计错误了，那么完全可以回到产品需求收集阶段进行修改，同时进行相应文档变更，PRD，HLS，LLS，测试用例变更。那么这个理论正确吗？在不考虑任何成本的情况下，这个理论可行。但如果考虑成本呢？\u003c/p\u003e\n\u003cp\u003e我们在一个产品或项目构建的早期，能想清楚所有要解决的用户问题，所有的功能，所有的技术依赖吗？ 经验说明根本不可能，不然变更控制委员会(CCB)设立来做什么？就是变更太多控制不住，需要一群人来控制。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2020-06-08-agile-document/requirment.png\"\u003e\u003cbr\u003e\n我们的业务，领域知识是随着产品不断的开发过程中，不断学习获得的，如果前期在缺乏大量产品知识的时候，我们要进行大量的需求设计，这时期会产生大量的低质量需求，大量错误的假设导致后期的返工。\u003c/p\u003e\n\u003cp\u003e1970发明的方法还适用于现在的市场环境，商业环境和研发技术吗？\u003c/p\u003e\n\u003cp\u003e大家回想一下1970年代的产品与技术,那个时候以科研系统为主流，unix系统在那时诞生，使用汇编和C语言为主要编程语言。那个时候市场竞争并不激烈，计算机还没有用于个人。所以在70年代左右开发的系统复杂，昂贵，而且没有多少市场竞争，开发一套系统往往耗时几年。这个时候开发一套系统成本很高，周期很长，使用重文档的流程开发，产生的浪费，往往被高成本，长时间的交付掩盖住了。\u003c/p\u003e\n\u003cp\u003e到了现在个人市场，商业市场都有了长足的发展，交付周期被缩短到了几周，甚至于每天上线多次。重文档的流程弊端凸显，要么根本就无法完成这些文档，要么对文档进行大量的裁剪，要么文档落后代码几公里再也无法同步。在快速高效的开发流程里写出这些高质量的文档变得不可能，也不必要，因为这些文档从一开始价值就不高。重文档流程的组织在商业交付上越来越慢，最后深陷泥潭，被新型的独角兽企业一遍又一遍的冲击，最后不得不转型开发流程寻求突破。\u003c/p\u003e\n\u003ch1 id=\"敏捷开发中的文档\"\u003e敏捷开发中的文档\u003c/h1\u003e\n\u003cp\u003e敏捷文化在90年代后期开始逐渐重塑了整个软件行业。以重视反馈，减少浪费，团队协作为核心，整个开发文档也遵循其核心价值。\u003cbr\u003e\n那么在敏捷中我们怎么写文档，才能高效，高质量，低成本的完成我们的交付呢？\u003c/p\u003e\n\u003ch3 id=\"关于需求文档\"\u003e关于需求文档：\u003c/h3\u003e\n\u003cp\u003e之前说到在前期业务人员，市场人员，产品经理会输出BRD，MRD，PRD，这些文档的目的和价值是什么呢？\u003cbr\u003e\n这些文档的核心目的是帮助组织的业务目标和产品对齐，在敏捷里面不仅希望目标对齐，同时还希望最大化使用这些文档，通过这些文档实现以下目的：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e业务目标和产品目标对齐\u003c/li\u003e\n\u003cli\u003e理解的一致性\u003c/li\u003e\n\u003cli\u003e文档和代码保持一致\u003c/li\u003e\n\u003cli\u003e自动化验收系统\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这样可以最大化的提升文档的价值，文档用于业务人员，产品经理，开发人员，测试人员理解一致，文档和代码始终一致可以实时反应代码情况，同时文档又用于产品交付的自动化验收。\u003c/p\u003e\n\u003ch6 id=\"用户故事\"\u003e用户故事\u003c/h6\u003e\n\u003cp\u003e敏捷里面提倡使用用户故事来描述需求，通过用户故事团队随时讨论，澄清需求，同时通过用户故事的验收标准（AC），帮助开发团队各角色明确需求的验收范围。  通过用户故事的INVEST原则，帮助我们提高交付效率，理解需求价值。\u003c/p\u003e\n\u003cp\u003e用户故事的INVEST原则\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2020-06-08-agile-document/us.png\"\u003e\u003c/p\u003e\n\u003ch6 id=\"实例化需求\"\u003e实例化需求\u003c/h6\u003e\n\u003cp\u003e敏捷里面提出了实例化需求的一组模式，帮助达到上述的目标，在实例化需求里面提倡：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e产品要从商业目标去得到需求的范围，要理解需求背后的\u0026quot;why\u0026quot;\u0026ldquo;who\u0026rdquo;，理解商业用户期望的结果是什么\u003c/li\u003e\n\u003cli\u003e需求是协作产生的，通过工作坊商业干系人，领域专家，开发团队一起完成需求的梳理和澄清\u003c/li\u003e\n\u003cli\u003e使用实例来描述需求，开发团队和商业用户一起识别系统的关键实例\u003c/li\u003e\n\u003cli\u003e精炼实例，实例需要呈现用户的需要，避免过多的实现细节\u003c/li\u003e\n\u003cli\u003e实例化需求实现自动化验收\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e前面几点还是比较容易理解，主要第5点很多产品经理觉得不可思议了，我写的需求还可以变为自动化验收测试系统？是的，现在有很多支持实例化需求的平台,如： Concordion,FitNesse.\u003c/p\u003e\n\u003cp\u003eConcordion实例化需求：\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2020-06-08-agile-document/specification-by-example.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自动化验收框架：\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2020-06-08-agile-document/specification-by-example-frame.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这里不具体讲解实例化需求验收部分，这个以后专题讲解。\u003c/p\u003e\n\u003ch3 id=\"关于设计文档\"\u003e关于设计文档：\u003c/h3\u003e\n\u003cp\u003e说了需求部分，那么开发设计部分呢？以前的HLS，LLS怎么更有价值，减少浪费呢？\u003c/p\u003e\n\u003cp\u003e敏捷里面认为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e代码的设计体现在代码自动化测试里面，这样代码的设计通过自动化测试代码实现，这时测试代码和实现代码保持一致，通过测试反应方法设计意图，反应功能设计的意图。\u003c/li\u003e\n\u003cli\u003e领域模型，领域的知识用领域模型反映，通过领域模型实现开发人员和领域专家理解一致性\u003c/li\u003e\n\u003cli\u003e通过富文本注释实现，代码不仅要自注释，而且通过图文并茂的富文本注释体现设计思路\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"UT\" loading=\"lazy\" src=\"/images/2020-06-08-agile-document/ut.jpg\"\u003e\u003cbr\u003e\n\u003cimg alt=\"领域模型\" loading=\"lazy\" src=\"/images/2020-06-08-agile-document/domain.png\"\u003e\u003cbr\u003e\n\u003cimg alt=\"富文本注释\" loading=\"lazy\" src=\"/images/2020-06-08-agile-document/commit.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"关于测试文档\"\u003e关于测试文档：\u003c/h3\u003e\n\u003cp\u003e在测试方面，提倡代码质量集体负责，测试人员并不是最后的守门员，而是作为测试专家，把测试方面的技能传递给开发人员，让开发人员对自己的功能充分测试，并完成自动化单元测试，自动化验收测试。最后测试文档变成了一个一个的自动化测试用例代码。\u003c/p\u003e\n\u003ch1 id=\"总结\"\u003e总结：\u003c/h1\u003e\n\u003cp\u003e在如今要求高效率，高质量快速交付的环境下，敏捷的轻量级文档流程，并不是真的“轻”了，而是聚焦于消灭成本高，浪费高，价值低的文档，通过自动化的方式提升文档的价值。作为产品，开发，测试的人员更需要锻炼基本功，提升整个交付过程的效率和质量。\u003c/p\u003e","title":"敏捷文档真的轻了吗？"},{"content":"敏捷 XP和scrum作为敏捷开发里面最重要的两种思想，相辅相成的发展了20多个年头。要了解这两种方式的本质，要先了解发明人。XP的发明人Kent Beck来自美国的软件工程师，TDD（测试驱动开发）的推崇者。在软件领域最出名的是他的Junit单元测试框架。Jeff Sutherland和Ken Schwaber共同发展了scrum的敏捷理念。Jeff Sutherland毕业于西点，11年的军旅生涯里面当了医生，随后涉及到IT领域. Ken Schwaber软件工程师，产品和工业的咨询。\n在这里我们可以了解到Kect Beck更偏向于技术，所以在XP里面除了价值，原则外，更看重各种开发的实践。而scrum则更偏向于人，团队，流程。所以我们采用的敏捷一般是XP和scrum的混合方式。既有XP里面的开发实践，也有scrum的关于人，团队，流程的框架。这两种理念相辅相成，共同发展，形成了今天的敏捷。\n小规模的敏捷 在90年代末期，没有现在的云计算，没有大数据，没有docker，k8s。受限于当时的软件技术和规模。XP和scrum在当时的环境下不管从价值观，原则和可以落地的工程实践，都比当时普遍采用的瀑布开发方式好上太多。在2000年后敏捷开发方式开始一步一步成为主流的开发方式。后来持续集成，持续交付，精益开发，用户故事地图，实例化需求的发展进一步加强了敏捷的各个部分。 在当时的背景下，采用组织架构的重新划分，以及架构的持续演进，就可以从component team,变化为feature team. 在feature team里面，团队之间依赖少。所以一个个独立的团队自己采用XP和scrum方式进行持续改进。整个组织的交付效率和质量得益于不断提升的单个团队。\n唯一的不变就是变化，这句话时刻提醒着我们。随着时间推移，软件的规模越来越大，SaaS，PaaS，大数据，中台化等技术和组织架构的变化。使得小而美的敏捷团队遇到了前所未有的挑战。\n规模化的敏捷 软件规模变得越来越大后，遇到的首要问题是团队间需求的依赖问题。一个完整的具有用户价值的功能现在无法由一个团队完成。有时需求会横跨3，4个团队，甚至7，8个团队。团队间就像以前的component team一样依赖起来。整个开发的过程变得臃肿，反应变慢，反馈周期变长。这样敏捷团队的价值观和原则被现实打破。怎么才能短，快的交付有价值的需求，得到反馈，使敏捷的价值重现。所以后来出现了规模化敏捷的思考，就是基于现状找到可以解决的方法。不管从safe，还是less，或者Scrum@Scale,其实本质就是解决两个核心问题。\n第一个问题就是：需求怎么对齐，其实也就是依赖团队间目标怎么对齐，怎么协同开发？\n第二个问题就是：随着软件规模扩大，团队，团队人数怎么扩张？\n针对第一个问题的本质是，如果无法解决团队间开发依赖问题，那么通过在依赖团队间建立统一的product backlog和统一迭代起止时间的方式进行缓解。统一的product backlog可以解决团队之间需求排序优先级的问题，再加上团队之间迭代的起止时间变得一致性，提升沟通，联调的效率，降低协作的成本。 针对第二个问题，还是考虑到团队人数开始变多，沟通渠道变宽，团队整体的透明性，沟通效率变差，团队变得迟缓。所以通过保持小而美的团队，通过一层层把小团队聚合起来，形成更大规模的团队群。上层团队之间的协作依靠团队代表成员（PO代表，scrum master代表，技术代表，测试代表等）进行沟通协作，来提升沟通效率。\n当软件规模更大后，所有的规模化方法都是解决协作的问题，沟通效率问题，解决这类问题本身会产生更多的成本（相较于以前的小规模敏捷团队）\n所以当组织达到一定规模化，进行敏捷的方式要进行相应的调整，根据每个组织的独特性一般有以下几点:\n优先解决团队开发的依赖 通过统一product backlog 统一团队迭代进行依赖缓解（比如集中多个团队的sprint plan） scrum of scrums, scrum of scrums of scrums(或者其他方法用于同步团队间的进度) 集体团队回顾（持续改进团队依赖问题) 持续交付基础设施的完善 说了那么多，其实规模化敏捷也属于一直在探索的道路上，在这条遍布荆棘的道路上，一定要坚持敏捷的价值观和原则，找寻到适合自己组织和团队的方法。\n","permalink":"https://kmnemon.github.io/posts/2020-04-27-large-scale-agile/","summary":"\u003ch1 id=\"敏捷\"\u003e敏捷\u003c/h1\u003e\n\u003cp\u003eXP和scrum作为敏捷开发里面最重要的两种思想，相辅相成的发展了20多个年头。要了解这两种方式的本质，要先了解发明人。XP的发明人Kent Beck来自美国的软件工程师，TDD（测试驱动开发）的推崇者。在软件领域最出名的是他的Junit单元测试框架。Jeff Sutherland和Ken Schwaber共同发展了scrum的敏捷理念。Jeff Sutherland毕业于西点，11年的军旅生涯里面当了医生，随后涉及到IT领域. Ken Schwaber软件工程师，产品和工业的咨询。\u003cbr\u003e\n在这里我们可以了解到Kect Beck更偏向于技术，所以在XP里面除了价值，原则外，更看重各种开发的实践。而scrum则更偏向于人，团队，流程。所以我们采用的敏捷一般是XP和scrum的混合方式。既有XP里面的开发实践，也有scrum的关于人，团队，流程的框架。这两种理念相辅相成，共同发展，形成了今天的敏捷。\u003c/p\u003e\n\u003ch1 id=\"小规模的敏捷\"\u003e小规模的敏捷\u003c/h1\u003e\n\u003cp\u003e在90年代末期，没有现在的云计算，没有大数据，没有docker，k8s。受限于当时的软件技术和规模。XP和scrum在当时的环境下不管从价值观，原则和可以落地的工程实践，都比当时普遍采用的瀑布开发方式好上太多。在2000年后敏捷开发方式开始一步一步成为主流的开发方式。后来持续集成，持续交付，精益开发，用户故事地图，实例化需求的发展进一步加强了敏捷的各个部分。\n在当时的背景下，采用组织架构的重新划分，以及架构的持续演进，就可以从component team,变化为feature team. 在feature team里面，团队之间依赖少。所以一个个独立的团队自己采用XP和scrum方式进行持续改进。整个组织的交付效率和质量得益于不断提升的单个团队。\u003cbr\u003e\n唯一的不变就是变化，这句话时刻提醒着我们。随着时间推移，软件的规模越来越大，SaaS，PaaS，大数据，中台化等技术和组织架构的变化。使得小而美的敏捷团队遇到了前所未有的挑战。\u003c/p\u003e\n\u003ch1 id=\"规模化的敏捷\"\u003e规模化的敏捷\u003c/h1\u003e\n\u003cp\u003e软件规模变得越来越大后，遇到的首要问题是团队间需求的依赖问题。一个完整的具有用户价值的功能现在无法由一个团队完成。有时需求会横跨3，4个团队，甚至7，8个团队。团队间就像以前的component team一样依赖起来。整个开发的过程变得臃肿，反应变慢，反馈周期变长。这样敏捷团队的价值观和原则被现实打破。怎么才能短，快的交付有价值的需求，得到反馈，使敏捷的价值重现。所以后来出现了规模化敏捷的思考，就是基于现状找到可以解决的方法。不管从safe，还是less，或者Scrum@Scale,其实本质就是解决两个核心问题。\u003cbr\u003e\n第一个问题就是：需求怎么对齐，其实也就是依赖团队间目标怎么对齐，怎么协同开发？\u003cbr\u003e\n第二个问题就是：随着软件规模扩大，团队，团队人数怎么扩张？\u003cbr\u003e\n针对第一个问题的本质是，如果无法解决团队间开发依赖问题，那么通过在依赖团队间建立统一的product backlog和统一迭代起止时间的方式进行缓解。统一的product backlog可以解决团队之间需求排序优先级的问题，再加上团队之间迭代的起止时间变得一致性，提升沟通，联调的效率，降低协作的成本。\n针对第二个问题，还是考虑到团队人数开始变多，沟通渠道变宽，团队整体的透明性，沟通效率变差，团队变得迟缓。所以通过保持小而美的团队，通过一层层把小团队聚合起来，形成更大规模的团队群。上层团队之间的协作依靠团队代表成员（PO代表，scrum master代表，技术代表，测试代表等）进行沟通协作，来提升沟通效率。\u003cbr\u003e\n当软件规模更大后，所有的规模化方法都是解决协作的问题，沟通效率问题，解决这类问题本身会产生更多的成本（相较于以前的小规模敏捷团队）\u003cbr\u003e\n所以当组织达到一定规模化，进行敏捷的方式要进行相应的调整，根据每个组织的独特性一般有以下几点:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e优先解决团队开发的依赖\u003c/li\u003e\n\u003cli\u003e通过统一product backlog\u003c/li\u003e\n\u003cli\u003e统一团队迭代进行依赖缓解（比如集中多个团队的sprint plan）\u003c/li\u003e\n\u003cli\u003escrum of scrums, scrum of scrums of scrums(或者其他方法用于同步团队间的进度)\u003c/li\u003e\n\u003cli\u003e集体团队回顾（持续改进团队依赖问题)\u003c/li\u003e\n\u003cli\u003e持续交付基础设施的完善\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e说了那么多，其实规模化敏捷也属于一直在探索的道路上，在这条遍布荆棘的道路上，一定要坚持敏捷的价值观和原则，找寻到适合自己组织和团队的方法。\u003c/p\u003e","title":"规模化敏捷思考"},{"content":"大道至简，优雅至上 写文章是一件有趣的事情。如果你感谢兴趣并有可能帮助到你，可以买一杯咖啡给我：P\n微信（26元）\n联系我：\n发邮件给我\n","permalink":"https://kmnemon.github.io/about/","summary":"\u003ch3 id=\"大道至简优雅至上\"\u003e大道至简，优雅至上\u003c/h3\u003e\n\u003cp\u003e写文章是一件有趣的事情。如果你感谢兴趣并有可能帮助到你，可以买一杯咖啡给我：P\u003c/p\u003e\n\u003cp\u003e微信（26元）\u003c/p\u003e\n\u003cimg src=\"/wechatpay.png\" width = \"200\" height=\"200\" /\u003e  \n\u003cp\u003e联系我：\u003cbr\u003e\n\u003ca href=\"mailto:kmnemon@outlook.com\"\u003e发邮件给我\u003c/a\u003e\u003c/p\u003e","title":"咖啡"},{"content":"版本 golang \u0026ndash; 1.12.4\nnsq-1.1.0.linux-amd64.go1.10.3.tar.gz\n什么是NSQ 一句话讲NSQ是一个简单队列，类似于java经常使用的activeMQ或者RocketMQ,一般在同步分离成异步，发送消息和接受消息解耦的地方使用到。\nNSQ有以下特性:\n支持拓扑的高可用性和避免单点故障(SPOFs)。 更强的消息递交保证 为单次处理绑定着内存的足迹(通过把一些持久话的消息放入磁盘) 对生产者和消费者的配置进行极大的简化 提供直接的升级路径 提升效率 NSQ组成 NSQ由三个组件组成:\nnsqd 用于接收消息，排队消息，投递消息，我们的客户端(生产者，消费者)主要和它打交道 nsqlookupd 管理nsqd,nsqadmin拓扑信息。 我们的客户端(消费者)询问此组件来发现nsqd等 nsqadmin web UI 查询各种NSQ组件的信息，消息信息 NSQ使用步骤 启动nsqlookupd组件 启动nsqd并向nsqlookupd注册 启动nsqadmin并向nsqlookupd注册 生产者推送一个message到其中一个nsqd，并将此消息设置到一个topic里面 消费者向nsqlookupd询问指定topic的消息，nsqlookupd把有此topic的nsqd地址给到消费者 消费者建立channel和topic之间的订阅关系，通过channel向nsqd获取指定topic里面的消息 nsqd向所有订阅该topic的channel推送message， 然后其中一个消费者可以通过其中一个channel获取该topic的message 注意第4点，生产者为什么没有从nsqlookupd注册中心去寻找可以推送消息的nsqd呢？因为nsq的设计理念是将nsqd本地化，也就是说生产者直接推送消息到local-nsqd。这点和RocketMQ的设计理念不一样，RocketMQ的NameServer和nsqlookupd类似，但是设计上RocketMQ生产者会访问NameServer去寻找可用的MQ推送消息。\n启动，注册过程: 生产者，消费者: 这就是nsq一个完整的使用流程，下面分别从客户端和代码两个方面介绍详细怎么使用\n客户端使用 启动nsqlookup\n$ nsqlookupd 在另一个shell启动一个nsqd,并在lookupd注册,注意-broadcast-address一定是消费者可以访问的地址\n$ nsqd --lookupd-tcp-address=127.0.0.1:4160 -broadcast-address=\u0026#34;x.x.x.x\u0026#34; -tcp-address=\u0026#34;0.0.0.0:4150\u0026#34; 启动nsqadmin，并在lookupd注册:\n$ nsqadmin --lookupd-http-address=127.0.0.1:4161 生产者生产一个message，并创建该消息的topic\n$ curl -d \u0026#39;hello world 1\u0026#39; \u0026#39;http://127.0.0.1:4151/pub?topic=test\u0026#39; 消费者通过lookupd查找对应的topic的nsq并绑定topic和channel，通过channel接受该topic的message\n$ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161 生产者生产更多消息\n$ curl -d \u0026#39;hello world 2\u0026#39; \u0026#39;http://127.0.0.1:4151/pub?topic=test\u0026#39;\r$ curl -d \u0026#39;hello world 3\u0026#39; \u0026#39;http://127.0.0.1:4151/pub?topic=test\u0026#39; 可以打开nsaadmin查看所有详情http://127.0.0.1:4171/ ，同时也可以查看/tmp下面接收并写入的message (test.*.log)\n代码 生产者代码:\npackage main\rimport (\r\u0026#34;github.com/nsqio/go-nsq\u0026#34;\r\u0026#34;log\u0026#34;\r)\rfunc main() {\rconfig := nsq.NewConfig()\rw, _ := nsq.NewProducer(\u0026#34;x.x.x.x:4150\u0026#34;, config)\rerr := w.Publish(\u0026#34;write_test\u0026#34;, []byte(\u0026#34;test\u0026#34;))\rif err != nil {\rlog.Panic(\u0026#34;Could not connect\u0026#34;)\r}\rw.Stop()\r} 消费者代码：\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;github.com/nsqio/go-nsq\u0026#34;\r\u0026#34;log\u0026#34;\r\u0026#34;sync\u0026#34;\r)\rfunc main() {\rwg := \u0026amp;sync.WaitGroup{}\rwg.Add(1)\rconfig := nsq.NewConfig()\rq, _ := nsq.NewConsumer(\u0026#34;write_test\u0026#34;, \u0026#34;ch\u0026#34;, config)\rq.AddHandler(nsq.HandlerFunc(func(message *nsq.Message) error {\rfmt.Println(string(message.Body))\rwg.Done()\rreturn nil\r}))\rerr := q.ConnectToNSQLookupd(\u0026#34;x.x.x.x:4161\u0026#34;)\rif err != nil {\rlog.Panic(\u0026#34;Could not connect\u0026#34;)\r}\rwg.Wait()\r} ","permalink":"https://kmnemon.github.io/posts/2019-06-24-golang-nsq-intro/","summary":"\u003ch1 id=\"版本\"\u003e版本\u003c/h1\u003e\n\u003cp\u003egolang \u0026ndash; 1.12.4\u003cbr\u003e\nnsq-1.1.0.linux-amd64.go1.10.3.tar.gz\u003c/p\u003e\n\u003ch1 id=\"什么是nsq\"\u003e什么是NSQ\u003c/h1\u003e\n\u003cp\u003e一句话讲NSQ是一个简单队列，类似于java经常使用的activeMQ或者RocketMQ,一般在同步分离成异步，发送消息和接受消息解耦的地方使用到。\u003cbr\u003e\nNSQ有以下特性:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e支持拓扑的高可用性和避免单点故障(SPOFs)。\u003c/li\u003e\n\u003cli\u003e更强的消息递交保证\u003c/li\u003e\n\u003cli\u003e为单次处理绑定着内存的足迹(通过把一些持久话的消息放入磁盘)\u003c/li\u003e\n\u003cli\u003e对生产者和消费者的配置进行极大的简化\u003c/li\u003e\n\u003cli\u003e提供直接的升级路径\u003c/li\u003e\n\u003cli\u003e提升效率\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"nsq组成\"\u003eNSQ组成\u003c/h1\u003e\n\u003cp\u003eNSQ由三个组件组成:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ensqd 用于接收消息，排队消息，投递消息，我们的客户端(生产者，消费者)主要和它打交道\u003c/li\u003e\n\u003cli\u003ensqlookupd 管理nsqd,nsqadmin拓扑信息。 我们的客户端(消费者)询问此组件来发现nsqd等\u003c/li\u003e\n\u003cli\u003ensqadmin web UI 查询各种NSQ组件的信息，消息信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"nsq使用步骤\"\u003eNSQ使用步骤\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e启动nsqlookupd组件\u003c/li\u003e\n\u003cli\u003e启动nsqd并向nsqlookupd注册\u003c/li\u003e\n\u003cli\u003e启动nsqadmin并向nsqlookupd注册\u003c/li\u003e\n\u003cli\u003e生产者推送一个message到其中一个nsqd，并将此消息设置到一个topic里面\u003c/li\u003e\n\u003cli\u003e消费者向nsqlookupd询问指定topic的消息，nsqlookupd把有此topic的nsqd地址给到消费者\u003c/li\u003e\n\u003cli\u003e消费者建立channel和topic之间的订阅关系，通过channel向nsqd获取指定topic里面的消息\u003c/li\u003e\n\u003cli\u003ensqd向所有订阅该topic的channel推送message， 然后其中一个消费者可以通过其中一个channel获取该topic的message\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e注意第4点，生产者为什么没有从nsqlookupd注册中心去寻找可以推送消息的nsqd呢？因为nsq的设计理念是将nsqd本地化，也就是说生产者直接推送消息到local-nsqd。这点和RocketMQ的设计理念不一样，RocketMQ的NameServer和nsqlookupd类似，但是设计上RocketMQ生产者会访问NameServer去寻找可用的MQ推送消息。\u003c/p\u003e\n\u003ch3 id=\"启动注册过程\"\u003e启动，注册过程:\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2019-06-24-golang-nsq-intro/startup.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"生产者消费者\"\u003e生产者，消费者:\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2019-06-24-golang-nsq-intro/producer_consumer.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这就是nsq一个完整的使用流程，下面分别从客户端和代码两个方面介绍详细怎么使用\u003c/p\u003e\n\u003ch1 id=\"客户端使用\"\u003e客户端使用\u003c/h1\u003e\n\u003cp\u003e启动nsqlookup\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ nsqlookupd\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e在另一个shell启动一个nsqd,并在lookupd注册,注意-broadcast-address一定是消费者可以访问的地址\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ nsqd --lookupd-tcp-address=127.0.0.1:4160 -broadcast-address=\u0026#34;x.x.x.x\u0026#34;  -tcp-address=\u0026#34;0.0.0.0:4150\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e启动nsqadmin，并在lookupd注册:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ nsqadmin --lookupd-http-address=127.0.0.1:4161\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e生产者生产一个message，并创建该消息的topic\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ curl -d \u0026#39;hello world 1\u0026#39; \u0026#39;http://127.0.0.1:4151/pub?topic=test\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e消费者通过lookupd查找对应的topic的nsq并绑定topic和channel，通过channel接受该topic的message\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e生产者生产更多消息\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ curl -d \u0026#39;hello world 2\u0026#39; \u0026#39;http://127.0.0.1:4151/pub?topic=test\u0026#39;\r\n$ curl -d \u0026#39;hello world 3\u0026#39; \u0026#39;http://127.0.0.1:4151/pub?topic=test\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e可以打开nsaadmin查看所有详情http://127.0.0.1:4171/ ，同时也可以查看/tmp下面接收并写入的message (test.*.log)\u003c/p\u003e","title":"golang-NSQ讲明白"},{"content":" 版本\ngolang \u0026ndash; 1.12.4\ngolang协程同步\n1.channel - monitor goroutine\nvar deposits = make(chan int) // send amount to deposit\rvar balances = make(chan int) // receive balance\rfunc Deposit(amount int) { deposits \u0026lt;- amount }\rfunc Balance() int { return \u0026lt;-balances }\rfunc teller() {\rvar balance int // balance is confined to teller goroutine\rfor {\rselect {\rcase amount := \u0026lt;-deposits:\rbalance += amount\rcase balances \u0026lt;- balance:\r}\r}\r}\rfunc init() {\rgo teller() // start the monitor goroutine\r} 2.channel - serial confinement\ntype Cake struct{ state string }\rfunc baker(cooked chan\u0026lt;- *Cake) {\rfor {\rcake := new(Cake)\rcake.state = \u0026#34;cooked\u0026#34;\rcooked \u0026lt;- cake // baker never touches this cake again\r} }\rfunc icer(iced chan\u0026lt;- *Cake, cooked \u0026lt;-chan *Cake) {\rfor cake := range cooked {\rcake.state = \u0026#34;iced\u0026#34;\riced \u0026lt;- cake // icer never touches this cake again\r} } 3.mutual exclusion\nimport \u0026#34;sync\u0026#34;\rvar mu sync.Mutex // guards balance\rvar balance int\rfunc Deposit(amount int) {\rmu.Lock()\rbalance = balance + amount\rmu.Unlock()\r}\rfunc Balance() int {\rmu.Lock()\rdefer mu.Unlock()\rreturn balance\r} 4.mutual exclusion - RWMutex\nimport \u0026#34;sync\u0026#34;\rvar mu sync.RWMutex // guards balance\rvar balance int\rfunc Deposit(amount int) {\rmu.Lock()\rbalance = balance + amount\rmu.Unlock()\r}\rfunc Balance() int {\rmu.RLock() //readers lock\rdefer mu.RUnlock()\rreturn balance\r} RLock允许读取并行，写入和读取完全互斥，多次读取，一次写入\n5.Lazy Initialization - sync.Once\nvar loadIconsOnce sync.Once\rvar icons map[string]image.Image\r// Concurrency-safe.\rfunc Icon(name string) image.Image {\rloadIconsOnce.Do(loadIcons)\rreturn icons[name]\r} ","permalink":"https://kmnemon.github.io/posts/2019-05-13-golang-concurrency/","summary":"\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e版本\u003cbr\u003e\ngolang \u0026ndash; 1.12.4\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003egolang协程同步\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e1.channel - monitor goroutine\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003evar deposits = make(chan int) // send amount to deposit\r\nvar balances = make(chan int) // receive balance\r\n\r\nfunc Deposit(amount int) { deposits \u0026lt;- amount }\r\nfunc Balance() int       { return \u0026lt;-balances }\r\n\r\nfunc teller() {\r\n     var balance int // balance is confined to teller goroutine\r\n     for {\r\n         select {\r\n         case amount := \u0026lt;-deposits:\r\n              balance += amount\r\n         case balances \u0026lt;- balance:\r\n         }\r\n      }\r\n}\r\nfunc init() {\r\n     go teller() // start the monitor goroutine\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e2.channel - serial confinement\u003c/p\u003e","title":"golang实现协程安全的几种方式"},{"content":" 版本\ngolang \u0026ndash; 1.12.4\nmongodb \u0026ndash; 4.0\ngo driver \u0026ndash; 1.0.0\n简介\n在上一篇《用golang实现mongodb数据库连接池-基本篇》我们实现了mongodb的golang driver按序使用的基本版，但还需要进一步提升效率和高并发安全。本篇张实现高效率协程安全版。\ndata race 什么是data race，考虑如下代码：\nvar balance int\rfunc Deposit(amount int){ balance = balance + amount}\rfunc Balance() int { return balance}\r//Alice:\rgo func(){\rbank.Deposit(200) // A1\rfmt.Println(\u0026#34;=\u0026#34;, bank.Balance()) // A2\r}()\r//Bob\rgo bank.Deposit(100) // B 当alice和bob同时执行如上的操作，最后的存款有几种可能性？\n根据直觉会有3种可能：\nalice first bob first alice/bob/alice 0 0 0 A1 200 B 100 A1 200 A2 \u0026ldquo;=200\u0026rdquo; A1 300 B 300 B 300 A2 \u0026ldquo;=300\u0026rdquo; A2 \u0026ldquo;=300\u0026rdquo; 这个结果最后存款都是剩余300似乎也没什么问题，但是这里还有第4种可能，那就是bob的存款操作发生在A1的balance + amount之后，但是在A1的balance =之前，那么会出现什么？\nData race 0 A1r 0 \u0026hellip;=balance + amount B 100 A1w 200 balace = \u0026hellip; A2 \u0026ldquo;=200\u0026rdquo; 现在Alice账户剩余200，在data race中100被程序冲掉。\n设计\n我们使用mutual exclusion的方式进行协程安全设计，具体请参见《golang实现协程安全的几种方式》\n核心代码\nconst(\rMAX_CONNECTION = 10\rINITIAL_CONNECTION = 4\rAVAILABLE = false\rUSED = true\r)\r/*\r代码取了一个巧，用实际存放数据库指针的大小ClientPool.size和mongodata.flag来表示上述a，b两个状态\r如果mongodata.flag都为USED，那么需要新申请个数据库连接: size++\rclientList: the client pool\rclientAvailable: the available flag, means the location and available flag in the client pool\rsize: the size of allocated client pool \u0026lt;= MAX_CONNECTION\r*/\rtype mongodata struct{\rclient *mongo.Client\rpos int\rflag bool\r}\rtype ClientPool struct{\rclientList [MAX_CONNECTION]mongodata\rsize int\r}\r//create a new database connection to the pool\rfunc (cp *ClientPool) allocateCToPool(pos int) (err error){\rcp.clientList[pos].client, err = Dbconnect()\rif err != nil {\rutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\rutils.Logger.Println(\u0026#34;allocateCToPool - allocateCToPool failed,position: \u0026#34;, pos, err)\rreturn err\r}\rcp.clientList[pos].flag = USED\rcp.clientList[pos].pos = pos\rreturn nil\r}\r//apply a connection from the pool\rfunc (cp *ClientPool) getCToPool(pos int){\rcp.clientList[pos].flag = USED\r}\r//free a connection back to the pool\rfunc (cp *ClientPool) putCBackPool(pos int){\rcp.clientList[pos].flag = AVAILABLE\r}\r//program apply a database connection\rfunc GetClient() (mongoclient *mongodata, err error) {\rmu.RLock()\rfor i:=1; i\u0026lt;cp.size; i++ {\rif cp.clientList[i].flag == AVAILABLE{\rreturn \u0026amp;cp.clientList[i], nil\r}\r}\rmu.RUnlock()\rmu.Lock()\rdefer mu.Unlock()\rif cp.size \u0026lt; MAX_CONNECTION{\rerr = cp.allocateCToPool(cp.size)\rif err != nil {\rutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\rutils.Logger.Println(\u0026#34;GetClient - DB pooling allocate failed\u0026#34;, err)\rreturn nil, err\r}\rpos := cp.size\rcp.size++\rreturn \u0026amp;cp.clientList[pos], nil\r} else {\rutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\rutils.Logger.Println(\u0026#34;GetClient - DB pooling is fulled\u0026#34;)\rreturn nil, errors.New(\u0026#34;DB pooling is fulled\u0026#34;)\r}\r}\r//program release a connection\rfunc ReleaseClient(mongoclient *mongodata){\rmu.Lock()\rcp.putCBackPool(mongoclient.pos)\rmu.Unlock()\r} 这样我们就完成了一个高效率协程安全的设计，完整代码地址: https://github.com/kmnemon/golang-mongodb-pool\n","permalink":"https://kmnemon.github.io/posts/2019-05-11-golang-database-pool-2/","summary":"\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e版本\u003cbr\u003e\ngolang \u0026ndash; 1.12.4\u003cbr\u003e\nmongodb \u0026ndash; 4.0\u003cbr\u003e\ngo driver \u0026ndash; 1.0.0\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e简介\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e在上一篇《\u003ca href=\"/posts/2019-05-10-golang-database-pool/\"\u003e用golang实现mongodb数据库连接池-基本篇\u003c/a\u003e》我们实现了mongodb的golang driver按序使用的基本版，但还需要进一步提升效率和高并发安全。本篇张实现高效率协程安全版。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003edata race\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e什么是data race，考虑如下代码：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003evar balance int\r\nfunc Deposit(amount int){ balance = balance + amount}\r\nfunc Balance() int { return balance}\r\n\r\n//Alice:\r\ngo func(){\r\n\tbank.Deposit(200)                // A1\r\n\tfmt.Println(\u0026#34;=\u0026#34;, bank.Balance()) // A2\r\n}()\r\n\r\n//Bob\r\ngo bank.Deposit(100)                  // B\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e当alice和bob同时执行如上的操作，最后的存款有几种可能性？\u003cbr\u003e\n根据直觉会有3种可能：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003ealice first\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003ebob first\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003ealice/bob/alice\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e0\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e0\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003eA1 200\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eB 100\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eA1 200\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003eA2 \u0026ldquo;=200\u0026rdquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eA1 300\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eB 300\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003eB 300\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eA2 \u0026ldquo;=300\u0026rdquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eA2 \u0026ldquo;=300\u0026rdquo;\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e这个结果最后存款都是剩余300似乎也没什么问题，但是这里还有第4种可能，那就是bob的存款操作发生在A1的balance + amount之后，但是在A1的balance =之前，那么会出现什么？\u003c/p\u003e","title":"用golang实现mongodb数据库连接池-高级篇-协程安全"},{"content":" 版本\ngolang \u0026ndash; 1.12.4\nmongodb \u0026ndash; 4.0\ngo driver \u0026ndash; 1.0.0\n简介\nmongodb的数据库driver在官方文档里面明确写明所有的数据库连接需要自己建立和释放，而且建议尽量复用已有的建立，那么也就是说driver里面并未实现连接池的功能。在我们实际应用中就需要自己实现这套数据库连接池提升程序和数据库之间的执行效率。\n设计思路 用一个数组来存放数据库连接的指针，并记录每一个指针两个状态: a.是否申请了数据库连接 b.这个连接是否已经给系统在使用中。举个例子就比较好理解了:\n申请一个用于存放数据连接的数组，一开始空的什么都没有\n程序需要一个数据库连接，连接池把数组第一个位置建立一个数据库连接，并把这个连接的状态置为：a.已申请 b.已给系统\n程序使用完释放数据库连接，现在数据库指针状态为：a.已申请 b.未使用\n程序需要新申请一个数据库连接，那么就回到了第2的状态。\n核心代码 const(\rMAX_CONNECTION = 10\rINITIAL_CONNECTION = 4\rAVAILABLE = false\rUSED = true\r)\r/*\r代码取了一个巧，用实际存放数据库指针的大小ClientPool.size和mongodata.flag来表示上述a，b两个状态\r如果mongodata.flag都为USED，那么需要新申请个数据库连接: size++\rclientList: the client pool\rclientAvailable: the available flag, means the location and available flag in the client pool\rsize: the size of allocated client pool \u0026lt;= MAX_CONNECTION\r*/\rtype mongodata struct{\rclient *mongo.Client\rpos int\rflag bool\r}\rtype ClientPool struct{\rclientList [MAX_CONNECTION]mongodata\rsize int\r}\r//create a new database connection to the pool\rfunc (cp *ClientPool) allocateCToPool(pos int) (err error){\rcp.clientList[pos].client, err = Dbconnect()\rif err != nil {\rutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\rutils.Logger.Println(\u0026#34;allocateCToPool - allocateCToPool failed,position: \u0026#34;, pos, err)\rreturn err\r}\rcp.clientList[pos].flag = USED\rcp.clientList[pos].pos = pos\rreturn nil\r}\r//apply a connection from the pool\rfunc (cp *ClientPool) getCToPool(pos int){\rcp.clientList[pos].flag = USED\r}\r//free a connection back to the pool\rfunc (cp *ClientPool) putCBackPool(pos int){\rcp.clientList[pos].flag = AVAILABLE\r}\r//program apply a database connection\rfunc GetClient() (mongoclient *mongodata, err error) {\rfor i:=1; i\u0026lt;cp.size; i++ {\rif cp.clientList[i].flag == AVAILABLE{\rreturn \u0026amp;cp.clientList[i], nil\r}\r}\rif cp.size \u0026lt; MAX_CONNECTION{\rerr = cp.allocateCToPool(cp.size)\rif err != nil {\rutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\rutils.Logger.Println(\u0026#34;GetClient - DB pooling allocate failed\u0026#34;, err)\rreturn nil, err\r}\rpos := cp.size\rcp.size++\rreturn \u0026amp;cp.clientList[pos], nil\r} else {\rutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\rutils.Logger.Println(\u0026#34;GetClient - DB pooling is fulled\u0026#34;)\rreturn nil, errors.New(\u0026#34;DB pooling is fulled\u0026#34;)\r}\r}\r//program release a connection\rfunc ReleaseClient(mongoclient *mongodata){\rcp.putCBackPool(mongoclient.pos)\r} 以上就是核心代码实现，但是这个代码有一个问题，就是在高并发下并非协程安全，这个留在下一篇《用golang实现mongodb数据库连接池-高级篇-协程安全》来优化。\n","permalink":"https://kmnemon.github.io/posts/2019-05-10-golang-database-pool/","summary":"\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e版本\u003cbr\u003e\ngolang \u0026ndash; 1.12.4\u003cbr\u003e\nmongodb \u0026ndash; 4.0\u003cbr\u003e\ngo driver \u0026ndash; 1.0.0\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e简介\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003emongodb的数据库driver在官方文档里面明确写明所有的数据库连接需要自己建立和释放，而且建议尽量复用已有的建立，那么也就是说driver里面并未实现连接池的功能。在我们实际应用中就需要自己实现这套数据库连接池提升程序和数据库之间的执行效率。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计思路\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e用一个数组来存放数据库连接的指针，并记录每一个指针两个状态: a.是否申请了数据库连接 b.这个连接是否已经给系统在使用中。举个例子就比较好理解了:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e申请一个用于存放数据连接的数组，一开始空的什么都没有\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2019-05-10-golang-database-pool/pool_initial.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e程序需要一个数据库连接，连接池把数组第一个位置建立一个数据库连接，并把这个连接的状态置为：a.已申请 b.已给系统\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2019-05-10-golang-database-pool/pool_create_connection.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e程序使用完释放数据库连接，现在数据库指针状态为：a.已申请 b.未使用\u003cbr\u003e\n\u003cimg loading=\"lazy\" src=\"/images/2019-05-10-golang-database-pool/pool_release_connection.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e程序需要新申请一个数据库连接，那么就回到了第2的状态。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e核心代码\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003econst(\r\n\tMAX_CONNECTION = 10\r\n\tINITIAL_CONNECTION = 4\r\n\tAVAILABLE = false\r\n\tUSED = true\r\n\r\n)\r\n\r\n/*\r\n代码取了一个巧，用实际存放数据库指针的大小ClientPool.size和mongodata.flag来表示上述a，b两个状态\r\n如果mongodata.flag都为USED，那么需要新申请个数据库连接: size++\r\nclientList: the client pool\r\nclientAvailable: the available flag, means the location and available flag in the  client pool\r\nsize: the size of allocated client pool \u0026lt;= MAX_CONNECTION\r\n*/\r\ntype mongodata struct{\r\n\tclient *mongo.Client\r\n\tpos int\r\n\tflag bool\r\n\r\n}\r\n\r\ntype ClientPool struct{\r\n\tclientList [MAX_CONNECTION]mongodata\r\n\tsize int\r\n}\r\n\r\n//create a new database connection to the pool\r\nfunc (cp *ClientPool) allocateCToPool(pos int) (err error){\r\n\tcp.clientList[pos].client, err = Dbconnect()\r\n\tif err != nil {\r\n\t\tutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\r\n\t\tutils.Logger.Println(\u0026#34;allocateCToPool - allocateCToPool failed,position: \u0026#34;, pos, err)\r\n\t\treturn err\r\n\t}\r\n\r\n\tcp.clientList[pos].flag = USED\r\n\tcp.clientList[pos].pos = pos\r\n\treturn nil\r\n}\r\n\r\n//apply a connection from the pool\r\nfunc (cp *ClientPool) getCToPool(pos int){\r\n\tcp.clientList[pos].flag = USED\r\n}\r\n\r\n//free a connection back to the pool\r\nfunc (cp *ClientPool) putCBackPool(pos int){\r\n\tcp.clientList[pos].flag = AVAILABLE\r\n}\r\n\r\n//program apply a database connection\r\nfunc GetClient() (mongoclient *mongodata,  err error) {\r\n\tfor i:=1; i\u0026lt;cp.size; i++ {\r\n\t\tif cp.clientList[i].flag == AVAILABLE{\r\n\t\t\treturn \u0026amp;cp.clientList[i], nil\r\n\t\t}\r\n\t}\r\n\r\n\tif cp.size \u0026lt; MAX_CONNECTION{\r\n\t\terr = cp.allocateCToPool(cp.size)\r\n\t\tif err != nil {\r\n\t\t\tutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\r\n\t\t\tutils.Logger.Println(\u0026#34;GetClient - DB pooling allocate failed\u0026#34;, err)\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\r\n\t\tpos := cp.size\r\n\t\tcp.size++\r\n\t\treturn \u0026amp;cp.clientList[pos], nil\r\n\t} else {\r\n\t\tutils.Logger.SetPrefix(\u0026#34;WARNING \u0026#34;)\r\n\t\tutils.Logger.Println(\u0026#34;GetClient - DB pooling is fulled\u0026#34;)\r\n\t\treturn nil, errors.New(\u0026#34;DB pooling is fulled\u0026#34;)\r\n\t}\r\n\r\n}\r\n\r\n//program release a connection\r\nfunc ReleaseClient(mongoclient *mongodata){\r\n\tcp.putCBackPool(mongoclient.pos)\r\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e以上就是核心代码实现，但是这个代码有一个问题，就是在高并发下并非协程安全，这个留在下一篇《\u003ca href=\"/posts/2019-05-11-golang-database-pool-2/\"\u003e用golang实现mongodb数据库连接池-高级篇-协程安全\u003c/a\u003e》来优化。\u003c/p\u003e","title":"用golang实现mongodb数据库连接池-基本篇"},{"content":"The company invited me to do a training crouse about the software\u0026rsquo;s quality, it\u0026rsquo;s an old topic every project book talk about it, every quality master discuss it, the cmmi and agile process have such a huge practices about it, what should i do about it? maybe i just list what i thought is important for the quality and what\u0026rsquo;s wrong with our modern software development process.\nthe passion\ni think most of us going to the industry is because we love this, we love the feel of change something through the finger.if you have this feeling, then you are good damn of it\ndaily meeting\nthree questiones to figture out:\nwhat did you do yesterday? what are you going to do today? Do you need some help?(is there something to stuck the process?) KANBAN\nthe most important thing in a project is the Team have the whole and same picture. whatever u do is keep everybody in the same line. we use KANBAN to do this thing. see the follow:\neverybody know a week\u0026rsquo;s task, they know each other\u0026rsquo;s job and can adjust the day of work to coodinate others.\nRetrospective Meeting\nproductivity tools\njust one button of work\nbuild + static check + auto deploy + auto test\nit\u0026rsquo;s great to use productive tools make the team efficiency. click one button and it\u0026rsquo;s done! build, code static scan, deploy, auto test, the developer and QA love to do the job smoothly. it\u0026rsquo;s saving a lot of time. do not do the same thing manually.\nwe need to be \u0026rsquo;lazy\u0026rsquo; as possible as we can.\nmysterious of code review\nlet\u0026rsquo;s list some research material: Code review rates should be between 200 and 400 lines of code per hour.Inspecting and reviewing more than a few hundred\rlines of code per hour for critical software (such as safety critical embedded software) may be too fast to find errors.\rIndustry data indicates that code reviews can accomplish at most an 85% defect removal rate with an average rate of about 65%. -quote by wiki Most of research about code review reveal that it is the most efficient way to improve software quality, but why most of the orgnization in our nation not do it well?\nthe reason i think is counter-intuitive, kpi-oriented, and deadline. im the prefession developer, i reading others boring code and 200~400 per hour, do not have any advanced for the project yet. the trash i just read belong to the other code monkey, it\u0026rsquo;s none of my bussiness. i have lots of features not done yet, i will coding my own code, meet the deliver time, go to the hell the other\u0026rsquo;s code!\nfocus and cooperate trade off\nprogramming need\nProcess Capability Baseline\nthe lack of data\nbe aware of technism\nhurry, not rush\nDeliver the software to the market, we need to be hurry, but donot rush, if you rush, the software definite to be\u0026hellip; They are not nerd, they are geeks\nThey can drive plane, they can play instrument, they are artisit.\n","permalink":"https://kmnemon.github.io/posts/2018-05-16-about-quality/","summary":"\u003cp\u003eThe company invited me to do a training crouse about the software\u0026rsquo;s quality, it\u0026rsquo;s an old topic every project book talk about it, every quality master discuss it, the cmmi and agile process have such a huge practices about it, what should i do about it?\nmaybe i just list what i thought is important for the quality and what\u0026rsquo;s wrong with our modern software development process.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ethe passion\u003cbr\u003e\ni think most of us going to the industry is because we love this, we love the feel of change something through the finger.if you have this feeling, then you are good damn of it\u003c/p\u003e","title":"about quality"}]